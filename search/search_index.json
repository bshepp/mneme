{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Mneme","text":"<p>Detecting field-like memory structures in biological systems</p> <p>Mneme is an exploratory research system for uncovering attractor states, regulatory logic, and latent architectures in biological tissue -- structures not captured by sequence-based models alone. The project employs Information Field Theory (IFT), Topological Data Analysis (TDA), and machine learning to identify and model distributed memory encoding via fields.</p>"},{"location":"#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Field Reconstruction -- Scalable Sparse GP (default), Dense IFT, Standard GP, and Neural Field backends. Handles 256x256 fields in sub-second time.</li> <li>Topology Analysis -- Full GUDHI integration for cubical, Rips, and Alpha complexes. Persistence diagrams, landscapes, images, Wasserstein/bottleneck distances.</li> <li>Attractor Detection -- Recurrence-based, Lyapunov, and clustering detectors for identifying stable states in temporal field data.</li> <li>Lyapunov Spectrum -- Full Wolf algorithm for computing Lyapunov exponents. Kaplan-Yorke dimension and automatic attractor classification.</li> <li>Symbolic Regression -- PySR integration for discovering governing PDEs from field dynamics.</li> <li>Latent Space Analysis -- Convolutional VAE for learning compressed field representations with interpolation and sampling.</li> <li>BETSE Integration -- Direct ingestion of BETSE bioelectric tissue simulation output.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import numpy as np\nfrom mneme.core import create_reconstructor\nfrom mneme.analysis.pipeline import create_bioelectric_pipeline\nfrom mneme.data.generators import generate_planarian_bioelectric_sequence\n\n# Generate synthetic bioelectric data\ndata = generate_planarian_bioelectric_sequence(shape=(64, 64), timesteps=30, seed=42)\n\n# Run analysis pipeline\npipe = create_bioelectric_pipeline()\nresult = pipe.run({'field': data})\nprint(f\"Pipeline completed in {result.execution_time:.2f}s\")\n\n# Reconstruct field from sparse observations\npositions = np.random.rand(100, 2)\nobservations = np.sin(4 * np.pi * positions[:, 0])\nrec = create_reconstructor('ift', resolution=(128, 128))\nrec.fit(observations, positions)\nfield = rec.reconstruct()\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>git clone https://github.com/bshepp/mneme.git\ncd mneme\npython -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\npip install -r requirements.txt\npip install -e .\n\n# Optional: TDA and symbolic regression\npip install gudhi pysr\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started -- Environment setup and dependencies</li> <li>Project Structure -- Code organization and architecture</li> <li>API Reference -- Auto-generated reference for all modules</li> <li>Data Pipeline -- Pipeline architecture and stages</li> <li>BETSE Analysis -- Results from BETSE simulation analysis</li> <li>Course -- 11-module learning course</li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License. See LICENSE for details.</p>"},{"location":"API_DESIGN/","title":"Mneme API Design Documentation","text":""},{"location":"API_DESIGN/#core-api-philosophy","title":"Core API Philosophy","text":"<p>The Mneme API follows these principles: - Composability: Small, focused functions that combine into complex pipelines - Type Safety: Clear type hints and validation - Configurability: Flexible parameters with sensible defaults - Reproducibility: Deterministic operations with seed control</p>"},{"location":"API_DESIGN/#module-apis","title":"Module APIs","text":"<p>MVP note: Some classes shown below (e.g., rich attractor characterization, full models) are placeholders or partially implemented. Methods explicitly marked with <code>NotImplementedError</code> are roadmap.</p>"},{"location":"API_DESIGN/#1-field-theory-module-mnemecorefield_theory-mvp","title":"1. Field Theory Module (<code>mneme.core.field_theory</code>) \u2014 MVP","text":"<pre><code>from mneme.core import field_theory\n\nclass FieldReconstructor:\n    \"\"\"Reconstruct continuous fields from discrete observations.\"\"\"\n\n    def __init__(self, method='ift', resolution=(256, 256)):\n        \"\"\"\n        Parameters:\n            method: Reconstruction method ('gaussian_process', 'ift', 'neural_field')\n            resolution: Output field resolution\n        \"\"\"\n\n    def fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'FieldReconstructor':\n        \"\"\"Fit the reconstructor to observations.\"\"\"\n\n    def reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n        \"\"\"Reconstruct the continuous field.\"\"\"\n\n    def uncertainty(self) -&gt; np.ndarray:\n        \"\"\"Return reconstruction uncertainty estimates.\"\"\"\n\n# Usage example\nreconstructor = FieldReconstructor(method='ift')\nreconstructor.fit(voltage_measurements, electrode_positions)\nfield = reconstructor.reconstruct()\nuncertainty = reconstructor.uncertainty()\n</code></pre>"},{"location":"API_DESIGN/#2-topology-module-mnemecoretopology-mvp","title":"2. Topology Module (<code>mneme.core.topology</code>) \u2014 MVP","text":"<p><pre><code>from mneme.core import topology\n\nclass PersistentHomology:\n    \"\"\"Compute persistent homology of fields.\"\"\"\n\n    def __init__(self, max_dimension=2, filtration='sublevel'):\n        \"\"\"\n        Parameters:\n            max_dimension: Maximum homological dimension\n            filtration: Type of filtration to use\n        \"\"\"\n\n    def compute_persistence(self, field: np.ndarray) -&gt; List[Diagram]:\n        \"\"\"Compute persistence diagrams.\"\"\"\n\n    def extract_features(self, diagrams: List[Diagram]) -&gt; np.ndarray:\n        \"\"\"Extract topological features from diagrams.\"\"\"\n\nclass AttractorDetector:\n    \"\"\"Detect and characterize attractors in dynamical fields (basic recurrence).\"\"\"\n\n    def __init__(self, method='recurrence', threshold=0.1):\n        \"\"\"\n        Parameters:\n            method: Detection method ('recurrence', 'lyapunov', 'clustering')\n            threshold: Detection threshold\n        \"\"\"\n\n    def detect(self, trajectory: np.ndarray) -&gt; List[Attractor]:\n        \"\"\"Detect attractors in phase space trajectory.\"\"\"\n\n    def characterize(self, attractor: Attractor) -&gt; Dict[str, Any]:\n        \"\"\"Compute attractor properties (dimension, stability, basin).\"\"\"\n\n### 2b. Point-cloud topology backends \u2014 MVP\n\n```python\nfrom mneme.core.topology import RipsComplex, AlphaComplex, field_to_point_cloud\n\n# Convert 2D field to point cloud and run Rips\npc = field_to_point_cloud(field2d, method='peaks', percentile=95.0)\ntda = RipsComplex(max_dimension=1)\ndiagrams = tda.compute_persistence(pc)\nfeatures = tda.extract_features(diagrams)\n</code></pre> <pre><code>### 3. Models Module (`mneme.models`) \u2014 placeholders\n\n```python\nfrom mneme.models import autoencoders, symbolic\n\nclass FieldAutoencoder(nn.Module):\n    \"\"\"Placeholder VAE for field data (minimal).\"\"\"\n\n    def __init__(self, input_shape, latent_dim=32, architecture='convolutional'):\n        \"\"\"\n        Parameters:\n            input_shape: Shape of input fields\n            latent_dim: Latent space dimensionality\n            architecture: Network architecture type\n        \"\"\"\n\n    def encode(self, field: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Encode field to latent representation (mean, log_var).\"\"\"\n\n    def decode(self, z: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Decode latent representation to field.\"\"\"\n\n    def forward(self, field: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"Forward pass returning reconstruction, mean, log_var.\"\"\"\n\nclass SymbolicRegressor:\n    \"\"\"Placeholder symbolic regression interface.\"\"\"\n\n    def __init__(self, operators=['+', '-', '*', '/', 'sin', 'cos'], \n                 complexity_penalty=0.001):\n        \"\"\"\n        Parameters:\n            operators: Allowed mathematical operators\n            complexity_penalty: Penalty for equation complexity\n        \"\"\"\n\n    def fit(self, X: np.ndarray, y: np.ndarray, \n            variable_names: Optional[List[str]] = None) -&gt; 'SymbolicRegressor':\n        \"\"\"Fit symbolic equations to data.\"\"\"\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predict using discovered equations.\"\"\"\n\n    def get_equations(self) -&gt; List[str]:\n        \"\"\"Return discovered equations as strings.\"\"\"\n</code></pre></p>"},{"location":"API_DESIGN/#4-data-module-mnemedata-mvp","title":"4. Data Module (<code>mneme.data</code>) \u2014 MVP","text":"<pre><code>from mneme.data import loaders, generators, preprocessors\n\n\"\"\"\nNote: The MVP provides loader utilities (`mneme.data.loaders.create_data_loader`) and generators rather than a concrete `BioelectricDataset` class. A thin dataset wrapper can be added later if needed.\n\"\"\"\n\nclass SyntheticFieldGenerator:\n    \"\"\"Generate synthetic field data for testing.\"\"\"\n\n    def __init__(self, field_type='gaussian_random', seed=None):\n        \"\"\"\n        Parameters:\n            field_type: Type of field to generate\n            seed: Random seed for reproducibility\n        \"\"\"\n\n    def generate_static(self, shape: Tuple[int, ...], \n                       parameters: Dict[str, Any]) -&gt; np.ndarray:\n        \"\"\"Generate static field.\"\"\"\n\n    def generate_dynamic(self, shape: Tuple[int, ...], \n                        timesteps: int, \n                        parameters: Dict[str, Any]) -&gt; np.ndarray:\n        \"\"\"Generate time-evolving field.\"\"\"\n\n    def add_noise(self, field: np.ndarray, noise_level: float) -&gt; np.ndarray:\n        \"\"\"Add realistic noise to field.\"\"\"\n\nclass FieldPreprocessor:\n    \"\"\"Preprocess field data for analysis.\"\"\"\n\n    def __init__(self, steps=['denoise', 'normalize', 'register']):\n        \"\"\"\n        Parameters:\n            steps: Preprocessing steps to apply\n        \"\"\"\n\n    def fit(self, fields: List[np.ndarray]) -&gt; 'FieldPreprocessor':\n        \"\"\"Fit preprocessing parameters.\"\"\"\n\n    def transform(self, field: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Apply preprocessing to field.\"\"\"\n\n    def inverse_transform(self, field: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Reverse preprocessing (where possible).\"\"\"\n</code></pre>"},{"location":"API_DESIGN/#5-analysis-pipeline-mnemeanalysispipeline-mvp","title":"5. Analysis Pipeline (<code>mneme.analysis.pipeline</code>) \u2014 MVP","text":"<pre><code>from mneme.analysis import pipeline\n\nclass MnemePipeline:\n    \"\"\"Complete analysis pipeline for field memory detection.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        \"\"\"\n        Parameters:\n            config: Pipeline configuration dictionary\n        \"\"\"\n\n    def add_stage(self, name: str, stage: Callable, \n                  inputs: List[str], outputs: List[str]) -&gt; 'MnemePipeline':\n        \"\"\"Add processing stage to pipeline.\"\"\"\n\n    def run(self, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Execute full pipeline on data.\"\"\"\n\n    def run_stage(self, stage_name: str, data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Run specific pipeline stage.\"\"\"\n\n    def visualize_flow(self) -&gt; None:\n        \"\"\"Visualize pipeline structure.\"\"\"\n\n# Predefined pipeline configurations\ndef create_standard_pipeline() -&gt; MnemePipeline:\n    \"\"\"Create standard analysis pipeline.\"\"\"\n    pipeline = MnemePipeline(config={\n        'preprocessing': {'normalize': True, 'denoise': True},\n        'reconstruction': {'method': 'ift', 'resolution': (256, 256)},\n        'analysis': {'compute_topology': True, 'detect_attractors': True},\n        'modeling': {'use_autoencoder': True, 'symbolic_regression': True}\n    })\n    return pipeline\n\ndef create_bioelectric_pipeline() -&gt; MnemePipeline:\n    \"\"\"Bioelectric-focused defaults; thin wrapper over standard.\"\"\"\n    return MnemePipeline({\n        'preprocessing': {'denoise': {'enabled': True}, 'normalize': {'enabled': True}, 'register': {'enabled': True}, 'interpolate': {'enabled': True}},\n        'reconstruction': {'method': 'ift', 'resolution': (256, 256)},\n        'topology': {'max_dimension': 2, 'filtration': 'sublevel'},\n        'attractors': {'method': 'recurrence', 'threshold': 0.1}\n    })\n</code></pre>"},{"location":"API_DESIGN/#6-visualization-module-mnemeanalysisvisualization","title":"6. Visualization Module (<code>mneme.analysis.visualization</code>)","text":"<pre><code>from mneme.analysis import visualization\n\nclass FieldVisualizer:\n    \"\"\"Visualize fields and analysis results.\"\"\"\n\n    def __init__(self, style='publication', figsize=(10, 8)):\n        \"\"\"\n        Parameters:\n            style: Plotting style preset\n            figsize: Default figure size\n        \"\"\"\n\n    def plot_field(self, field: np.ndarray, title: str = None, \n                   colormap: str = 'viridis', **kwargs) -&gt; plt.Figure:\n        \"\"\"Plot 2D field with customizable appearance.\"\"\"\n\n    def plot_field_sequence(self, fields: List[np.ndarray], \n                           fps: int = 10) -&gt; animation.FuncAnimation:\n        \"\"\"Create animation of field evolution.\"\"\"\n\n    def plot_persistence_diagram(self, diagram: Diagram, \n                                ax: Optional[plt.Axes] = None) -&gt; plt.Figure:\n        \"\"\"Plot topological persistence diagram.\"\"\"\n\n    def plot_attractor_portrait(self, trajectory: np.ndarray, \n                               attractors: List[Attractor]) -&gt; plt.Figure:\n        \"\"\"Plot phase space with detected attractors.\"\"\"\n\n    def create_dashboard(self, results: Dict[str, Any]) -&gt; None:\n        \"\"\"Create interactive dashboard of results.\"\"\"\n</code></pre>"},{"location":"API_DESIGN/#usage-patterns","title":"Usage Patterns","text":""},{"location":"API_DESIGN/#basic-field-analysis","title":"Basic Field Analysis","text":"<pre><code>import mneme\nfrom mneme.core import field_theory, topology\nfrom mneme.analysis import pipeline, visualization\n\n# Load data\ndata = mneme.data.load_bioelectric(\"path/to/data\")\n\n# Create and run pipeline\npipe = pipeline.create_standard_pipeline()\nresults = pipe.run(data)\n\n# Visualize results\nviz = visualization.FieldVisualizer()\nviz.create_dashboard(results)\n</code></pre>"},{"location":"API_DESIGN/#custom-pipeline","title":"Custom Pipeline","text":"<pre><code># Define custom pipeline\npipe = MnemePipeline(config={'seed': 42})\n\n# Add custom stages\npipe.add_stage(\n    name='custom_filter',\n    stage=lambda x: custom_filter_function(x['field']),\n    inputs=['field'],\n    outputs=['filtered_field']\n)\n\npipe.add_stage(\n    name='extract_features',\n    stage=lambda x: extract_spatial_features(x['filtered_field']),\n    inputs=['filtered_field'],\n    outputs=['features']\n)\n\n# Run pipeline\nresults = pipe.run({'field': my_field_data})\n</code></pre>"},{"location":"API_DESIGN/#batch-processing","title":"Batch Processing","text":"<pre><code>from mneme.data import BioelectricDataset\nfrom torch.utils.data import DataLoader\n\n# Create dataset and dataloader\ndataset = BioelectricDataset(\"data/planarian/\")\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Process batches\nfor batch in dataloader:\n    fields = batch['voltage_field']\n    results = pipe.run_batch(fields)\n    # Save or aggregate results\n</code></pre>"},{"location":"API_DESIGN/#error-handling","title":"Error Handling","text":"<p>All API functions include proper error handling:</p> <pre><code>try:\n    reconstructor = FieldReconstructor(method='invalid_method')\nexcept ValueError as e:\n    print(f\"Invalid method: {e}\")\n\n# Or with validation\nfrom mneme.utils import validate_parameters\n\n@validate_parameters\ndef process_field(field: np.ndarray, threshold: float = 0.1) -&gt; np.ndarray:\n    \"\"\"Process field with automatic parameter validation.\"\"\"\n    return field[field &gt; threshold]\n</code></pre>"},{"location":"API_DESIGN/#configuration-management","title":"Configuration Management","text":"<pre><code>from mneme.utils import Config\n\n# Load configuration\nconfig = Config.from_yaml(\"config/experiment.yaml\")\n\n# Access nested values\nreconstruction_method = config.get(\"reconstruction.method\", default=\"ift\")\n\n# Update configuration\nconfig.set(\"analysis.threshold\", 0.15)\nconfig.save(\"config/modified.yaml\")\n</code></pre>"},{"location":"BETSE_ANALYSIS_REPORT/","title":"BETSE Simulation Analysis Report","text":"<p>Date: 2026-02-13 (updated 2026-02-14 with patterns results) Analyst: Mneme pipeline (automated) + manual interpretation Data source: BETSE paper configurations (<code>attractors_2018</code>, <code>physiology_2018</code>, <code>patterns_2018</code>) run on AWS EC2 c6i.xlarge Pipeline version: Mneme 0.1.x (GUDHI TDA for H0+H1, PySR symbolic regression, PyTorch VAE)</p>"},{"location":"BETSE_ANALYSIS_REPORT/#executive-summary","title":"Executive Summary","text":"<p>We ran five BETSE bioelectric tissue simulations derived from published Levin Lab paper configurations through the Mneme analysis pipeline. The analysis consisted of two phases: an initial pass using topology, Lyapunov spectrum, and recurrence analysis; and a deeper pass using PCA mode extraction, Wasserstein distance tracking, and convolutional VAE latent-space embedding.</p> <p>Key findings:</p> <ol> <li> <p>Multi-stability confirmed. Two simulations of the same tissue under different initial conditions converge to distinct attractor basins, occupying clearly separated regions in both PCA and VAE latent spaces. This is the core phenomenon Mneme was designed to detect.</p> </li> <li> <p>Pattern formation breaks the dimensionality ceiling. Attractor and physiology simulations are effectively rank-2 (99.5%+ variance in 2 PCA modes), but the patterns simulation has 5 significant modes (81% + 13% + 4% + 1% + 0.6%). GRN-driven pattern formation creates the multi-modal spatial dynamics that gap-junction-only coupling cannot.</p> </li> <li> <p>Wasserstein distance tracking is the most discriminating method. It reveals four distinct topological regimes: sim_1 (oscillatory settling), sim_2 (directed drift), physiology (topology-preserving excursion), and patterns (high-rate accumulating reorganization with total drift 84.1 -- 2.6x the nearest comparator).</p> </li> <li> <p>Topological reorganization without topological creation. The patterns simulation maintains ~22 H0 features from first to last frame, but the Wasserstein distance between them is 84.1 mV -- meaning the features are being continuously reshuffled, not created or destroyed. This is the signature of active pattern formation.</p> </li> <li> <p>Physiology simulation is a distinct dynamical class. A small cell cluster undergoing a 56 mV depolarization-repolarization event shows topology-preserving dynamics -- massive voltage change with almost no topological reorganization.</p> </li> </ol>"},{"location":"BETSE_ANALYSIS_REPORT/#1-data-overview","title":"1. Data Overview","text":""},{"location":"BETSE_ANALYSIS_REPORT/#source-configurations","title":"Source Configurations","text":"<p>All data was generated using BETSE v1.3.x from published YAML configurations included in the BETSE repository (<code>doc/yaml/paper/</code>). Simulations ran on AWS EC2 (c6i.xlarge, 4 vCPU, 8 GB RAM) for approximately 3 hours.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#datasets","title":"Datasets","text":"Dataset Config Cells Timesteps Vmem Range (mV) Spatial Domain (um) sim_1 attractors_2018 (init_1) 153 635 [-70.6, +20.3] 135 x 133 sim_2 attractors_2018 (init_2) 156 635 [-86.5, +18.0] 135 x 133 physiology physiology_2018 7 190 [-83.8, -21.2] 17 x 15 <p>The <code>attractors_2018</code> configuration defines a tissue with gap junction-coupled cells under two different initial voltage conditions (init_1, init_2), then simulates their evolution over 635 timesteps. The <code>physiology_2018</code> configuration models a small cluster of 7 cells undergoing ion channel-driven voltage dynamics.</p> <p>Data deduplication note: File hashing confirmed that <code>attractors_2_RESULTS/sim_2</code> and <code>attractors_3_RESULTS/sim_3</code> are byte-for-byte identical to their counterparts in <code>attractors_1_RESULTS</code>. The three \"attractor\" configs share the same base tissue mesh; only the unique simulation runs (sim_1 in config 1, sim_2 in config 2) produced distinct data. All analysis below uses the three unique datasets listed above.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#preprocessing","title":"Preprocessing","text":"<p>Raw BETSE output (scattered Vmem2D CSV files with cell positions and voltages) was interpolated onto a regular 64x64 grid using cubic interpolation via <code>mneme.data.betse_loader.load_betse_timeseries()</code>. This produces a (T, 64, 64) field sequence per dataset.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#2-initial-analysis","title":"2. Initial Analysis","text":""},{"location":"BETSE_ANALYSIS_REPORT/#21-topological-feature-counts","title":"2.1 Topological Feature Counts","text":"<p>Persistent homology (H0 = connected components) was computed at first, middle, and last frames using cubical complex filtration.</p> Dataset Frame H0 Features Max Persistence (mV) Mean Persistence (mV) sim_1 first (t=0) 18 89.1 8.7 middle (t=317) 8 77.0 14.0 last (t=634) 11 84.2 12.6 sim_2 first (t=0) 14 102.0 12.3 middle (t=317) 20 98.1 8.2 last (t=634) 21 100.1 7.9 physiology first (t=0) 1 1.7 1.7 middle (t=95) 1 1.9 1.9 last (t=189) 1 0.9 0.9 <p>Observation: Opposite topological trends. sim_1 simplifies over time (18 to 11 features), with fewer but more persistent structures emerging. sim_2 complexifies (14 to 21 features), gaining topological structure but with each feature becoming less persistent. These are two different tissue responses: one consolidating, one proliferating.</p> <p>Physiology is topologically trivial throughout -- a single connected component with persistence under 2 mV, consistent with a nearly uniform field across 7 tightly coupled cells.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#22-topology-evolution-10-sample-timeline","title":"2.2 Topology Evolution (10-Sample Timeline)","text":"<p>sim_1 (simplifying): <pre><code>t=0:   18 features\nt=70:  13\nt=140: 18\nt=211: 23  &lt;-- peak complexity\nt=281: 17\nt=352: 14\nt=422: 25  &lt;-- second peak\nt=493: 21\nt=563: 19\nt=634: 11  &lt;-- minimum\n</code></pre></p> <p>sim_2 (complexifying): <pre><code>t=0:   14 features\nt=70:  15\nt=140: 19\nt=211: 16\nt=281: 22  &lt;-- peak\nt=352: 19\nt=422: 19\nt=493: 14  &lt;-- dip\nt=563: 19\nt=634: 21\n</code></pre></p> <p>sim_1 shows oscillatory bursts (peaks at t=211 and t=422) with an overall downward trend. sim_2 shows a steady rise with a temporary dip around t=493. These are different attractors with different basin geometries.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#23-lyapunov-spectrum-initial-3d-trajectory","title":"2.3 Lyapunov Spectrum (Initial, 3D Trajectory)","text":"<p>The initial Lyapunov analysis used a simple 3D trajectory constructed from spatial moments (mean voltage, standard deviation, skewness):</p> Dataset Spectrum Type D_KY Recurrence Rate sim_1 [+10.45, +7.44, +7.18] Strange 3.0 6.1% sim_2 [+11.08, +7.67, +7.06] Strange 3.0 20.5% physiology [+3.77, +1.31, +0.34] Strange 3.0 2.6% <p>All exponents positive and D_KY = embedding dimension in every case. This signals saturation: the 3D moment trajectory is under-embedded for proper attractor characterization. However, the relative values are meaningful -- sim_2's 3.3x higher recurrence rate (20.5% vs. 6.1%) indicates more structured, quasi-periodic dynamics even in this simple representation.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#3-deep-analysis","title":"3. Deep Analysis","text":""},{"location":"BETSE_ANALYSIS_REPORT/#31-pca-mode-extraction","title":"3.1 PCA Mode Extraction","text":"<p>Each 64x64 frame was flattened to a 4,096-dimensional vector, centered, and decomposed via SVD. The top 10 singular values and their variance contributions:</p> <p>sim_1 singular values: 2083, 130, 4.7, 0.47, 0.09, 0.008, ... sim_2 singular values: 1021, 67, 11.4, 0.91, 0.07, 0.007, ... physiology singular values: 13412, 1500, 28, 9.3, 0.14, ...</p> Dataset Mode 0 Modes 0+1 Modes 0+1+2 Effective Rank sim_1 99.61% 100.00% 100.00% 2 sim_2 99.55% 99.99% 100.00% 2 physiology 98.76% 100.00% 100.00% 2 <p>Finding: All three datasets are effectively rank-2. The entire spatiotemporal field evolution can be approximated as:</p> <pre><code>V(x, y, t) ~ V_mean(x, y) + c_1(t) * phi_1(x, y) + c_2(t) * phi_2(x, y)\n</code></pre> <p>where phi_1 and phi_2 are fixed spatial modes and only the two time-varying coefficients c_1(t), c_2(t) change. This is a profound dimensionality reduction: from 4,096 dimensions per frame to 2 effective degrees of freedom.</p> <p>Implications: - The tissue's voltage field has a dominant \"breathing mode\" (phi_1) that accounts for ~99% of dynamics, with a secondary perturbation mode (phi_2). - Attractor analysis should operate in this 2D coefficient space, not in higher dimensions. - This explains why all Lyapunov analyses saturated -- we were embedding a 2D trajectory in 3D or 10D space, producing spurious positive exponents in the empty dimensions. - The patterns configuration (pattern formation with gap junctions) is expected to break this rank-2 structure by introducing spatial modes that compete.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#32-lyapunov-spectrum-10d-pca-trajectory","title":"3.2 Lyapunov Spectrum (10D PCA Trajectory)","text":"<p>As predicted by the rank-2 finding, the 10D PCA Lyapunov spectrum is fully positive for all datasets:</p> Dataset Lambda_max Lambda_min All Positive? D_KY sim_1 +15.02 +10.20 Yes (10/10) 10.0 sim_2 +15.14 +10.29 Yes (10/10) 10.0 physiology +8.68 +4.95 Yes (10/10) 10.0 <p>The 8 noise-dominated PCA dimensions generate spurious positive exponents. The meaningful Lyapunov information is in the relative magnitudes: physiology has distinctly lower exponents (max 8.68 vs. ~15) consistent with its simpler, fewer-cell dynamics.</p> <p>The Lyapunov analysis is not informative for these rank-2 datasets. Proper characterization requires either: (a) restricting to the 2D PCA subspace and using specialized 2D Lyapunov methods, or (b) analyzing datasets with higher effective rank (e.g., pattern-forming simulations).</p>"},{"location":"BETSE_ANALYSIS_REPORT/#33-recurrence-quantification-analysis-10d-pca","title":"3.3 Recurrence Quantification Analysis (10D PCA)","text":"<p>Despite Lyapunov saturation, recurrence analysis on the PCA trajectory reveals meaningful structure:</p> Metric sim_1 sim_2 physiology Recurrence rate 3.7% 4.0% 10.5% Determinism 0.459 0.462 0.421 Max diagonal line length 99 99 9 Mean diagonal line length 5.8 5.7 3.7 Number of diagonal lines 1,192 1,296 430 <p>Finding: Long quasi-periodic orbits in attractor simulations. Both sim_1 and sim_2 contain diagonal line segments of length 99, meaning the trajectory repeats the same path for 99 consecutive timesteps before diverging. This is strong evidence of quasi-periodic orbiting within an attractor basin. sim_2 has slightly more diagonal lines (1,296 vs. 1,192), consistent with its higher recurrence.</p> <p>Physiology never repeats for more than 9 steps -- its trajectory is a single sweep, not an orbit.</p> <p>Determinism of ~0.46 for all three datasets indicates moderate dynamical structure: roughly half of all recurrence points fall on diagonal lines (indicating deterministic trajectories) rather than being isolated (indicating stochastic returns).</p>"},{"location":"BETSE_ANALYSIS_REPORT/#34-wasserstein-distance-tracking","title":"3.4 Wasserstein Distance Tracking","text":"<p>Persistent homology was computed at 30 evenly-spaced frames per dataset. The Wasserstein-2 distance between consecutive frames' H0 persistence diagrams measures the rate of topological change:</p> Metric sim_1 sim_2 physiology Mean step W-distance 21.88 16.08 4.64 Std of step distances 15.39 13.82 3.37 Max single step 81.18 67.11 11.04 Min single step 5.51 4.01 0.04 Total drift (first-to-last) 32.22 56.83 1.86 Bottleneck (first-to-last) 5.34 2.51 0.86 <p>This is the most discriminating analysis we performed.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#sim_1-oscillatory-topology-with-settling","title":"sim_1: Oscillatory Topology with Settling","text":"<p>sim_1's Wasserstein series over time: <pre><code>t=0-21:    51.4  (large initial reorganization)\nt=21-43:   36.1\nt=43-65:   26.0  (decreasing -- system settling)\nt=65-87:   29.9\nt=87-109:  34.8\n...\nt=502-524:  7.0  (nearly stable)\nt=524-546:  5.5  (minimum)\nt=546-568: 81.2  (sudden burst -- topological catastrophe)\nt=568-590:  7.7  (immediate return to stability)\nt=612-634: 21.3\n</code></pre></p> <p>This is a classic settling-with-intermittent-bursts pattern. The topology reorganizes rapidly at first, then quiets down, but experiences a sudden catastrophic event around t=546-568 (a single-step Wasserstein of 81.2, compared to a baseline of ~7). The bottleneck distance spike of 11.8 at the same timestep confirms a single dominant topological feature underwent a drastic change.</p> <p>Despite high mean step change (21.9), total drift is moderate (32.2), meaning the large changes partially cancel out. sim_1's topology oscillates but doesn't drift far from its starting configuration.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#sim_2-directional-topological-drift","title":"sim_2: Directional Topological Drift","text":"<p>sim_2's Wasserstein series: <pre><code>t=0-21:    51.7  (large initial reorganization, similar to sim_1)\nt=21-43:   22.1\nt=43-65:   20.2  (also decreasing)\n...\nt=371-393:  4.1  (quiet)\nt=393-415:  5.0\nt=415-437:  4.5\n...\nt=546-568: 67.1  (burst -- but smaller than sim_1's 81.2)\nt=612-634: 26.7\n</code></pre></p> <p>sim_2 also settles and also has a late burst, but with a critical difference: total drift is 56.8 vs. sim_1's 32.2. The small, consistent step changes accumulate rather than cancelling. sim_2 is going somewhere topologically -- its persistence diagram at t=634 is almost twice as far from t=0 as sim_1's is.</p> <p>Meanwhile, sim_2's bottleneck maximum is only 4.84 (vs. sim_1's 11.8). No single feature changes catastrophically; instead, many features shift incrementally. sim_2 transforms through distributed, gradual topological evolution.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#physiology-topology-preserving-voltage-excursion","title":"physiology: Topology-Preserving Voltage Excursion","text":"<p>physiology's Wasserstein distances oscillate between 0.04 and 11.0 around a mean of 4.6, with total drift of only 1.9. This tissue undergoes a 56 mV voltage swing (from -23 to -79 mV), but its topology barely changes. The voltage excursion preserves the spatial organization of the field. This is consistent with the physiology config modeling a synchronized ion channel event across a tightly-coupled 7-cell cluster: all cells depolarize and repolarize together, maintaining their relative voltage arrangement.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#35-vae-latent-space-analysis","title":"3.5 VAE Latent-Space Analysis","text":"<p>A convolutional VAE (16-dimensional latent space) was trained on all 1,460 frames from all three datasets jointly, then used to encode each dataset's trajectory into the learned latent manifold.</p> <p>Training: 1,168 train / 292 validation frames, 50 epochs, converged at epoch 47 (loss 21.47). Train/val loss convergence confirmed no overfitting.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#latent-space-positions-two-distinct-attractor-basins","title":"Latent-Space Positions: Two Distinct Attractor Basins","text":"Latent Dim sim_1 mean sim_2 mean physiology mean sim_1 vs sim_2 separation 1 -0.14 -0.96 0.06 0.82 5 0.46 -2.08 0.38 2.54 7 1.03 1.25 -0.08 0.22 12 -1.54 -0.53 -0.14 1.01 <p>sim_1 and sim_2 occupy clearly separated positions in the 16D latent space, with maximum separation of 2.54 units in dimension 5. The VAE has learned to place these two initial conditions in different regions of its generative manifold. This is direct evidence of distinct attractor basins as seen through a learned nonlinear embedding.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#latent-space-spread-narrow-orbits-vs-wide-excursion","title":"Latent-Space Spread: Narrow Orbits vs. Wide Excursion","text":"Latent Dim sim_1 std sim_2 std physiology std 0 0.014 0.018 0.366 4 0.015 0.004 0.590 5 0.155 0.038 1.358 12 0.060 0.018 1.092 <p>The attractor simulations are confined to narrow corridors in latent space (max std = 0.155 for sim_1, 0.038 for sim_2). They orbit tightly around their respective basin centers.</p> <p>Physiology sweeps through a vastly larger region (std up to 1.36 in dim 5, 1.09 in dim 12). The VAE sees the attractor sims as \"staying in place\" and the physiology sim as \"traversing the manifold.\"</p> <p>sim_2 is even more tightly confined than sim_1 (max std 0.038 vs. 0.155), consistent with its higher recurrence rate and more periodic dynamics.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#vae-recurrence-rates","title":"VAE Recurrence Rates","text":"Dataset VAE Recurrence sim_1 5.9% sim_2 7.7% physiology 15.0% <p>Physiology has the highest VAE recurrence despite having the widest spread. This indicates its trajectory passes through certain latent regions multiple times during its large excursion -- consistent with a depolarization-repolarization cycle that returns near its origin.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#4-synthesis","title":"4. Synthesis","text":""},{"location":"BETSE_ANALYSIS_REPORT/#what-the-data-tells-us","title":"What the Data Tells Us","text":""},{"location":"BETSE_ANALYSIS_REPORT/#41-multi-stability-is-real-and-detectable","title":"4.1 Multi-Stability is Real and Detectable","text":"<p>The same BETSE tissue (153-156 cells, identical gap junction coupling) produces qualitatively different dynamics depending on initial conditions:</p> <ul> <li>sim_1 occupies a higher-voltage basin (mean Vmem ~ -40 mV), simplifies topologically over time, and exhibits oscillatory but non-accumulating topological change (Wasserstein drift = 32.2).</li> <li>sim_2 occupies a lower-voltage basin (mean Vmem ~ -58 mV), gains topological complexity over time, and undergoes directed topological drift (Wasserstein drift = 56.8).</li> </ul> <p>Both are detected as distinct by every method: PCA positions, VAE latent means, recurrence structure, topological evolution direction, and Wasserstein distance profiles. This validates Mneme's core design premise -- that field-level attractor states encode information about tissue organization that is not captured by single-cell measurements.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#42-topology-is-more-informative-than-voltage-statistics","title":"4.2 Topology is More Informative Than Voltage Statistics","text":"<p>The mean voltage trajectories of sim_1 and sim_2 are both nearly flat (3.8 mV and 1.3 mV total swing respectively). A naive analysis looking only at voltage statistics would conclude these are boring, near-equilibrium systems. Persistent homology and Wasserstein tracking reveal rich, evolving spatial structure invisible to summary statistics.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#43-rank-2-structure-sets-a-baseline","title":"4.3 Rank-2 Structure Sets a Baseline","text":"<p>The finding that these BETSE fields are effectively rank-2 establishes an important baseline. It means: - The attractor configs model a simple system with one dominant spatial mode and one perturbation mode. - Higher-rank dynamics (more competing spatial modes) are expected in pattern-forming configurations and in biological tissues with heterogeneous channel expression. - The Mneme pipeline is ready for higher-rank data -- the VAE, PCA, and Wasserstein analyses all scale naturally. The Lyapunov analysis needs restriction to the effective rank.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#44-different-methods-reveal-different-structure","title":"4.4 Different Methods Reveal Different Structure","text":"Method Best discriminates Limitation for this data PCA Effective dimensionality, mode structure Fields are rank-2 (ceiling) Lyapunov -- Saturated at embedding dimension Recurrence Orbital structure, periodicity Similar determinism across datasets Wasserstein Rate and direction of topological change Requires dense sampling for events VAE latent space Basin separation, trajectory geometry Lyapunov fails on latent trajectories H0 feature counting First/last comparison Misses oscillatory dynamics <p>Wasserstein distance tracking emerged as the single most informative method for this data, revealing both the oscillatory vs. directional distinction and the topology-preserving nature of the physiology excursion.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#5-limitations-and-caveats","title":"5. Limitations and Caveats","text":"<ol> <li> <p>Initial analysis used scipy fallback TDA. Sections 2-3 (initial analysis, deep analysis of attractor/physiology configs) used the scipy-based persistence computation, which computes H0 (connected components) only. The later patterns analysis (Section 7) and the cross-frame Wasserstein matrix used full GUDHI with H0+H1 support. H1 results are available only for the patterns dataset.</p> </li> <li> <p>Interpolation artifacts. The 153-824 cell positions were interpolated to a 64x64 regular grid using cubic interpolation. This creates smooth inter-cell fields that do not exist in the discrete BETSE model. Topological features near the interpolation boundary should be treated with caution.</p> </li> <li> <p>Lyapunov saturation on rank-2 data. No meaningful Lyapunov exponents or Kaplan-Yorke dimensions were obtained for the attractor/physiology configs due to their rank-2 structure. The patterns config (rank-5) should produce meaningful 5D Lyapunov spectra, though this has not yet been run with rank restriction.</p> </li> <li> <p>Single tissue geometry per condition. The attractor configs share one tissue mesh (153-156 cells), patterns uses a larger elliptical mesh (824 cells), and physiology uses a tiny cluster (7 cells). Generalization to other tissue geometries requires additional simulations.</p> </li> <li> <p>Symbolic regression R-squared is moderate. PySR symbolic regression on the patterns PCA modes produced R-squared values ranging from 0.24 to 0.59. The discovered equations capture qualitative dynamics but are not quantitatively precise -- expected given the complexity of GRN-driven pattern formation.</p> </li> </ol>"},{"location":"BETSE_ANALYSIS_REPORT/#6-next-steps","title":"6. Next Steps","text":"<ol> <li> <p>~~Analyze the patterns configuration.~~ Done -- see Section 7 below. Confirmed higher-rank (5-mode) PCA and massive topological reorganization.</p> </li> <li> <p>~~Install GUDHI.~~ Done -- full H0+H1 persistence computation now available. Used for cross-frame Wasserstein matrix on patterns data.</p> </li> <li> <p>2D Lyapunov analysis. Restrict to the 2-component PCA trajectory for attractor configs and compute proper 2D Lyapunov exponents to determine whether the dynamics are chaotic, quasi-periodic, or convergent.</p> </li> <li> <p>~~Symbolic regression on PCA coefficients.~~ Done -- PySR discovered ODEs for 5 PCA modes of patterns data (R-squared 0.24-0.59). Also ran spatial PDE discovery via <code>discover_field_dynamics()</code>.</p> </li> <li> <p>~~Cross-frame Wasserstein analysis.~~ Done -- computed full 60x60 NxN Wasserstein matrix for patterns data (H0+H1). Saved to <code>results/deep_analysis/wasserstein_cross_matrix_patterns.npz</code>.</p> </li> <li> <p>ECG data comparison. Apply the same pipeline to self-collected AD8232 ECG data to compare biological vs. simulated bioelectric field structure.</p> </li> <li> <p>Parameter sweep experiments. Vary gap junction conductance and ion channel expression in BETSE; track attractor bifurcations using Mneme's Wasserstein and PCA analysis.</p> </li> <li> <p>Per-paper validation. Compare Mneme's topological signatures and Lyapunov values to quantitative results reported in the original BETSE papers.</p> </li> </ol>"},{"location":"BETSE_ANALYSIS_REPORT/#7-patterns-configuration-the-breakthrough-dataset","title":"7. Patterns Configuration -- The Breakthrough Dataset","text":"<p>The patterns simulation completed on AWS on 2026-02-14 (26 minutes runtime) and was re-exported with Vmem CSV output enabled. This dataset is qualitatively different from everything analyzed above and validates key predictions from the earlier analysis.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#71-data-summary","title":"7.1 Data Summary","text":"Property Patterns vs. Attractors vs. Physiology Cells 824 5.3x more (153-156) 118x more (7) Timesteps 119 5.3x fewer (635) 0.6x fewer (190) Vmem range [-69.6, -26.8] mV Narrower than sim_2 Similar magnitude Tissue shape Elliptical Circular Tiny cluster <p>The patterns config simulates a large elliptical tissue (824 cells) with gene regulatory network (GRN)-driven pattern formation. This is the first dataset with enough spatial complexity to potentially produce multi-modal spatial dynamics.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#72-pca-higher-effective-rank-confirmed-prediction","title":"7.2 PCA: Higher Effective Rank (Confirmed Prediction)","text":"<p>This is the result we predicted: pattern formation breaks the rank-2 structure.</p> Mode Patterns Attractors (sim_1) Attractors (sim_2) Physiology 0 81.4% 99.6% 99.6% 98.8% 0+1 93.9% 100.0% 100.0% 100.0% 0+1+2 98.0% 100.0% 100.0% 100.0% 0+1+2+3 99.0% 100.0% 100.0% 100.0% 0+...+4 99.6% 100.0% 100.0% 100.0% Effective rank ~5 ~2 ~2 ~2 <p>The patterns field has 5 significant PCA modes, compared to 2 for all other datasets. Mode 0 captures only 81.4% of variance (vs. 99.5%+ elsewhere), meaning the remaining 18.6% is distributed across at least 4 additional independent spatial modes. This is exactly what pattern formation looks like in PCA: multiple competing spatial modes with similar amplitudes.</p> <p>The singular value spectrum drops gradually (81%, 13%, 4%, 1%, 0.6%) rather than falling off a cliff after mode 1. This indicates a richer, higher-dimensional attractor landscape.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#73-wasserstein-distances-massive-topological-activity","title":"7.3 Wasserstein Distances: Massive Topological Activity","text":"Metric Patterns sim_1 sim_2 Physiology Mean step W-distance 37.23 21.88 16.08 4.64 Std of step distances 25.64 15.39 13.82 3.37 Max single step 90.35 81.18 67.11 11.04 Total drift (first-to-last) 84.08 32.22 56.83 1.86 Bottleneck (first-to-last) 11.56 5.34 2.51 0.86 <p>The patterns simulation has the highest topological change rate across every metric: - Mean Wasserstein 37.2 -- nearly double sim_1's 21.9 and 2.3x sim_2's 16.1 - Total drift 84.1 -- 2.6x sim_1's 32.2 and 1.5x sim_2's 56.8 - Bottleneck 11.6 -- indicating a single dominant topological feature that changed by 11.6 mV in persistence from first to last frame</p> <p>The pattern-forming tissue is undergoing far more topological reorganization than the attractor simulations. And unlike sim_1 (which oscillates) or sim_2 (which drifts gently), patterns is both high-rate AND high-drift: topological changes are large, frequent, and accumulating.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#74-topology-stable-feature-count-changing-feature-identity","title":"7.4 Topology: Stable Feature Count, Changing Feature Identity","text":"Frame H0 Features Max Persistence (mV) first (t=0) 22 40.2 t=24 29 -- middle (t=59) 20 40.2 t=73 24 -- t=98 24 -- last (t=118) 22 38.8 <p>The feature count is relatively stable (20-29, first and last both 22), but the Wasserstein distances are enormous. This means the features are being reorganized, not created or destroyed. Connected components move, merge, split, and reform -- their number stays similar but their identity (birth-death values in persistence diagrams) changes dramatically. This is the signature of active pattern formation: the topology is churning.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#75-recurrence-low-determinism","title":"7.5 Recurrence: Low Determinism","text":"Metric Patterns sim_1 sim_2 Physiology Recurrence rate 12.9% 3.7% 4.0% 10.5% Determinism 0.390 0.459 0.462 0.421 Max diagonal 16 99 99 9 Mean diagonal 5.2 5.8 5.7 3.7 <p>The patterns simulation has the lowest determinism (0.39 vs. 0.46 for attractors) and the shortest maximum diagonal (16 vs. 99). The trajectory never repeats for more than 16 steps -- compared to the 99-step quasi-periodic orbits in the attractor sims. This system is continuously exploring new states rather than orbiting.</p> <p>Combined with the high recurrence rate (12.9%), this indicates a trajectory that frequently returns to similar states (high recurrence) but never follows the same path for long (low determinism, short diagonals). This is consistent with a strange attractor with high-dimensional structure, or with a system undergoing a non-repeating transient through a complex landscape.</p>"},{"location":"BETSE_ANALYSIS_REPORT/#76-implications","title":"7.6 Implications","text":"<p>The patterns dataset confirms every prediction from the earlier analysis:</p> <ol> <li> <p>Higher PCA rank breaks Lyapunov saturation. With 5 effective modes, a 5D PCA trajectory should yield meaningful Lyapunov exponents with genuine negative components. This is the dataset where proper attractor characterization becomes possible.</p> </li> <li> <p>Topological analysis is most informative for pattern-forming tissues. The Wasserstein tracking shows dramatic, accumulating topological reorganization that simple voltage statistics would miss entirely (the voltage range [-69.6, -26.8] is moderate and the mean voltage changes slowly).</p> </li> <li> <p>GRN-driven dynamics produce richer attractor landscapes. The gene regulatory network coupling creates spatial competition between patterns, producing the multi-modal dynamics (5 PCA modes) that gap-junction-only coupling (rank-2) cannot.</p> </li> <li> <p>This is the dataset to focus future analysis on. Symbolic regression on the 5-mode PCA trajectory could reveal the pattern-forming PDEs. VAE interpolation between early and late frames could map the pattern transformation pathway. Cross-frame Wasserstein matrices could identify topological phase transitions.</p> </li> </ol>"},{"location":"BETSE_ANALYSIS_REPORT/#appendix-file-manifest","title":"Appendix: File Manifest","text":"File Contents <code>results/attractors_1_sim1/analysis_results.json</code> Initial analysis of sim_1 <code>results/attractors_1_sim1/betse_field_sequence.npz</code> Interpolated 64x64 field sequence (635 frames) <code>results/attractors_1_sim2/analysis_results.json</code> Initial analysis of sim_2 <code>results/attractors_1_sim2/betse_field_sequence.npz</code> Interpolated 64x64 field sequence (635 frames) <code>results/physiology_sim1/analysis_results.json</code> Initial analysis of physiology <code>results/physiology_sim1/betse_field_sequence.npz</code> Interpolated 64x64 field sequence (190 frames) <code>results/patterns_sim/analysis_results.json</code> Initial analysis of patterns <code>results/patterns_sim/betse_field_sequence.npz</code> Interpolated 64x64 field sequence (119 frames) <code>results/deep_analysis/deep_analysis_results.json</code> Full deep analysis results (PCA, Wasserstein, VAE, recurrence, symbolic regression) <code>results/deep_analysis/wasserstein_cross_matrix_patterns.npz</code> 60x60 H0+H1 Wasserstein distance matrices for patterns <code>scripts/analyze_betse.py</code> Initial analysis script <code>scripts/deep_analysis.py</code> Deep analysis script (PCA, VAE, Wasserstein, symbolic regression) <code>src/mneme/data/betse_loader.py</code> BETSE data loader and interpolation"},{"location":"DATA_ACQUISITION_PLAN/","title":"Bioelectric Data Acquisition Plan","text":"<p>A comprehensive plan for acquiring and analyzing bioelectric time series data to validate Mneme's analysis capabilities before approaching academic collaborators.</p>"},{"location":"DATA_ACQUISITION_PLAN/#part-1-publicly-available-datasets","title":"Part 1: Publicly Available Datasets","text":""},{"location":"DATA_ACQUISITION_PLAN/#tier-1-immediately-available-physionet","title":"Tier 1: Immediately Available (PhysioNet)","text":"<p>PhysioNet (physionet.org) provides free access to research-grade physiological data. All datasets can be downloaded using the <code>wfdb</code> Python library (already installed).</p> Dataset Type Size Sampling Why It's Useful MIT-BIH Arrhythmia ECG 48 records \u00d7 30 min 360 Hz \u2705 Already tested! Classic benchmark MIT-BIH Normal Sinus Rhythm ECG 18 records \u00d7 24 hr 128 Hz Long-term HRV analysis Apnea-ECG ECG + breathing 70 records \u00d7 7-10 hr 100 Hz Sleep state dynamics Sleep-EDF EEG/EOG/EMG 197 records 100 Hz Brain state transitions CHB-MIT Scalp EEG EEG 23 subjects, seizures 256 Hz Epileptic attractor dynamics MIMIC-III Multi-modal ICU &gt;40k patients Varies Complex physiological systems Gait in Aging and Disease Gait dynamics 15 subjects ~300 Hz Motor control attractors <p>Download command: <pre><code>import wfdb\nrecord = wfdb.rdrecord('record_name', pn_dir='database_name')\n</code></pre></p>"},{"location":"DATA_ACQUISITION_PLAN/#tier-2-other-public-repositories","title":"Tier 2: Other Public Repositories","text":"Source Data Type Access OpenNeuro (openneuro.org) EEG, fMRI Free, BIDS format BNCI Horizon 2020 BCI datasets Free registration Kaggle Various competitions Free account UCI ML Repository EEG, ECG classics Direct download Allen Brain Observatory Calcium imaging API access"},{"location":"DATA_ACQUISITION_PLAN/#tier-3-specialized-biological-data","title":"Tier 3: Specialized Biological Data","text":"Dataset Organism Data Type Source C. elegans connectome Nematode Neural activity OpenWorm Drosophila whole-brain Fruit fly Calcium imaging Janelia Zebrafish brain imaging Fish Voltage/calcium Various labs <p>Note: Planarian bioelectric data is NOT readily available in public repositories. This is why validation on other biological systems is important first.</p>"},{"location":"DATA_ACQUISITION_PLAN/#part-2-diy-data-collection-from-yourself","title":"Part 2: DIY Data Collection (From Yourself)","text":""},{"location":"DATA_ACQUISITION_PLAN/#option-a-consumer-eeg-200-500","title":"Option A: Consumer EEG (~$200-500)","text":"<p>Recommended: Muse 2 or Muse S - Price: $250-400 - Channels: 4 EEG + 2 reference - Sampling: 256 Hz - Data access: Via Mind Monitor app \u2192 CSV export - Pros: Easy setup, no expertise needed, comfortable - Cons: Limited channels, consumer-grade</p> <p>What you can measure: - Alpha waves (relaxation) - Beta waves (focus) - Meditation states - Sleep stages (Muse S)</p> <p>Analysis potential: <pre><code># Example: Analyze your own meditation data\nfrom mneme.core import compute_lyapunov_spectrum\nimport numpy as np\n\n# Load exported CSV from Mind Monitor\neeg_data = np.loadtxt('my_meditation_session.csv', delimiter=',')\n\n# Compute Lyapunov spectrum for each channel\nfor channel in range(4):\n    spectrum = compute_lyapunov_spectrum(eeg_data[:, channel], dt=1/256)\n    print(f\"Channel {channel}: \u03bb\u2081 = {spectrum[0]:.4f}\")\n</code></pre></p>"},{"location":"DATA_ACQUISITION_PLAN/#option-b-research-grade-eeg-500-2000","title":"Option B: Research-Grade EEG (~$500-2000)","text":"<p>OpenBCI Cyton Board - Price: $500 (8-channel) to $950 (16-channel) - Channels: 8-16 EEG - Sampling: Up to 250 Hz (can be modified) - Data access: Direct streaming, full raw data - Pros: Research-grade, open-source, customizable - Cons: Requires setup expertise, electrode gel</p> <p>OpenBCI Ganglion - Price: $200 - Channels: 4 - Good for: EMG, ECG, simple EEG</p>"},{"location":"DATA_ACQUISITION_PLAN/#option-c-simple-bioelectric-sensors-20-100","title":"Option C: Simple Bioelectric Sensors (~$20-100)","text":"<p>Arduino + AD8232 (ECG) - Price: ~$25 total - What you need:   - Arduino Uno (~$15)   - AD8232 ECG module (~$10)   - 3 electrode pads (~$5) - Sampling: Up to 500 Hz - Quality: Surprisingly good for research</p> <p>Pulse Sensor (PPG) - Price: ~$25 - Measures: Heart rate via optical sensing - Use: HRV analysis without electrodes</p> <p>GSR/EDA Sensor - Price: ~$15-30 - Measures: Skin conductance (stress, arousal) - Use: Autonomic nervous system dynamics</p>"},{"location":"DATA_ACQUISITION_PLAN/#option-d-combined-approach-recommended","title":"Option D: Combined Approach (Recommended)","text":"<p>Starter Kit (~$100): 1. Arduino Uno R3 ($15) 2. AD8232 ECG sensor ($10) 3. Pulse sensor ($25) 4. GSR sensor ($15) 5. Electrodes &amp; leads ($15) 6. Breadboard &amp; wires ($10)</p> <p>This gives you: - ECG (heart electrical activity) - PPG (heart rate via light) - GSR (skin conductance/stress)</p> <p>All can be analyzed with Lyapunov spectrum!</p>"},{"location":"DATA_ACQUISITION_PLAN/#part-3-hardware-comparison-matrix","title":"Part 3: Hardware Comparison Matrix","text":"Device Price Channels Sample Rate Ease of Use Data Quality Best For Muse 2 $250 4 EEG 256 Hz \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 Quick EEG experiments OpenBCI Cyton $500 8 EEG 250 Hz \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Serious research Arduino ECG $25 1 ECG 500 Hz \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 HRV analysis Polar H10 $90 1 ECG 130 Hz \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Long-term HRV BITalino $200 Multi 1000 Hz \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Education/research"},{"location":"DATA_ACQUISITION_PLAN/#part-4-recommended-analysis-pipeline","title":"Part 4: Recommended Analysis Pipeline","text":""},{"location":"DATA_ACQUISITION_PLAN/#phase-1-public-data-validation-week-1-2","title":"Phase 1: Public Data Validation (Week 1-2)","text":"<pre><code># Download and analyze multiple PhysioNet datasets\npython -c \"\nimport wfdb\nfrom mneme.core import compute_lyapunov_spectrum, kaplan_yorke_dimension\n\n# 1. Sleep EEG - brain state transitions\nrecord = wfdb.rdrecord('slp01a', pn_dir='slpdb', sampto=100000)\n# Analyze...\n\n# 2. Gait dynamics - motor control\nrecord = wfdb.rdrecord('ga02', pn_dir='gaitdb')\n# Analyze...\n\n# 3. More ECG for HRV benchmarking\nrecord = wfdb.rdrecord('16265', pn_dir='nsrdb', sampto=100000)\n# Analyze...\n\"\n</code></pre> <p>Goal: Build a table of Lyapunov spectra across different physiological systems.</p>"},{"location":"DATA_ACQUISITION_PLAN/#phase-2-own-body-data-week-3-4","title":"Phase 2: Own Body Data (Week 3-4)","text":"<p>Experiment ideas: 1. Resting vs. Active HRV - Record ECG during rest, then during mental arithmetic 2. Meditation dynamics - Track EEG changes during meditation session 3. Sleep transitions - Record overnight data, analyze state changes 4. Stress response - GSR during calm vs. stressful tasks</p>"},{"location":"DATA_ACQUISITION_PLAN/#phase-3-cross-system-comparison-week-5","title":"Phase 3: Cross-System Comparison (Week 5+)","text":"System Expected \u03bb\u2081 Expected D_KY Attractor Type Resting HRV +0.1 to +0.2 2-3 Strange Active HRV Higher? Higher? Strange Sleep EEG State-dependent Varies by stage Multiple Meditation Lower chaos? Lower dimension? ?"},{"location":"DATA_ACQUISITION_PLAN/#part-5-concrete-next-steps","title":"Part 5: Concrete Next Steps","text":""},{"location":"DATA_ACQUISITION_PLAN/#immediate-today","title":"Immediate (Today)","text":"<ol> <li>\u2705 PhysioNet ECG analyzed (already done!)</li> <li>Download 2-3 more PhysioNet datasets</li> <li>Run Lyapunov analysis on each</li> <li>Compare results to published literature</li> </ol>"},{"location":"DATA_ACQUISITION_PLAN/#short-term-this-week","title":"Short-term (This Week)","text":"<ol> <li>Download Sleep-EDF dataset</li> <li>Analyze EEG state transitions</li> <li>Download gait dynamics data</li> <li>Build comparison table</li> </ol>"},{"location":"DATA_ACQUISITION_PLAN/#medium-term-this-month","title":"Medium-term (This Month)","text":"<p>If you want to collect your own data:</p> <p>Budget Option ($50): - Arduino + AD8232 ECG kit - Record your own HRV during different activities - Compare to PhysioNet benchmarks</p> <p>Better Option ($250): - Muse 2 headband - Record EEG during meditation/focus/rest - Analyze brain state dynamics</p> <p>Research Option ($500+): - OpenBCI Cyton - Full research-grade EEG/ECG/EMG capability - Publication-quality data</p>"},{"location":"DATA_ACQUISITION_PLAN/#part-6-what-this-proves-to-academics","title":"Part 6: What This Proves to Academics","text":"<p>When you approach the Levin Lab or other researchers, you can say:</p> <p>\"I've built a Lyapunov spectrum analysis pipeline and validated it on: - PhysioNet ECG data (HRV chaos matches literature) - Sleep EEG data (state transitions detected) - My own bioelectric recordings</p> <p>I'd like to apply these same methods to planarian bioelectric data to characterize attractor dynamics during regeneration.\"</p> <p>This demonstrates: 1. Working tools - not just theory 2. Validation - results match known literature 3. Personal investment - you've recorded your own data 4. Clear application - specific hypothesis for their data</p>"},{"location":"DATA_ACQUISITION_PLAN/#appendix-python-code-for-multi-dataset-analysis","title":"Appendix: Python Code for Multi-Dataset Analysis","text":"<pre><code>\"\"\"\nComprehensive bioelectric analysis script.\nRun on multiple PhysioNet datasets to build validation table.\n\"\"\"\n\nimport numpy as np\nimport wfdb\nfrom mneme.core import compute_lyapunov_spectrum, kaplan_yorke_dimension\nfrom mneme.core.attractors import classify_attractor_by_lyapunov, embed_trajectory\n\nDATASETS = [\n    ('100', 'mitdb', 'ECG Arrhythmia'),\n    ('slp01a', 'slpdb', 'Sleep Polysomnography'),\n    ('ga02', 'gaitdb', 'Gait Dynamics'),\n    ('chf01', 'chfdb', 'Congestive Heart Failure'),\n]\n\nresults = []\n\nfor record_name, db_name, description in DATASETS:\n    try:\n        record = wfdb.rdrecord(record_name, pn_dir=db_name, sampto=50000)\n        signal = record.p_signal[:, 0]\n        fs = record.fs\n\n        # Embed and analyze\n        trajectory = embed_trajectory(signal, embedding_dimension=4, time_delay=int(fs/10))\n        spectrum = compute_lyapunov_spectrum(trajectory, dt=1/fs)\n\n        results.append({\n            'dataset': description,\n            'lambda_1': spectrum[0],\n            'd_ky': kaplan_yorke_dimension(spectrum),\n            'type': classify_attractor_by_lyapunov(spectrum)\n        })\n        print(f\"\u2713 {description}: \u03bb\u2081={spectrum[0]:.4f}, D_KY={kaplan_yorke_dimension(spectrum):.2f}\")\n    except Exception as e:\n        print(f\"\u2717 {description}: {e}\")\n</code></pre>"},{"location":"DATA_ACQUISITION_PLAN/#summary","title":"Summary","text":"Phase Data Source Cost Time Value Validation PhysioNet Free 1 week Proves methods work Expansion OpenNeuro, etc. Free 2 weeks Broader validation Personal Arduino ECG $50 1 week Hands-on experience Advanced Muse/OpenBCI $250-500 2 weeks Publication-ready data <p>Recommended path: Start with PhysioNet (free), then Arduino ECG ($50), then approach academics with validated results.</p>"},{"location":"DATA_PIPELINE/","title":"Mneme Data Pipeline Documentation","text":"<p>Accuracy note (MVP): The quality checker, a basic parallel pipeline helper, and lightweight monitoring utilities now exist in <code>src/</code> (see <code>mneme.data.validation/quality</code>, <code>mneme.data.parallel</code>, <code>mneme.utils.monitoring</code>). The feature extractor and recovery/checkpointing remain roadmap examples.</p>"},{"location":"DATA_PIPELINE/#overview","title":"Overview","text":"<p>The Mneme data pipeline handles the flow of data from raw bioelectric measurements and synthetic generation through preprocessing, analysis, and final results. The pipeline is designed to be modular, reproducible, and scalable.</p>"},{"location":"DATA_PIPELINE/#data-flow-architecture","title":"Data Flow Architecture","text":"<pre><code>Raw Data Sources          Preprocessing           Analysis              Results\n================          =============           ========              =======\n\nBioelectric Images   --&gt;  Denoising          --&gt;  Field               --&gt; Attractor\nVoltage Maps        --&gt;  Registration       --&gt;  Reconstruction      --&gt; Patterns\nGene Expression     --&gt;  Normalization      --&gt;  Topology Analysis   --&gt; \nSynthetic Fields    --&gt;  Interpolation      --&gt;  Symbolic Regression --&gt; Reports\n                         Augmentation           Autoencoding          Visualizations\n</code></pre>"},{"location":"DATA_PIPELINE/#data-formats-and-standards","title":"Data Formats and Standards","text":""},{"location":"DATA_PIPELINE/#1-raw-data-formats","title":"1. Raw Data Formats","text":""},{"location":"DATA_PIPELINE/#bioelectric-imaging-data","title":"Bioelectric Imaging Data","text":"<pre><code># Standard format: HDF5 with structured metadata\n{\n    'voltage_fields': np.ndarray,  # Shape: (time, height, width)\n    'timestamps': np.ndarray,      # Shape: (time,)\n    'metadata': {\n        'specimen_id': str,\n        'experiment_date': str,\n        'sampling_rate_hz': float,\n        'voltage_unit': str,\n        'spatial_resolution_mm': float,\n        'experimental_conditions': dict\n    }\n}\n</code></pre>"},{"location":"DATA_PIPELINE/#gene-expression-data","title":"Gene Expression Data","text":"<pre><code># Format: Spatial expression matrices\n{\n    'expression_matrix': np.ndarray,  # Shape: (genes, spatial_points)\n    'gene_names': List[str],\n    'spatial_coordinates': np.ndarray,  # Shape: (spatial_points, 2)\n    'time_point': float\n}\n</code></pre>"},{"location":"DATA_PIPELINE/#2-processed-data-format","title":"2. Processed Data Format","text":"<pre><code># Standardized processed data structure\nclass ProcessedField:\n    data: np.ndarray           # Normalized field values\n    mask: np.ndarray          # Valid data mask\n    coordinates: np.ndarray   # Spatial coordinates\n    timestamp: float          # Time point\n    metadata: Dict[str, Any]  # Processing metadata\n\n    def to_hdf5(self, path: str): ...\n    def from_hdf5(cls, path: str): ...\n</code></pre>"},{"location":"DATA_PIPELINE/#pipeline-stages","title":"Pipeline Stages","text":""},{"location":"DATA_PIPELINE/#stage-1-data-ingestion","title":"Stage 1: Data Ingestion","text":"<pre><code>from mneme.data import loaders\n\n# Bioelectric data loader\nloader = loaders.BioelectricLoader(\n    data_dir=\"data/raw/planarian/\",\n    file_pattern=\"*.h5\",\n    lazy_load=True  # Load data on demand\n)\n\n# Iterate through experiments\nfor experiment in loader:\n    voltage_field = experiment.voltage_field\n    metadata = experiment.metadata\n</code></pre>"},{"location":"DATA_PIPELINE/#stage-2-quality-control-roadmap","title":"Stage 2: Quality Control (roadmap)","text":"<pre><code>from mneme.data import quality\n\n# Quality assessment\nqc = quality.QualityChecker()\nreport = qc.check_field(voltage_field)\n\n# Check for:\n# - Missing values\n# - Outliers\n# - Signal-to-noise ratio\n# - Spatial resolution adequacy\n\nif report.passed:\n    processed_field = preprocess(voltage_field)\nelse:\n    logger.warning(f\"Quality check failed: {report.issues}\")\n</code></pre>"},{"location":"DATA_PIPELINE/#stage-3-preprocessing","title":"Stage 3: Preprocessing","text":"<pre><code>from mneme.data import preprocessors\n\n# Create preprocessing pipeline\npreprocessor = preprocessors.FieldPreprocessor([\n    preprocessors.Denoiser(method='wavelet', threshold='soft'),\n    preprocessors.Registrator(reference='first_frame'),\n    preprocessors.Normalizer(method='z_score', per_frame=True),\n    preprocessors.Interpolator(target_resolution=(256, 256))\n])\n\n# Apply preprocessing\nprocessed = preprocessor.fit_transform(voltage_field)\n</code></pre>"},{"location":"DATA_PIPELINE/#preprocessing-steps","title":"Preprocessing Steps:","text":"<ol> <li>Denoising</li> <li>Wavelet denoising for preserving edges</li> <li>Gaussian filtering for smooth fields</li> <li> <p>Median filtering for impulse noise</p> </li> <li> <p>Registration</p> </li> <li>Align temporal sequences</li> <li>Correct for specimen movement</li> <li> <p>Maintain spatial correspondence</p> </li> <li> <p>Normalization</p> </li> <li>Z-score normalization</li> <li>Min-max scaling</li> <li> <p>Histogram equalization</p> </li> <li> <p>Interpolation</p> </li> <li>Bicubic interpolation for upsampling</li> <li>Gaussian process interpolation for missing data</li> </ol>"},{"location":"DATA_PIPELINE/#stage-4-feature-extraction-roadmap","title":"Stage 4: Feature Extraction (roadmap)","text":"<pre><code>from mneme.analysis import features\n\n# Extract multi-scale features\nextractor = features.FieldFeatureExtractor()\nfeature_dict = extractor.extract(processed_field)\n\n# Features include:\n# - Spatial gradients\n# - Laplacian values\n# - Local curvature\n# - Texture descriptors\n# - Frequency components\n</code></pre>"},{"location":"DATA_PIPELINE/#stage-5-core-analysis","title":"Stage 5: Core Analysis","text":"<pre><code>from mneme.core import field_theory, topology\nfrom mneme.models import autoencoders\n\n# 1. Field reconstruction\nreconstructor = field_theory.FieldReconstructor(method='ift')\ncontinuous_field = reconstructor.fit_reconstruct(processed_field)\n\n# 2. Topology analysis\n# Cubical for 2D fields (default), or use Rips/Alpha with adapter\ntda = topology.PersistentHomology()\npersistence_diagrams = tda.compute_persistence(continuous_field)\n\n# Point-cloud backends\npc = topology.field_to_point_cloud(continuous_field, method='peaks', percentile=95.0)\nrips = topology.RipsComplex(max_dimension=1)\nrips_diagrams = rips.compute_persistence(pc)\n\n# 3. Latent space embedding\nautoencoder = autoencoders.FieldAutoencoder(latent_dim=32)\nlatent_representation = autoencoder.encode(continuous_field)\n\n# 4. Attractor detection (recurrence default; lyapunov/clustering also available)\ndetector = topology.AttractorDetector(method='recurrence')\nattractors = detector.detect(latent_trajectory)\n</code></pre>"},{"location":"DATA_PIPELINE/#stage-6-results-generation-roadmap","title":"Stage 6: Results Generation (roadmap)","text":"<pre><code>from mneme.analysis import results\n\n# Generate comprehensive results\nresult_generator = results.ResultGenerator()\nresults = result_generator.compile({\n    'raw_data': voltage_field,\n    'processed_data': processed_field,\n    'reconstruction': continuous_field,\n    'topology': persistence_diagrams,\n    'attractors': attractors,\n    'latent_space': latent_representation\n})\n\n# Save results\nresults.save(\"experiments/results/exp_001/\")\n</code></pre>"},{"location":"DATA_PIPELINE/#data-pipeline-configuration","title":"Data Pipeline Configuration","text":""},{"location":"DATA_PIPELINE/#configuration-file-configpipelineyaml","title":"Configuration File (<code>config/pipeline.yaml</code>)","text":"<pre><code>pipeline:\n  name: \"standard_bioelectric_pipeline\"\n  version: \"1.0\"\n\n  stages:\n    ingestion:\n      loader: \"BioelectricLoader\"\n      params:\n        lazy_load: true\n        cache_size: \"2GB\"\n\n    quality_control:\n      checks:\n        - missing_values\n        - outlier_detection\n        - snr_threshold: 10.0\n\n    preprocessing:\n      steps:\n        - name: \"denoise\"\n          method: \"wavelet\"\n          params:\n            wavelet: \"db4\"\n            level: 3\n\n        - name: \"normalize\"\n          method: \"z_score\"\n          params:\n            per_frame: true\n\n        - name: \"interpolate\"\n          method: \"bicubic\"\n          params:\n            target_shape: [256, 256]\n\n    analysis:\n      field_reconstruction:\n        method: \"ift\"\n        resolution: [512, 512]\n\n      topology:\n        max_dimension: 2\n        filtration: \"sublevel\"\n\n      attractors:\n        method: \"recurrence\"\n        threshold: 0.1\n\n  output:\n    format: \"hdf5\"\n    compression: \"gzip\"\n    save_intermediate: true\n</code></pre>"},{"location":"DATA_PIPELINE/#running-the-pipeline","title":"Running the Pipeline","text":"<pre><code>from mneme.analysis import pipeline\n\n# Load configuration\nconfig = pipeline.load_config(\"config/pipeline.yaml\")\n\n# Create pipeline\npipe = pipeline.DataPipeline(config)\n\n# Run on single dataset\nresults = pipe.run(\"data/raw/experiment_001.h5\")\n\n# Batch processing\nresults = pipe.run_batch(\n    input_pattern=\"data/raw/*.h5\",\n    output_dir=\"results/\",\n    parallel=True,\n    n_workers=4\n)\n</code></pre>"},{"location":"DATA_PIPELINE/#parallel-processing-mvp","title":"Parallel Processing (MVP)","text":"<pre><code>from mneme.data import parallel\n\n# Parallel pipeline for large datasets\nparallel_pipeline = parallel.ParallelPipeline(\n    pipeline=pipe,\n    backend='multiprocessing',  # MVP\n    n_workers=8\n)\n\n# Process multiple files\nresults = parallel_pipeline.map(file_list)\n</code></pre>"},{"location":"DATA_PIPELINE/#data-validation","title":"Data Validation","text":"<pre><code>from mneme.data import validation\n\n# Define validation schema\nschema = validation.FieldDataSchema(\n    shape=(None, 256, 256),  # Time dimension can vary\n    dtype=np.float32,\n    value_range=(-100, 100),  # mV\n    required_metadata=['specimen_id', 'timestamp']\n)\n\n# Validate data\nvalidator = validation.DataValidator(schema)\nis_valid, errors = validator.validate(data)\n</code></pre>"},{"location":"DATA_PIPELINE/#caching-and-optimization","title":"Caching and Optimization","text":"<pre><code>from mneme.data import cache\n\n# Enable caching for expensive operations\n@cache.memoize(cache_dir=\"cache/preprocessing/\")\ndef expensive_preprocessing(field):\n    return heavy_computation(field)\n\n# LRU cache for frequent access\nfield_cache = cache.FieldCache(max_size=\"10GB\")\nfield_cache.put(\"exp_001\", processed_field)\n</code></pre>"},{"location":"DATA_PIPELINE/#monitoring-and-logging-mvp","title":"Monitoring and Logging (MVP)","text":"<pre><code>from mneme.utils import monitoring\n\n# Pipeline monitoring\nmonitor = monitoring.PipelineMonitor()\nmonitor.start()\n\nwith monitor.track_stage(\"preprocessing\"):\n    processed = preprocessor.transform(data)\n\n# Get performance metrics\nmetrics = monitor.get_metrics()\nprint(f\"Preprocessing durations: {metrics['stage_durations_s']}\")\n</code></pre>"},{"location":"DATA_PIPELINE/#error-handling-and-recovery-roadmap","title":"Error Handling and Recovery (roadmap)","text":"<pre><code>from mneme.data import recovery\n\n# Checkpoint-based recovery\npipeline_with_checkpoints = pipeline.DataPipeline(\n    config=config,\n    checkpoint_dir=\"checkpoints/\",\n    checkpoint_frequency=10  # Every 10 samples\n)\n\ntry:\n    results = pipeline_with_checkpoints.run(data)\nexcept Exception as e:\n    # Resume from last checkpoint\n    results = pipeline_with_checkpoints.resume()\n</code></pre>"},{"location":"DATA_PIPELINE/#best-practices","title":"Best Practices","text":"<ol> <li>Data Versioning: Track data and pipeline versions</li> <li>Reproducibility: Set random seeds, log parameters</li> <li>Validation: Validate data at each stage</li> <li>Documentation: Document data sources and transformations</li> <li>Testing: Unit test each pipeline component</li> <li>Monitoring: Track performance and resource usage</li> <li>Error Handling: Implement graceful failure and recovery</li> </ol>"},{"location":"DEVELOPMENT_SETUP/","title":"Mneme Development Setup Guide","text":""},{"location":"DEVELOPMENT_SETUP/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12.3 (tested and working)</li> <li>Git</li> <li>Virtual environment tool (venv recommended)</li> <li>CUDA-capable GPU (optional, for deep learning models)</li> <li>WSL2 environment (if on Windows)</li> </ul>"},{"location":"DEVELOPMENT_SETUP/#initial-setup","title":"Initial Setup","text":""},{"location":"DEVELOPMENT_SETUP/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/mneme.git\ncd mneme\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code># Using venv\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Or using conda\nconda create -n mneme python=3.9\nconda activate mneme\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Core dependencies\npip install -r requirements.txt\n\n# Development dependencies (includes testing and linting tools)\npip install -r requirements-dev.txt\n\n# Install package in development mode\npip install -e .\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#dependencies-overview","title":"Dependencies Overview","text":""},{"location":"DEVELOPMENT_SETUP/#core-scientific-libraries","title":"Core Scientific Libraries","text":"<pre><code>numpy&gt;=1.21.0\nscipy&gt;=1.7.0\npandas&gt;=1.3.0\nmatplotlib&gt;=3.4.0\nseaborn&gt;=0.11.0\nscikit-learn&gt;=0.24.0\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#deep-learning","title":"Deep Learning","text":"<pre><code>torch&gt;=2.0.0\ntorchvision&gt;=0.15.0\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#specialized-tools","title":"Specialized Tools","text":"<pre><code>pysr&gt;=0.6.0              # Symbolic regression\ngudhi&gt;=3.4.0             # Topological data analysis\nnifty&gt;=0.1.0             # Information field theory\nscikit-image&gt;=0.18.0     # Image processing\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#development-tools","title":"Development Tools","text":"<pre><code>pytest&gt;=6.2.0\npytest-cov&gt;=2.12.0\nblack&gt;=21.6b0\nflake8&gt;=3.9.0\nmypy&gt;=0.910\njupyter&gt;=1.0.0\nipykernel&gt;=6.0.0\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#environment-configuration","title":"Environment Configuration","text":""},{"location":"DEVELOPMENT_SETUP/#1-create-configuration-file","title":"1. Create Configuration File","text":"<p>Create <code>config/development.yaml</code>:</p> <pre><code># Development configuration\ndata:\n  raw_path: ./data/raw\n  processed_path: ./data/processed\n  synthetic_path: ./data/synthetic\n\nexperiments:\n  output_dir: ./experiments/results\n  log_level: DEBUG\n  random_seed: 42\n\ncompute:\n  device: auto  # 'cuda', 'cpu', or 'auto'\n  num_workers: 4\n  batch_size: 32\n\nvisualization:\n  backend: matplotlib\n  dpi: 300\n  save_format: png\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#2-set-environment-variables","title":"2. Set Environment Variables","text":"<p>Create <code>.env</code> file in project root:</p> <pre><code># Environment variables\nMNEME_CONFIG_PATH=./config/development.yaml\nMNEME_LOG_LEVEL=DEBUG\nPYTHONPATH=\"${PYTHONPATH}:${PWD}/src\"\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#verify-installation","title":"Verify Installation","text":""},{"location":"DEVELOPMENT_SETUP/#1-run-test-suite","title":"1. Run Test Suite","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=mneme --cov-report=html\n\n# Run specific test module\npytest tests/unit/test_field_theory.py\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#2-check-imports","title":"2. Check Imports","text":"<pre><code># In Python interpreter or notebook\nimport mneme\nfrom mneme.core import field_theory\nfrom mneme.data import generators\nfrom mneme.models import autoencoders\n\nprint(f\"Mneme version: {mneme.__version__}\")\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#3-run-example-script","title":"3. Run Example Script","text":"<pre><code># Generate synthetic data\npython src/scripts/generate_synthetic.py --size 100 --noise 0.1\n\n# Run basic pipeline\npython src/scripts/run_pipeline.py --config config/development.yaml\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#development-tools-setup","title":"Development Tools Setup","text":""},{"location":"DEVELOPMENT_SETUP/#1-code-formatting","title":"1. Code Formatting","text":"<pre><code># Format code with black\nblack src/ tests/\n\n# Check without modifying\nblack --check src/ tests/\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#2-linting","title":"2. Linting","text":"<pre><code># Run flake8\nflake8 src/ tests/\n\n# Run mypy for type checking\nmypy src/\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#3-pre-commit-hooks","title":"3. Pre-commit Hooks","text":"<p>Create <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: 21.6b0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/flake8\n    rev: 3.9.2\n    hooks:\n      - id: flake8\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v0.910\n    hooks:\n      - id: mypy\n</code></pre> <p>Install hooks: <pre><code>pip install pre-commit\npre-commit install\n</code></pre></p>"},{"location":"DEVELOPMENT_SETUP/#jupyter-notebook-setup","title":"Jupyter Notebook Setup","text":"<pre><code># Install kernel for virtual environment\npython -m ipykernel install --user --name mneme --display-name \"Mneme\"\n\n# Start Jupyter\njupyter notebook\n\n# Or JupyterLab\njupyter lab\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#gpu-setup-optional","title":"GPU Setup (Optional)","text":""},{"location":"DEVELOPMENT_SETUP/#for-nvidia-gpus","title":"For NVIDIA GPUs:","text":"<ol> <li>Install CUDA Toolkit (11.3 or higher)</li> <li>Install cuDNN</li> <li>Install PyTorch with CUDA support:</li> </ol> <pre><code>pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#verify-gpu","title":"Verify GPU:","text":"<pre><code>import torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n</code></pre>"},{"location":"DEVELOPMENT_SETUP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DEVELOPMENT_SETUP/#common-issues","title":"Common Issues:","text":"<ol> <li>Import errors: Ensure <code>PYTHONPATH</code> includes <code>src/</code> directory</li> <li>GUDHI installation: May require C++ compiler on some systems</li> <li>PySR installation: Requires Julia, follow PySR docs</li> <li>Memory issues: Reduce batch size in configuration</li> </ol>"},{"location":"DEVELOPMENT_SETUP/#getting-help","title":"Getting Help:","text":"<ul> <li>Check existing issues on GitHub</li> <li>Consult documentation in <code>docs/</code></li> <li>Run tests to identify specific problems</li> </ul>"},{"location":"PROJECT_STRUCTURE/","title":"Mneme Project Structure","text":""},{"location":"PROJECT_STRUCTURE/#directory-layout","title":"Directory Layout","text":"<pre><code>mneme/\n\u251c\u2500\u2500 docs/                      # Project documentation\n\u2502   \u251c\u2500\u2500 PROJECT_STRUCTURE.md   # This file\n\u2502   \u251c\u2500\u2500 DEVELOPMENT_SETUP.md   # Setup and installation guide\n\u2502   \u251c\u2500\u2500 API_DESIGN.md          # Module and API documentation\n\u2502   \u251c\u2500\u2500 DATA_PIPELINE.md       # Data processing pipeline docs\n\u2502   \u2514\u2500\u2500 TESTING_STRATEGY.md    # Testing approach and guidelines\n\u2502\n\u251c\u2500\u2500 src/                       # Source code\n\u2502   \u251c\u2500\u2500 mneme/                 # Main package\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 core/              # Core functionality\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 field_theory.py    # IFT implementations\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 topology.py        # TDA algorithms\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 attractors.py      # Attractor detection\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 models/            # ML models (MVP)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 autoencoders.py    # Placeholder FieldAutoencoder\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 symbolic.py         # Placeholder SymbolicRegressor\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 data/              # Data handling\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 loaders.py         # Data loading utilities\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 generators.py      # Synthetic data generation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 preprocessors.py   # Data preprocessing\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 bioelectric.py     # Bioelectric data handling\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u251c\u2500\u2500 analysis/          # Analysis modules\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pipeline.py        # Main analysis pipeline\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 visualization.py   # Plotting and visualization\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 features.py        # Basic field feature extraction (MVP)\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 metrics.py         # Evaluation metrics\n\u2502   \u2502   \u2502\n\u2502   \u2502   \u2514\u2500\u2500 utils/             # Utilities\n\u2502   \u2502       \u251c\u2500\u2500 __init__.py\n\u2502   \u2502       \u251c\u2500\u2500 config.py          # Configuration management\n\u2502   \u2502       \u251c\u2500\u2500 logging.py         # Logging setup\n\u2502   \u2502       \u2514\u2500\u2500 io.py              # I/O utilities\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 scripts/               # Executable scripts (legacy; use CLI)\n\u2502       \u251c\u2500\u2500 generate_synthetic.py\n\u2502       \u251c\u2500\u2500 run_pipeline.py\n\u2502       \u2514\u2500\u2500 visualize_results.py\n\u2502\n\u251c\u2500\u2500 notebooks/                 # Jupyter notebooks (MVP: one demo)\n\u2502   \u2514\u2500\u2500 01_demo.ipynb\n\u2502\n\u251c\u2500\u2500 tests/                     # Test suite\n\u2502   \u251c\u2500\u2500 unit/                  # Unit tests\n\u2502   \u2502   \u251c\u2500\u2500 test_field_theory.py\n\u2502   \u2502   \u251c\u2500\u2500 test_topology.py\n\u2502   \u2502   \u2514\u2500\u2500 test_data_loaders.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 integration/           # Integration tests\n\u2502   \u2502   \u2514\u2500\u2500 test_pipeline.py\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 fixtures/              # Test data\n\u2502       \u2514\u2500\u2500 synthetic_test_data.npz\n\u2502\n\u251c\u2500\u2500 data/                      # Data directory\n\u2502   \u251c\u2500\u2500 raw/                   # Raw data (gitignored)\n\u2502   \u251c\u2500\u2500 processed/             # Processed data (gitignored)\n\u2502   \u2514\u2500\u2500 synthetic/             # Generated synthetic data\n\u2502\n\u251c\u2500\u2500 experiments/               # Experiment tracking\n\u2502   \u251c\u2500\u2500 configs/               # Experiment configurations\n\u2502   \u2514\u2500\u2500 results/               # Experiment results (gitignored)\n\u2502\n\u251c\u2500\u2500 requirements.txt           # Python dependencies\n\u251c\u2500\u2500 requirements-dev.txt       # Development dependencies\n\u251c\u2500\u2500 setup.py                   # Package setup\n\u251c\u2500\u2500 .gitignore                # Git ignore file\n\u251c\u2500\u2500 README.md                  # Project README\n\u251c\u2500\u2500 CLAUDE.md                  # Claude Code guidance\n\u2514\u2500\u2500 LICENSE                    # License file\n</code></pre>"},{"location":"PROJECT_STRUCTURE/#module-responsibilities","title":"Module Responsibilities","text":""},{"location":"PROJECT_STRUCTURE/#core-modules-srcmnemecore","title":"Core Modules (<code>src/mneme/core/</code>)","text":"<ul> <li>field_theory.py: Information Field Theory implementations for continuous field reconstruction</li> <li>topology.py: Topological Data Analysis algorithms for persistent structure identification</li> <li>attractors.py: Attractor detection and characterization methods</li> </ul>"},{"location":"PROJECT_STRUCTURE/#model-modules-srcmnememodels","title":"Model Modules (<code>src/mneme/models/</code>)","text":"<ul> <li>autoencoders.py: Placeholder <code>FieldAutoencoder</code> (future: real models)</li> <li>symbolic.py: Placeholder <code>SymbolicRegressor</code> (future: PySR integration)</li> </ul>"},{"location":"PROJECT_STRUCTURE/#data-modules-srcmnemedata","title":"Data Modules (<code>src/mneme/data/</code>)","text":"<ul> <li>loaders.py: Unified data loading interfaces for different data sources</li> <li>generators.py: Synthetic data generation for testing and validation</li> <li>preprocessors.py: Normalization, filtering, and data preparation</li> <li>bioelectric.py: Specialized handlers for bioelectric imaging data</li> </ul>"},{"location":"PROJECT_STRUCTURE/#analysis-modules-srcmnemeanalysis","title":"Analysis Modules (<code>src/mneme/analysis/</code>)","text":"<ul> <li>pipeline.py: Orchestrates the analysis workflow (MVP-ready)</li> <li>visualization.py: Plotting utilities (MVP-ready)</li> <li>features.py: Basic feature extractor (MVP-ready)</li> <li>metrics.py: Evaluation utilities (minimal)</li> </ul>"},{"location":"PROJECT_STRUCTURE/#development-workflow","title":"Development Workflow","text":"<p>Note: <code>quality</code> (validation/quality checker), <code>parallel</code> (basic helper), and <code>monitoring</code> (lightweight utilities) now exist in <code>src/</code>. <code>features</code> remains minimal and broader recovery/checkpointing are still roadmap.</p> <ol> <li>Feature Development: Create feature branches from <code>main</code></li> <li>Testing: Write tests alongside new features</li> <li>Documentation: Update relevant docs with changes</li> <li>Experiments: Track experiments in <code>experiments/</code> directory</li> <li>Notebooks: Use notebooks for exploration, move stable code to modules</li> </ol>"},{"location":"PROJECT_STRUCTURE/#code-organization-principles","title":"Code Organization Principles","text":"<ol> <li>Separation of Concerns: Keep data, models, and analysis logic separate</li> <li>Modularity: Each module should have a single, well-defined purpose</li> <li>Testability: Design for easy unit and integration testing</li> <li>Configuration: Use config files for experiment parameters</li> <li>Reproducibility: Track random seeds, versions, and parameters</li> </ol>"},{"location":"REPO_AUDIT_2025-08-18/","title":"REPO AUDIT 2025 08 18","text":""},{"location":"REPO_AUDIT_2025-08-18/#repository-audit-2025-08-18","title":"Repository audit (2025-08-18)","text":"<ul> <li>CI/CD</li> <li>Tests: Now Ubuntu + Python 3.11/3.12, lint passes; mypy temporarily non-blocking; smoke test present.</li> <li>Docs: Markdown bundled and deployed to <code>gh-pages</code> with proper permissions.</li> <li> <p>Recommendation: Re-enable strict mypy after type hygiene pass; add real tests to replace smoke.</p> </li> <li> <p>Packaging/metadata</p> </li> <li><code>setup.py</code> fixed URLs and console scripts; <code>pyproject.toml</code> still declared Python &gt;=3.8 and pointed scripts to missing <code>mneme.scripts.*</code>.</li> <li> <p>Action: Update <code>pyproject.toml</code> to Python &gt;=3.12, correct URLs, and map console scripts to <code>mneme.cli:main</code> placeholders.</p> </li> <li> <p>APIs vs code</p> </li> <li>CLI references <code>create_bioelectric_pipeline</code> (present).</li> <li> <p><code>models/</code> docs mention <code>autoencoders.py</code>, <code>symbolic.py</code>; minimal placeholders now present and exported.</p> </li> <li> <p>Types/static analysis</p> </li> <li>mypy reports many errors (Pydantic types used as annotations, missing return types, unions). Also <code>python_version</code> set to 3.8.</li> <li> <p>Action: Set mypy <code>python_version</code> to 3.12; add <code>types-PyYAML</code> to dev deps; later, add annotations/ignores as needed.</p> </li> <li> <p>Docs vs reality</p> </li> <li> <p>README fixed to <code>import mneme</code> and Python 3.12. Markdown docs match structure; notebooks/tests listed in docs exceed current repo. With placeholders added, structure aligns better.</p> </li> <li> <p>NotImplemented/TODOs</p> </li> <li> <p>Core algorithms in <code>core/topology.py</code> and <code>core/attractors.py</code> include <code>NotImplementedError</code> and TODOs (Rips/Alpha persistence, Lyapunov, clustering, basins). Acceptable for roadmap; ensure API surfaces communicate experimental status.</p> </li> <li> <p>Next steps (implemented now)</p> </li> <li>Patched <code>pyproject.toml</code> (Python 3.12, URLs, scripts, mypy 3.12) and added optional extras <code>[pysr]</code>.</li> <li>Implemented <code>create_bioelectric_pipeline</code> (MVP defaults) and verified CLI integration.</li> <li>Added <code>types-PyYAML</code> to dev requirements.</li> <li>Added <code>models/autoencoders.py</code> and <code>models/symbolic.py</code> placeholders and exported them.</li> <li><code>mneme.utils.io.load_results</code> now returns <code>AnalysisResult</code> for HDF5; <code>.h5</code>/<code>.hdf5</code> supported.</li> <li> <p><code>mneme info</code> import order improved; PySR/Julia status reported cleanly.</p> </li> <li> <p>Future improvements</p> </li> <li>Add concrete loaders and tests; flesh out topology/attractor features; add docs page summarizing known placeholders and roadmap.</li> </ul>"},{"location":"TESTING_STRATEGY/","title":"Mneme Testing Strategy","text":"<p>MVP note: Current repository includes a smoke test for imports. The sections below describe the intended testing strategy as the project grows.</p>"},{"location":"TESTING_STRATEGY/#testing-philosophy","title":"Testing Philosophy","text":"<p>The Mneme project employs comprehensive testing to ensure: - Correctness: Mathematical and algorithmic accuracy - Robustness: Handling edge cases and invalid inputs - Performance: Efficient processing of large datasets - Reproducibility: Deterministic results with fixed seeds</p>"},{"location":"TESTING_STRATEGY/#test-categories","title":"Test Categories","text":""},{"location":"TESTING_STRATEGY/#1-unit-tests","title":"1. Unit Tests","text":"<p>Test individual functions and classes in isolation.</p> <pre><code># tests/unit/test_field_theory.py\nimport pytest\nimport numpy as np\nfrom mneme.core.field_theory import FieldReconstructor\n\nclass TestFieldReconstructor:\n    def test_initialization(self):\n        reconstructor = FieldReconstructor(method='gaussian_process')\n        assert reconstructor.method == 'gaussian_process'\n        assert reconstructor.resolution == (256, 256)\n\n    def test_fit_with_valid_data(self):\n        # Generate test data\n        observations = np.random.randn(100)\n        positions = np.random.rand(100, 2)\n\n        reconstructor = FieldReconstructor()\n        reconstructor.fit(observations, positions)\n\n        assert reconstructor.is_fitted\n        assert reconstructor.observations.shape == (100,)\n\n    def test_reconstruct_shape(self):\n        # Setup\n        observations = np.random.randn(50)\n        positions = np.random.rand(50, 2)\n\n        reconstructor = FieldReconstructor(resolution=(128, 128))\n        reconstructor.fit(observations, positions)\n\n        # Test\n        field = reconstructor.reconstruct()\n\n        assert field.shape == (128, 128)\n        assert not np.any(np.isnan(field))\n\n    @pytest.mark.parametrize(\"method\", ['gaussian_process', 'ift', 'neural_field'])\n    def test_different_methods(self, method):\n        reconstructor = FieldReconstructor(method=method)\n        # Test method-specific behavior\n</code></pre>"},{"location":"TESTING_STRATEGY/#2-integration-tests","title":"2. Integration Tests","text":"<p>Test interactions between components.</p> <pre><code># tests/integration/test_pipeline.py\nimport pytest\nfrom mneme.analysis.pipeline import MnemePipeline\nfrom mneme.data.generators import SyntheticFieldGenerator\n\nclass TestPipelineIntegration:\n    def test_full_pipeline_execution(self):\n        # Generate synthetic data\n        generator = SyntheticFieldGenerator(seed=42)\n        field_data = generator.generate_dynamic(\n            shape=(64, 64), \n            timesteps=10,\n            parameters={'noise_level': 0.1}\n        )\n\n        # Create and run pipeline\n        pipeline = MnemePipeline({\n            'preprocessing': {'normalize': True},\n            'reconstruction': {'method': 'ift'},\n            'analysis': {'compute_topology': True}\n        })\n\n        results = pipeline.run({'field': field_data})\n\n        # Verify all expected outputs\n        assert 'reconstructed_field' in results\n        assert 'persistence_diagrams' in results\n        assert results['reconstructed_field'].shape[1:] == (256, 256)\n\n    def test_pipeline_stage_dependencies(self):\n        # Test that stages execute in correct order\n        pipeline = MnemePipeline({})\n\n        # Add stages with dependencies\n        pipeline.add_stage('preprocess', lambda x: x, ['raw'], ['processed'])\n        pipeline.add_stage('analyze', lambda x: x, ['processed'], ['results'])\n\n        # Verify dependency resolution\n        order = pipeline._resolve_execution_order()\n        assert order.index('preprocess') &lt; order.index('analyze')\n</code></pre>"},{"location":"TESTING_STRATEGY/#3-property-based-tests","title":"3. Property-Based Tests","text":"<p>Use hypothesis for generative testing.</p> <pre><code># tests/unit/test_topology_properties.py\nimport hypothesis as hp\nfrom hypothesis import strategies as st\nfrom mneme.core.topology import PersistentHomology\n\nclass TestTopologyProperties:\n    @hp.given(\n        field=st.lists(\n            st.lists(st.floats(min_value=-100, max_value=100), \n                    min_size=10, max_size=100),\n            min_size=10, max_size=100\n        )\n    )\n    def test_persistence_diagram_properties(self, field):\n        # Convert to numpy array\n        field_array = np.array(field)\n\n        ph = PersistentHomology()\n        diagrams = ph.compute_persistence(field_array)\n\n        # Property: Birth times &lt;= Death times\n        for diagram in diagrams:\n            assert np.all(diagram[:, 0] &lt;= diagram[:, 1])\n\n        # Property: Finite persistence\n        assert np.all(np.isfinite(diagrams[0]))\n</code></pre>"},{"location":"TESTING_STRATEGY/#4-performance-tests","title":"4. Performance Tests","text":"<p>Ensure operations meet performance requirements.</p> <pre><code># tests/performance/test_reconstruction_performance.py\nimport pytest\nimport time\nfrom mneme.core.field_theory import FieldReconstructor\n\nclass TestReconstructionPerformance:\n    @pytest.mark.performance\n    def test_reconstruction_speed(self, benchmark):\n        # Setup\n        observations = np.random.randn(1000)\n        positions = np.random.rand(1000, 2)\n\n        reconstructor = FieldReconstructor(method='gaussian_process')\n        reconstructor.fit(observations, positions)\n\n        # Benchmark reconstruction\n        result = benchmark(reconstructor.reconstruct)\n\n        # Assert performance threshold\n        assert benchmark.stats['mean'] &lt; 1.0  # Should complete in &lt; 1 second\n\n    @pytest.mark.performance\n    @pytest.mark.parametrize(\"size\", [100, 1000, 10000])\n    def test_scaling_behavior(self, size):\n        observations = np.random.randn(size)\n        positions = np.random.rand(size, 2)\n\n        reconstructor = FieldReconstructor()\n\n        start = time.time()\n        reconstructor.fit(observations, positions)\n        reconstructor.reconstruct()\n        duration = time.time() - start\n\n        # Log-linear scaling expected\n        expected_max_time = 0.001 * size * np.log(size)\n        assert duration &lt; expected_max_time\n</code></pre>"},{"location":"TESTING_STRATEGY/#5-data-validation-tests","title":"5. Data Validation Tests","text":"<p>Test data loading and validation.</p> <pre><code># tests/unit/test_data_validation.py\nimport pytest\nfrom mneme.data.validation import FieldDataSchema, DataValidator\n\nclass TestDataValidation:\n    def test_valid_field_data(self):\n        schema = FieldDataSchema(\n            shape=(None, 256, 256),\n            dtype=np.float32,\n            value_range=(-100, 100)\n        )\n\n        # Valid data\n        valid_data = np.random.uniform(-50, 50, (10, 256, 256)).astype(np.float32)\n        validator = DataValidator(schema)\n\n        is_valid, errors = validator.validate(valid_data)\n        assert is_valid\n        assert len(errors) == 0\n\n    def test_invalid_shape(self):\n        schema = FieldDataSchema(shape=(None, 256, 256))\n        invalid_data = np.zeros((10, 128, 128))  # Wrong spatial dimensions\n\n        validator = DataValidator(schema)\n        is_valid, errors = validator.validate(invalid_data)\n\n        assert not is_valid\n        assert 'shape' in errors[0]\n\n    def test_out_of_range_values(self):\n        schema = FieldDataSchema(value_range=(0, 1))\n        invalid_data = np.array([[-1, 2, 0.5]])  # Values outside range\n\n        validator = DataValidator(schema)\n        is_valid, errors = validator.validate(invalid_data)\n\n        assert not is_valid\n        assert 'value_range' in errors[0]\n</code></pre>"},{"location":"TESTING_STRATEGY/#6-fixture-and-mock-tests","title":"6. Fixture and Mock Tests","text":"<pre><code># tests/conftest.py\nimport pytest\nimport numpy as np\nfrom mneme.data.generators import SyntheticFieldGenerator\n\n@pytest.fixture\ndef sample_field():\n    \"\"\"Generate a sample field for testing.\"\"\"\n    generator = SyntheticFieldGenerator(seed=42)\n    return generator.generate_static(\n        shape=(64, 64),\n        parameters={'pattern': 'gaussian_blob', 'noise': 0.1}\n    )\n\n@pytest.fixture\ndef mock_bioelectric_data(tmp_path):\n    \"\"\"Create mock bioelectric data file.\"\"\"\n    import h5py\n\n    data_file = tmp_path / \"mock_data.h5\"\n    with h5py.File(data_file, 'w') as f:\n        f.create_dataset('voltage_fields', data=np.random.randn(10, 64, 64))\n        f.create_dataset('timestamps', data=np.arange(10))\n        f.attrs['sampling_rate_hz'] = 10.0\n\n    return data_file\n\n# Usage in tests\ndef test_with_fixture(sample_field):\n    assert sample_field.shape == (64, 64)\n    assert sample_field.dtype == np.float64\n</code></pre>"},{"location":"TESTING_STRATEGY/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/                      # Unit tests for individual components\n\u2502   \u251c\u2500\u2500 test_field_theory.py\n\u2502   \u251c\u2500\u2500 test_topology.py\n\u2502   \u251c\u2500\u2500 test_attractors.py\n\u2502   \u251c\u2500\u2500 test_data_loaders.py\n\u2502   \u2514\u2500\u2500 test_models.py\n\u2502\n\u251c\u2500\u2500 integration/               # Integration tests\n\u2502   \u251c\u2500\u2500 test_pipeline.py\n\u2502   \u251c\u2500\u2500 test_data_flow.py\n\u2502   \u2514\u2500\u2500 test_model_training.py\n\u2502\n\u251c\u2500\u2500 performance/               # Performance benchmarks\n\u2502   \u251c\u2500\u2500 test_reconstruction_performance.py\n\u2502   \u2514\u2500\u2500 test_topology_performance.py\n\u2502\n\u251c\u2500\u2500 fixtures/                  # Test data and fixtures\n\u2502   \u251c\u2500\u2500 synthetic_fields.npz\n\u2502   \u2514\u2500\u2500 test_config.yaml\n\u2502\n\u2514\u2500\u2500 conftest.py               # Shared fixtures and configuration\n</code></pre>"},{"location":"TESTING_STRATEGY/#running-tests","title":"Running Tests","text":""},{"location":"TESTING_STRATEGY/#basic-test-execution","title":"Basic Test Execution","text":"<pre><code># Run all tests\npytest\n\n# Run specific test file\npytest tests/unit/test_field_theory.py\n\n# Run tests matching pattern\npytest -k \"reconstruction\"\n\n# Run with coverage\npytest --cov=mneme --cov-report=html\n\n# Run only marked tests\npytest -m \"not slow\"\n</code></pre>"},{"location":"TESTING_STRATEGY/#test-markers","title":"Test Markers","text":"<pre><code># Mark slow tests\n@pytest.mark.slow\ndef test_large_dataset_processing():\n    # Test that takes &gt; 1 second\n    pass\n\n# Mark tests requiring GPU\n@pytest.mark.gpu\ndef test_neural_field_cuda():\n    # Test requiring CUDA\n    pass\n\n# Mark integration tests\n@pytest.mark.integration\ndef test_full_pipeline():\n    # Cross-component test\n    pass\n</code></pre>"},{"location":"TESTING_STRATEGY/#continuous-integration","title":"Continuous Integration","text":"<pre><code># .github/workflows/tests.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.8, 3.9, \"3.10\"]\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        pip install -r requirements.txt\n        pip install -r requirements-dev.txt\n\n    - name: Run tests\n      run: |\n        pytest --cov=mneme --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v2\n</code></pre>"},{"location":"TESTING_STRATEGY/#test-driven-development-guidelines","title":"Test-Driven Development Guidelines","text":"<ol> <li>Write Tests First: Define expected behavior before implementation</li> <li>Test Edge Cases: Empty inputs, extreme values, invalid parameters</li> <li>Mock External Dependencies: Use mocks for file I/O, network calls</li> <li>Keep Tests Fast: Mock expensive operations, use small test data</li> <li>Clear Test Names: <code>test_&lt;what&gt;_&lt;condition&gt;_&lt;expected_result&gt;</code></li> <li>One Assertion Per Test: Make failures easy to diagnose</li> <li>Use Fixtures: Share setup code, ensure cleanup</li> </ol>"},{"location":"TESTING_STRATEGY/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>Minimum overall coverage: 80%</li> <li>Core modules (<code>field_theory</code>, <code>topology</code>): 90%</li> <li>Critical paths: 95%</li> <li>Exclude from coverage: Visualization code, scripts</li> </ul>"},{"location":"TESTING_STRATEGY/#debugging-tests","title":"Debugging Tests","text":"<pre><code># Use pytest debugging\npytest --pdb  # Drop into debugger on failure\n\n# Capture print statements\npytest -s  # No capture, show prints\n\n# Verbose output\npytest -vv  # Very verbose\n\n# Run specific test with debugging\npytest tests/unit/test_field_theory.py::TestFieldReconstructor::test_fit_with_valid_data --pdb -vv\n</code></pre>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>This project is governed by the Contributor Covenant Code of Conduct, version 2.1.</p> <p>For the full text, see CODE_OF_CONDUCT.md in the repository root.</p>"},{"location":"code_of_conduct/#summary","title":"Summary","text":"<p>We are committed to making participation in this project a harassment-free experience for everyone. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"code_of_conduct/#reporting","title":"Reporting","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to bshepp@gmail.com. All complaints will be reviewed and investigated promptly and fairly.</p>"},{"location":"contributing/","title":"Contributing to Mneme","text":"<p>Thank you for your interest in contributing to Mneme! </p> <p>For full contributing guidelines, see CONTRIBUTING.md in the repository root.</p>"},{"location":"contributing/#quick-summary","title":"Quick Summary","text":"<ol> <li>Fork the repository and create a feature branch</li> <li>Follow PEP 8 style with Black formatting (88 char line length)</li> <li>Use conventional commits format</li> <li>Write tests for new functionality</li> <li>Update docstrings (NumPy style) for new/modified functions</li> <li>Run quality checks before submitting:</li> </ol> <pre><code>black src/ tests/\nflake8 src/ tests/\nmypy src/\npytest\n</code></pre>"},{"location":"contributing/#areas-for-contribution","title":"Areas for Contribution","text":"<p>High Priority:</p> <ul> <li>Additional IFT reconstruction methods</li> <li>More symbolic regression backends</li> <li>Visualization improvements</li> <li>Memory optimization for large datasets</li> <li>3D field data support</li> </ul> <p>Good First Issues:</p> <ul> <li>Add unit tests for uncovered functions</li> <li>Improve error messages</li> <li>Add type hints to older code</li> <li>Create example notebooks</li> </ul> <p>See the full guidelines for detailed information on code style, pull request process, and project-specific guidelines.</p>"},{"location":"mneme_project_plan_v1_original/","title":"Mneme project plan v1 original","text":"<p>Project Title: Mneme</p> <p>Purpose: Mneme is an exploratory research system designed to detect field-like, emergent memory structures embedded in biological systems, beginning with planarian regeneration and bioelectric data. It seeks to uncover attractor states, regulatory logic, and latent architectures not captured by sequence-based models alone.</p> <p>Guiding Premise: Biological systems, particularly those capable of regeneration, may encode memory not just genetically but as persistent spatial or field-based attractors. Mneme aims to identify, model, and interpret these attractor dynamics using machine learning, field theory, and topological methods.</p> <p>Phase 1: Synthetic Data Prototyping (Planarian Focus)</p> <p>Objective: Develop and validate a modular analysis pipeline on synthetic field-like data inspired by planarian voltage maps and regenerative logic.</p> <p>Tasks: 1. Create synthetic 2D field data with noise and attractor behavior. 2. Apply Information Field Theory (IFT) reconstruction to interpolate continuous fields. 3. Run dimensionality reduction (PCA, autoencoders) to uncover latent spaces. 4. Apply Topological Data Analysis (TDA) to identify persistent structures. 5. Use Symbolic Regression to extract mathematical rules governing local field behaviors. 6. Validate internal coherence across methods.</p> <p>Tools: Python, Jupyter/Colab, NumPy, SciPy, PyTorch/Keras, PySR, GUDHI (for TDA)</p> <p>Phase 2: Real Bioelectric + Gene Expression Data (Planarian)</p> <p>Objective: Test Mneme on actual biological data, starting with planarian bioelectric images, gene expression overlays, and regeneration timelines.</p> <p>Tasks: 1. Collect and preprocess datasets from Levin Lab, SmedGD, and published literature. 2. Normalize spatial and temporal scales. 3. Reconstruct bioelectric and expression fields with IFT tools. 4. Embed expression snapshots into latent space (e.g., via VAE). 5. Detect attractors, loops, and bifurcations using TDA. 6. Run symbolic regression on voltage-expression transitions. 7. Correlate findings with known regeneration outcomes and perturbation experiments.</p> <p>Deliverables: - A reproducible Jupyter notebook pipeline - Cleaned and annotated dataset repository - Visualization module for field and attractor mapping</p> <p>Phase 3: Interpretation + Theory Development</p> <p>Objective: Formalize insights into a model of distributed memory encoding via fields in biological tissue.</p> <p>Tasks: 1. Identify recurring attractor geometries and recovery behaviors. 2. Propose theoretical framework for field memory dynamics. 3. Compare results to Hopfield networks and morphogenetic models. 4. Draft whitepaper or publication. 5. Design follow-up experiments (e.g., perturbation predictions).</p> <p>Potential Extensions: - Cross-organism validation (e.g., zebrafish, axolotl) - Inclusion of behavior/fear response patterning - Field inheritance modeling across generations</p> <p>Core Values: - No prior overfitting to clean systems (Drosophila bias avoided) - Sensitivity to emergent, nonlinear, and self-correcting behavior - Respect for biological memory as distributed and dynamic</p> <p>Current Status: Project name chosen: Mneme Project plan initialized Synthetic data prototyping phase in progress Real planarian datasets to be sourced and prepped</p>"},{"location":"api/","title":"API Reference","text":"<p>Auto-generated reference documentation for all public Mneme modules.</p>"},{"location":"api/#core-modules","title":"Core Modules","text":"<p>The foundation of Mneme's analysis capabilities:</p> <ul> <li>Field Theory -- Field reconstruction from sparse observations (Sparse GP, Dense IFT, Neural Fields)</li> <li>Topology -- Persistent homology, persistence diagrams, Wasserstein/bottleneck distances</li> <li>Attractors -- Recurrence analysis, Lyapunov spectrum, clustering-based attractor detection</li> </ul>"},{"location":"api/#models","title":"Models","text":"<p>Machine learning models for field analysis:</p> <ul> <li>Autoencoders -- Convolutional VAE for learning compressed field representations</li> <li>Symbolic Regression -- PySR integration for discovering governing equations</li> </ul>"},{"location":"api/#data","title":"Data","text":"<p>Data loading, generation, and preprocessing:</p> <ul> <li>Generators -- Synthetic field data generation (Gaussian blobs, bioelectric sequences)</li> <li>Preprocessors -- Denoising, normalization, interpolation</li> <li>BETSE Loader -- Load BETSE bioelectric tissue simulation output</li> </ul>"},{"location":"api/#analysis","title":"Analysis","text":"<p>Pipeline orchestration and visualization:</p> <ul> <li>Pipeline -- End-to-end analysis pipeline with configurable stages</li> <li>Visualization -- Field visualization, dashboards, and plotting utilities</li> </ul>"},{"location":"api/analysis/pipeline/","title":"Pipeline","text":"<p>End-to-end analysis pipeline with configurable stages.</p>"},{"location":"api/analysis/pipeline/#factory-functions","title":"Factory Functions","text":""},{"location":"api/analysis/pipeline/#mneme.analysis.pipeline.create_bioelectric_pipeline","title":"create_bioelectric_pipeline","text":"<pre><code>create_bioelectric_pipeline(config: Optional[Dict[str, Any]] = None) -&gt; MnemePipeline\n</code></pre> <p>Create a bioelectric-focused analysis pipeline.</p> <p>This is a lightweight wrapper around the standard pipeline with bioelectric-appropriate defaults. It can be extended later.</p> Source code in <code>src/mneme/analysis/pipeline.py</code> <pre><code>def create_bioelectric_pipeline(config: Optional[Dict[str, Any]] = None) -&gt; MnemePipeline:\n    \"\"\"Create a bioelectric-focused analysis pipeline.\n\n    This is a lightweight wrapper around the standard pipeline with\n    bioelectric-appropriate defaults. It can be extended later.\n    \"\"\"\n    if config is None:\n        config = {\n            'preprocessing': {\n                # Use lightweight, broadly compatible defaults for MVP\n                'denoise': {'enabled': True, 'method': 'gaussian', 'sigma': 1.0},\n                'normalize': {'enabled': True, 'method': 'z_score', 'per_frame': True},\n                # Registration requires temporal (3D) data; disable by default for 2D fields\n                'register': {'enabled': False},\n                # Linear interpolation is much faster than cubic for MVP\n                'interpolate': {'enabled': True, 'target_shape': (256, 256), 'method': 'linear'},\n            },\n            'reconstruction': {\n                'method': 'ift',\n                'resolution': (256, 256),\n                'parameters': {}\n            },\n            'topology': {\n                'backend': 'cubical',  # 'cubical' | 'rips' | 'alpha'\n                'max_dimension': 2,\n                'filtration': 'sublevel',\n                'persistence_threshold': 0.05\n            },\n            'attractors': {\n                'method': 'recurrence',\n                'threshold': 0.1,\n                'parameters': {}\n            }\n        }\n\n    return MnemePipeline(config)\n</code></pre>"},{"location":"api/analysis/pipeline/#mneme.analysis.pipeline.create_standard_pipeline","title":"create_standard_pipeline","text":"<pre><code>create_standard_pipeline(config: Optional[Dict[str, Any]] = None) -&gt; MnemePipeline\n</code></pre> <p>Create standard analysis pipeline.</p> Source code in <code>src/mneme/analysis/pipeline.py</code> <pre><code>def create_standard_pipeline(config: Optional[Dict[str, Any]] = None) -&gt; MnemePipeline:\n    \"\"\"Create standard analysis pipeline.\"\"\"\n    if config is None:\n        config = {\n            'preprocessing': {\n                'denoise': {'enabled': True, 'method': 'gaussian', 'sigma': 1.0},\n                'normalize': {'enabled': True, 'method': 'z_score'},\n                'register': {'enabled': False},\n                'interpolate': {'enabled': True, 'target_shape': (256, 256)}\n            },\n            'reconstruction': {\n                'method': 'gaussian_process',\n                'resolution': (256, 256),\n                'parameters': {'kernel': 'rbf', 'length_scale': 10.0}\n            },\n            'topology': {\n                'backend': 'cubical',  # 'cubical' | 'rips' | 'alpha'\n                'max_dimension': 2,\n                'filtration': 'sublevel',\n                'persistence_threshold': 0.05\n            },\n            'attractors': {\n                'method': 'recurrence',\n                'threshold': 0.1,\n                'parameters': {'min_persistence': 0.1}\n            }\n        }\n\n    return MnemePipeline(config)\n</code></pre>"},{"location":"api/analysis/pipeline/#pipeline-class","title":"Pipeline Class","text":""},{"location":"api/analysis/pipeline/#mneme.analysis.pipeline.MnemePipeline","title":"MnemePipeline","text":"<pre><code>MnemePipeline(config: Dict[str, Any])\n</code></pre> <p>Complete analysis pipeline for field memory detection.</p> <p>Initialize pipeline with configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Pipeline configuration</p> required Source code in <code>src/mneme/analysis/pipeline.py</code> <pre><code>def __init__(self, config: Dict[str, Any]):\n    \"\"\"\n    Initialize pipeline with configuration.\n\n    Parameters\n    ----------\n    config : Dict[str, Any]\n        Pipeline configuration\n    \"\"\"\n    self.config = config\n    self.stages = []\n    self.stage_mapping = {}\n    self.logger = logging.getLogger(__name__)\n\n    # Initialize components\n    self._initialize_components()\n</code></pre>"},{"location":"api/analysis/pipeline/#mneme.analysis.pipeline.MnemePipeline.add_stage","title":"add_stage","text":"<pre><code>add_stage(name: str, stage_func: Callable, inputs: List[str], outputs: List[str], enabled: bool = True) -&gt; MnemePipeline\n</code></pre> <p>Add processing stage to pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Stage name</p> required <code>stage_func</code> <code>Callable</code> <p>Function to execute</p> required <code>inputs</code> <code>List[str]</code> <p>Input data keys</p> required <code>outputs</code> <code>List[str]</code> <p>Output data keys</p> required <code>enabled</code> <code>bool</code> <p>Whether stage is enabled</p> <code>True</code> <p>Returns:</p> Name Type Description <code>self</code> <code>MnemePipeline</code> <p>Pipeline instance for chaining</p> Source code in <code>src/mneme/analysis/pipeline.py</code> <pre><code>def add_stage(\n    self,\n    name: str,\n    stage_func: Callable,\n    inputs: List[str],\n    outputs: List[str],\n    enabled: bool = True\n) -&gt; 'MnemePipeline':\n    \"\"\"\n    Add processing stage to pipeline.\n\n    Parameters\n    ----------\n    name : str\n        Stage name\n    stage_func : Callable\n        Function to execute\n    inputs : List[str]\n        Input data keys\n    outputs : List[str]  \n        Output data keys\n    enabled : bool\n        Whether stage is enabled\n\n    Returns\n    -------\n    self : MnemePipeline\n        Pipeline instance for chaining\n    \"\"\"\n    stage = PipelineStage(\n        name=name,\n        enabled=enabled,\n        inputs=inputs,\n        outputs=outputs\n    )\n\n    self.stages.append(stage)\n    self.stage_mapping[name] = stage_func\n\n    return self\n</code></pre>"},{"location":"api/analysis/pipeline/#mneme.analysis.pipeline.MnemePipeline.run","title":"run","text":"<pre><code>run(data: Union[Dict[str, Any], Field, ndarray]) -&gt; PipelineResult\n</code></pre> <p>Execute full pipeline on data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[Dict[str, Any], Field, ndarray]</code> <p>Input data</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>PipelineResult</code> <p>Pipeline execution result</p> Source code in <code>src/mneme/analysis/pipeline.py</code> <pre><code>def run(self, data: Union[Dict[str, Any], Field, np.ndarray]) -&gt; PipelineResult:\n    \"\"\"\n    Execute full pipeline on data.\n\n    Parameters\n    ----------\n    data : Union[Dict[str, Any], Field, np.ndarray]\n        Input data\n\n    Returns\n    -------\n    result : PipelineResult\n        Pipeline execution result\n    \"\"\"\n    start_time = time.time()\n    stage_results = {}\n    errors = []\n\n    try:\n        # Prepare data\n        if isinstance(data, np.ndarray):\n            data_dict = {'field': Field(data=data)}\n        elif isinstance(data, Field):\n            data_dict = {'field': data}\n        else:\n            data_dict = data.copy()\n\n        # Run standard pipeline\n        if not self.stages:\n            # Use default pipeline\n            stage_results = self._run_default_pipeline(data_dict)\n        else:\n            # Run custom pipeline\n            stage_results = self._run_custom_pipeline(data_dict)\n\n        # Create analysis result\n        analysis_result = self._create_analysis_result(data_dict, stage_results)\n\n        execution_time = time.time() - start_time\n\n        return PipelineResult(\n            success=True,\n            execution_time=execution_time,\n            stage_results=stage_results,\n            analysis_result=analysis_result\n        )\n\n    except Exception as e:\n        execution_time = time.time() - start_time\n        errors.append(str(e))\n        self.logger.error(f\"Pipeline execution failed: {e}\")\n\n        return PipelineResult(\n            success=False,\n            execution_time=execution_time,\n            stage_results=stage_results,\n            errors=errors\n        )\n</code></pre>"},{"location":"api/analysis/pipeline/#result-types","title":"Result Types","text":""},{"location":"api/analysis/pipeline/#mneme.analysis.pipeline.PipelineResult","title":"PipelineResult  <code>dataclass</code>","text":"<pre><code>PipelineResult(success: bool, execution_time: float, stage_results: Dict[str, Any], analysis_result: Optional[AnalysisResult] = None, errors: Optional[List[str]] = None)\n</code></pre> <p>Result from pipeline execution.</p>"},{"location":"api/analysis/visualization/","title":"Visualization","text":"<p>Field visualization, dashboards, and plotting utilities.</p>"},{"location":"api/analysis/visualization/#visualizer-class","title":"Visualizer Class","text":""},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer","title":"FieldVisualizer","text":"<pre><code>FieldVisualizer(style: str = 'publication', figsize: Tuple[int, int] = (10, 8))\n</code></pre> <p>Visualize fields and analysis results.</p> <p>Initialize field visualizer.</p> <p>Parameters:</p> Name Type Description Default <code>style</code> <code>str</code> <p>Plotting style preset</p> <code>'publication'</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Default figure size</p> <code>(10, 8)</code> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def __init__(self, style: str = \"publication\", figsize: Tuple[int, int] = (10, 8)):\n    \"\"\"\n    Initialize field visualizer.\n\n    Parameters\n    ----------\n    style : str\n        Plotting style preset\n    figsize : Tuple[int, int]\n        Default figure size\n    \"\"\"\n    self.style = style\n    self.figsize = figsize\n    self.setup_style()\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.setup_style","title":"setup_style","text":"<pre><code>setup_style() -&gt; None\n</code></pre> <p>Setup matplotlib style.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def setup_style(self) -&gt; None:\n    \"\"\"Setup matplotlib style.\"\"\"\n    if self.style == \"publication\":\n        plt.style.use(\"seaborn-v0_8-whitegrid\")\n        plt.rcParams.update(\n            {\n                \"font.size\": 12,\n                \"axes.labelsize\": 14,\n                \"axes.titlesize\": 16,\n                \"xtick.labelsize\": 12,\n                \"ytick.labelsize\": 12,\n                \"legend.fontsize\": 12,\n                \"figure.titlesize\": 18,\n                \"axes.spines.top\": False,\n                \"axes.spines.right\": False,\n                \"figure.dpi\": 300,\n            }\n        )\n    elif self.style == \"presentation\":\n        plt.style.use(\"seaborn-v0_8-talk\")\n        plt.rcParams.update({\"font.size\": 14, \"figure.dpi\": 150})\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_field","title":"plot_field","text":"<pre><code>plot_field(field: Union[Field, ndarray], title: Optional[str] = None, colormap: str = 'viridis', show_colorbar: bool = True, ax: Optional[Axes] = None, **kwargs: Any) -&gt; plt.Figure\n</code></pre> <p>Plot 2D field with customizable appearance.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>Field or ndarray</code> <p>Field to plot</p> required <code>title</code> <code>str</code> <p>Plot title</p> <code>None</code> <code>colormap</code> <code>str</code> <p>Colormap name</p> <code>'viridis'</code> <code>show_colorbar</code> <code>bool</code> <p>Whether to show colorbar</p> <code>True</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for imshow</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Figure object</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_field(\n    self,\n    field: Union[Field, np.ndarray],\n    title: Optional[str] = None,\n    colormap: str = \"viridis\",\n    show_colorbar: bool = True,\n    ax: Optional[plt.Axes] = None,\n    **kwargs: Any,\n) -&gt; plt.Figure:\n    \"\"\"\n    Plot 2D field with customizable appearance.\n\n    Parameters\n    ----------\n    field : Field or np.ndarray\n        Field to plot\n    title : str, optional\n        Plot title\n    colormap : str\n        Colormap name\n    show_colorbar : bool\n        Whether to show colorbar\n    ax : plt.Axes, optional\n        Existing axes to plot on\n    **kwargs\n        Additional arguments for imshow\n\n    Returns\n    -------\n    fig : plt.Figure\n        Figure object\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=self.figsize)\n    else:\n        fig = ax.get_figure()\n\n    # Extract data\n    if isinstance(field, Field):\n        data = field.data\n        metadata = field.metadata or {}\n    else:\n        data = field\n        metadata = {}\n\n    # Handle 3D data (take first slice)\n    if data.ndim == 3:\n        data = data[0]\n        if title is None:\n            title = \"Field (first time slice)\"\n\n    # Plot field\n    im = ax.imshow(data, cmap=colormap, aspect=\"auto\", **kwargs)\n\n    if title:\n        ax.set_title(title)\n\n    # Add colorbar\n    if show_colorbar:\n        cbar = plt.colorbar(im, ax=ax)\n        if \"units\" in metadata:\n            cbar.set_label(metadata[\"units\"])\n\n    # Set labels\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_field_sequence","title":"plot_field_sequence","text":"<pre><code>plot_field_sequence(fields: Union[List[Field], ndarray], fps: int = 10, title: Optional[str] = None, colormap: str = 'viridis', **kwargs: Any) -&gt; animation.FuncAnimation\n</code></pre> <p>Create animation of field evolution.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_field_sequence(\n    self,\n    fields: Union[List[Field], np.ndarray],\n    fps: int = 10,\n    title: Optional[str] = None,\n    colormap: str = \"viridis\",\n    **kwargs: Any,\n) -&gt; animation.FuncAnimation:\n    \"\"\"Create animation of field evolution.\"\"\"\n    if isinstance(fields, np.ndarray):\n        if fields.ndim != 3:\n            raise ValueError(\"Field sequence must be 3D (time, height, width)\")\n        field_data = fields\n    else:\n        field_data = np.stack([f.data for f in fields])\n\n    fig, ax = plt.subplots(figsize=self.figsize)\n\n    # Set up the plot\n    vmin, vmax = np.percentile(field_data, [1, 99])\n    im = ax.imshow(field_data[0], cmap=colormap, vmin=vmin, vmax=vmax, **kwargs)\n\n    if title:\n        ax.set_title(title)\n\n    plt.colorbar(im, ax=ax)\n\n    def animate(frame: int):\n        im.set_array(field_data[frame])\n        ax.set_title(f\"{title or 'Field Evolution'} - Frame {frame}\")\n        return [im]\n\n    ani = animation.FuncAnimation(\n        fig, animate, frames=len(field_data), interval=1000 // fps, blit=True\n    )\n\n    return ani\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_persistence_diagram","title":"plot_persistence_diagram","text":"<pre><code>plot_persistence_diagram(diagram: PersistenceDiagram, ax: Optional[Axes] = None, title: Optional[str] = None, **kwargs: Any) -&gt; plt.Figure\n</code></pre> <p>Plot topological persistence diagram.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_persistence_diagram(\n    self,\n    diagram: PersistenceDiagram,\n    ax: Optional[plt.Axes] = None,\n    title: Optional[str] = None,\n    **kwargs: Any,\n) -&gt; plt.Figure:\n    \"\"\"Plot topological persistence diagram.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=self.figsize)\n    else:\n        fig = ax.get_figure()\n\n    if len(diagram.points) == 0:\n        ax.text(\n            0.5,\n            0.5,\n            \"No persistent features\",\n            transform=ax.transAxes,\n            ha=\"center\",\n            va=\"center\",\n        )\n        ax.set_title(title or f\"Persistence Diagram (Dim {diagram.dimension})\")\n        return fig\n\n    # Plot points\n    birth = diagram.points[:, 0]\n    death = diagram.points[:, 1]\n\n    # Color by persistence\n    persistence = death - birth\n    scatter = ax.scatter(birth, death, c=persistence, cmap=\"viridis\", **kwargs)\n\n    # Add diagonal line\n    lims = [min(birth.min(), death.min()), max(birth.max(), death.max())]\n    ax.plot(lims, lims, \"k--\", alpha=0.5, label=\"y=x\")\n\n    # Labels and title\n    ax.set_xlabel(\"Birth\")\n    ax.set_ylabel(\"Death\")\n    ax.set_title(title or f\"Persistence Diagram (Dim {diagram.dimension})\")\n\n    # Colorbar\n    plt.colorbar(scatter, ax=ax, label=\"Persistence\")\n\n    # Equal aspect ratio\n    ax.set_aspect(\"equal\")\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_multiple_persistence_diagrams","title":"plot_multiple_persistence_diagrams","text":"<pre><code>plot_multiple_persistence_diagrams(diagrams: List[PersistenceDiagram], titles: Optional[List[str]] = None) -&gt; plt.Figure\n</code></pre> <p>Plot multiple persistence diagrams.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_multiple_persistence_diagrams(\n    self, diagrams: List[PersistenceDiagram], titles: Optional[List[str]] = None\n) -&gt; plt.Figure:\n    \"\"\"Plot multiple persistence diagrams.\"\"\"\n    num_diagrams = len(diagrams)\n    cols = min(3, num_diagrams)\n    rows = (num_diagrams + cols - 1) // cols\n\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n\n    if num_diagrams == 1:\n        axes = [axes]  # type: ignore[assignment]\n    elif rows == 1:\n        axes = axes.flatten()  # type: ignore[assignment]\n    else:\n        axes = axes.flatten()  # type: ignore[assignment]\n\n    for i, diagram in enumerate(diagrams):\n        t = titles[i] if titles else f\"Dimension {diagram.dimension}\"\n        self.plot_persistence_diagram(diagram, ax=axes[i], title=t)\n\n    # Hide unused subplots\n    for i in range(num_diagrams, len(axes)):\n        axes[i].set_visible(False)\n\n    plt.tight_layout()\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_attractor_portrait","title":"plot_attractor_portrait","text":"<pre><code>plot_attractor_portrait(trajectory: ndarray, attractors: List[Attractor], ax: Optional[Axes] = None, title: Optional[str] = None) -&gt; plt.Figure\n</code></pre> <p>Plot phase space with detected attractors.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_attractor_portrait(\n    self,\n    trajectory: np.ndarray,\n    attractors: List[Attractor],\n    ax: Optional[plt.Axes] = None,\n    title: Optional[str] = None,\n) -&gt; plt.Figure:\n    \"\"\"Plot phase space with detected attractors.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=self.figsize)\n    else:\n        fig = ax.get_figure()\n\n    # Plot trajectory\n    if trajectory.shape[1] &gt;= 2:\n        ax.plot(trajectory[:, 0], trajectory[:, 1], \"gray\", alpha=0.3, linewidth=0.5)\n        ax.scatter(trajectory[:, 0], trajectory[:, 1], c=\"lightgray\", s=1, alpha=0.5)\n\n    # Plot attractors\n    colors = plt.cm.Set1(np.linspace(0, 1, len(attractors)))\n\n    for i, attractor in enumerate(attractors):\n        if attractor.trajectory_indices:\n            # Plot attractor points\n            attractor_points = trajectory[attractor.trajectory_indices]\n            if attractor_points.shape[1] &gt;= 2:\n                ax.scatter(\n                    attractor_points[:, 0],\n                    attractor_points[:, 1],\n                    c=[colors[i]],\n                    s=20,\n                    alpha=0.8,\n                    label=f\"{attractor.type.value} (size: {attractor.basin_size:.2f})\",\n                )\n\n                # Mark center\n                if len(attractor.center) &gt;= 2:\n                    ax.scatter(\n                        attractor.center[0],\n                        attractor.center[1],\n                        c=[colors[i]],\n                        s=100,\n                        marker=\"x\",\n                        linewidth=3,\n                    )\n\n    ax.set_xlabel(\"Dimension 1\")\n    ax.set_ylabel(\"Dimension 2\")\n    ax.set_title(title or \"Phase Space Portrait\")\n\n    if attractors:\n        ax.legend()\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_field_statistics","title":"plot_field_statistics","text":"<pre><code>plot_field_statistics(field: Union[Field, ndarray], ax: Optional[Axes] = None) -&gt; plt.Figure\n</code></pre> <p>Plot field statistics.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_field_statistics(self, field: Union[Field, np.ndarray], ax: Optional[plt.Axes] = None) -&gt; plt.Figure:\n    \"\"\"Plot field statistics.\"\"\"\n    if ax is None:\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    else:\n        fig = ax.get_figure()\n        ax1 = ax2 = ax\n\n    # Extract data\n    if isinstance(field, Field):\n        data = field.data\n    else:\n        data = field\n\n    # Flatten data for histogram\n    flat_data = data.flatten()\n    finite_data = flat_data[np.isfinite(flat_data)]\n\n    # Histogram\n    ax1.hist(finite_data, bins=50, alpha=0.7, edgecolor=\"black\")\n    ax1.set_xlabel(\"Value\")\n    ax1.set_ylabel(\"Frequency\")\n    ax1.set_title(\"Value Distribution\")\n\n    # Add statistics text\n    stats_text = f\"Mean: {np.mean(finite_data):.3f}\\n\"\n    stats_text += f\"Std: {np.std(finite_data):.3f}\\n\"\n    stats_text += f\"Min: {np.min(finite_data):.3f}\\n\"\n    stats_text += f\"Max: {np.max(finite_data):.3f}\"\n\n    ax1.text(\n        0.02,\n        0.98,\n        stats_text,\n        transform=ax1.transAxes,\n        verticalalignment=\"top\",\n        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n    )\n\n    # Spatial profile (if 2D)\n    if data.ndim == 2:\n        # Average profiles\n        profile_x = np.mean(data, axis=0)\n        profile_y = np.mean(data, axis=1)\n\n        ax2.plot(profile_x, label=\"X profile\")\n        ax2.plot(profile_y, label=\"Y profile\")\n        ax2.set_xlabel(\"Position\")\n        ax2.set_ylabel(\"Average Value\")\n        ax2.set_title(\"Spatial Profiles\")\n        ax2.legend()\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_reconstruction_comparison","title":"plot_reconstruction_comparison","text":"<pre><code>plot_reconstruction_comparison(original: Union[Field, ndarray], reconstructed: Union[Field, ndarray], uncertainty: Optional[ndarray] = None) -&gt; plt.Figure\n</code></pre> <p>Compare original and reconstructed fields.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_reconstruction_comparison(\n    self,\n    original: Union[Field, np.ndarray],\n    reconstructed: Union[Field, np.ndarray],\n    uncertainty: Optional[np.ndarray] = None,\n) -&gt; plt.Figure:\n    \"\"\"Compare original and reconstructed fields.\"\"\"\n    num_plots = 3 if uncertainty is not None else 2\n    fig, axes = plt.subplots(1, num_plots, figsize=(5 * num_plots, 5))\n\n    # Extract data\n    orig_data = original.data if isinstance(original, Field) else original\n    recon_data = reconstructed.data if isinstance(reconstructed, Field) else reconstructed\n\n    # Plot original\n    im1 = axes[0].imshow(orig_data, cmap=\"viridis\", aspect=\"auto\")\n    axes[0].set_title(\"Original\")\n    plt.colorbar(im1, ax=axes[0])\n\n    # Plot reconstructed\n    im2 = axes[1].imshow(recon_data, cmap=\"viridis\", aspect=\"auto\")\n    axes[1].set_title(\"Reconstructed\")\n    plt.colorbar(im2, ax=axes[1])\n\n    # Plot uncertainty if available\n    if uncertainty is not None:\n        im3 = axes[2].imshow(uncertainty, cmap=\"Reds\", aspect=\"auto\")\n        axes[2].set_title(\"Uncertainty\")\n        plt.colorbar(im3, ax=axes[2])\n\n    plt.tight_layout()\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.create_analysis_dashboard","title":"create_analysis_dashboard","text":"<pre><code>create_analysis_dashboard(result: AnalysisResult, save_path: Optional[str] = None) -&gt; plt.Figure\n</code></pre> <p>Create comprehensive analysis dashboard.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def create_analysis_dashboard(\n    self, result: AnalysisResult, save_path: Optional[str] = None\n) -&gt; plt.Figure:\n    \"\"\"Create comprehensive analysis dashboard.\"\"\"\n    fig = plt.figure(figsize=(18, 12))\n\n    # Create grid layout\n    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n\n    # Original field\n    ax1 = fig.add_subplot(gs[0, 0])\n    if result.raw_data is not None:\n        self.plot_field(result.raw_data, title=\"Original Field\", ax=ax1)\n\n    # Processed field\n    ax2 = fig.add_subplot(gs[0, 1])\n    if result.processed_data is not None:\n        self.plot_field(result.processed_data, title=\"Processed Field\", ax=ax2)\n\n    # Reconstructed field\n    ax3 = fig.add_subplot(gs[0, 2])\n    if result.reconstruction is not None:\n        self.plot_field(result.reconstruction.field, title=\"Reconstructed Field\", ax=ax3)\n\n    # Reconstruction uncertainty\n    ax4 = fig.add_subplot(gs[0, 3])\n    if result.reconstruction is not None and result.reconstruction.uncertainty is not None:\n        im = ax4.imshow(result.reconstruction.uncertainty, cmap=\"Reds\", aspect=\"auto\")\n        ax4.set_title(\"Reconstruction Uncertainty\")\n        plt.colorbar(im, ax=ax4)\n\n    # Persistence diagrams and summary\n    if result.topology is not None and result.topology.diagrams:\n        # Plot up to 3 diagrams\n        for i, diagram in enumerate(result.topology.diagrams[:3]):\n            ax = fig.add_subplot(gs[1, i])\n            self.plot_persistence_diagram(diagram, ax=ax)\n        # Summary panel\n        ax_sum = fig.add_subplot(gs[1, 3])\n        feats = result.topology.features if result.topology.features is not None else None\n        text_lines = []\n        if feats is not None:\n            text_lines.append(f\"Feature vector length: {len(feats)}\")\n        # Backend hint isn't on AnalysisResult; show generic text\n        text_lines.append(\"Topology backend: see pipeline stage results\")\n        ax_sum.axis('off')\n        ax_sum.text(0.05, 0.95, \"Topology Summary\\n\" + \"\\n\".join(text_lines), va='top')\n\n    # Attractor analysis\n    if result.attractors:\n        ax_attr = fig.add_subplot(gs[2, :2])\n\n        # Create simple trajectory for visualization\n        if result.processed_data is not None and result.processed_data.data.ndim == 3:\n            # Create trajectory from field evolution\n            field_data = result.processed_data.data\n            trajectory = field_data.reshape(field_data.shape[0], -1)\n\n            # Subsample for visualization\n            if trajectory.shape[1] &gt; 100:\n                indices = np.random.choice(trajectory.shape[1], 100, replace=False)\n                trajectory = trajectory[:, indices]\n\n            self.plot_attractor_portrait(trajectory, result.attractors, ax=ax_attr)\n\n        # Attractor summary\n        ax_attr_sum = fig.add_subplot(gs[2, 2])\n        types = [a.type.value for a in result.attractors]\n        if types:\n            unique, counts = np.unique(types, return_counts=True)\n            ax_attr_sum.bar(unique, counts)\n            ax_attr_sum.set_title('Attractor Types')\n            ax_attr_sum.set_ylabel('Count')\n        else:\n            ax_attr_sum.axis('off')\n\n    # Statistics\n    ax_stats = fig.add_subplot(gs[2, 3:])\n    if result.raw_data is not None:\n        self.plot_field_statistics(result.raw_data, ax=ax_stats)\n\n    # Add title\n    fig.suptitle(f\"Analysis Dashboard - {result.experiment_id}\", fontsize=16)\n\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.FieldVisualizer.plot_pipeline_results","title":"plot_pipeline_results","text":"<pre><code>plot_pipeline_results(results: Dict[str, Any], save_path: Optional[str] = None) -&gt; plt.Figure\n</code></pre> <p>Plot pipeline stage results.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_pipeline_results(self, results: Dict[str, Any], save_path: Optional[str] = None) -&gt; plt.Figure:\n    \"\"\"Plot pipeline stage results.\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n    axes = axes.flatten()\n\n    # Quality metrics\n    if \"quality_check\" in results:\n        quality = results[\"quality_check\"]\n        metrics = quality.get(\"metrics\", {})\n\n        # Plot quality metrics\n        metric_names: List[str] = []\n        metric_values: List[float] = []\n\n        for key, value in metrics.items():\n            if isinstance(value, (int, float)):\n                metric_names.append(key)\n                metric_values.append(float(value))\n\n        if metric_names:\n            axes[0].bar(range(len(metric_names)), metric_values)\n            axes[0].set_xticks(range(len(metric_names)))\n            axes[0].set_xticklabels(metric_names, rotation=45, ha=\"right\")\n            axes[0].set_title(\"Quality Metrics\")\n\n    # Topology features\n    if \"topology\" in results:\n        topo = results[\"topology\"]\n        if \"feature_vector_length\" in topo:\n            axes[1].text(\n                0.5,\n                0.5,\n                f\"Topological Features: {topo['feature_vector_length']}\",\n                transform=axes[1].transAxes,\n                ha=\"center\",\n                va=\"center\",\n            )\n        axes[1].set_title(\"Topology Analysis\")\n\n    # Attractor summary\n    if \"attractors\" in results:\n        attr = results[\"attractors\"]\n        if \"attractor_types\" in attr:\n            types = attr[\"attractor_types\"]\n            unique_types, counts = np.unique(types, return_counts=True)\n            axes[2].bar(unique_types, counts)\n            axes[2].set_title(\"Attractor Types\")\n            axes[2].set_xlabel(\"Type\")\n            axes[2].set_ylabel(\"Count\")\n\n    # Execution times\n    times: List[float] = []\n    labels: List[str] = []\n\n    for stage_name, stage_result in results.items():\n        if isinstance(stage_result, dict) and \"computation_time\" in stage_result:\n            times.append(float(stage_result[\"computation_time\"]))\n            labels.append(stage_name)\n\n    if times:\n        axes[3].bar(labels, times)\n        axes[3].set_title(\"Stage Execution Times\")\n        axes[3].set_ylabel(\"Time (s)\")\n        axes[3].tick_params(axis=\"x\", rotation=45)\n\n    plt.tight_layout()\n\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#convenience-functions","title":"Convenience Functions","text":""},{"location":"api/analysis/visualization/#mneme.analysis.visualization.plot_bioelectric_gradient","title":"plot_bioelectric_gradient","text":"<pre><code>plot_bioelectric_gradient(field: ndarray, title: str = 'Bioelectric Field') -&gt; plt.Figure\n</code></pre> <p>Plot bioelectric field with appropriate colormap.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def plot_bioelectric_gradient(field: np.ndarray, title: str = \"Bioelectric Field\") -&gt; plt.Figure:\n    \"\"\"Plot bioelectric field with appropriate colormap.\"\"\"\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    # Use RdBu colormap for voltage data\n    im = ax.imshow(field, cmap=\"RdBu_r\", aspect=\"auto\")\n\n    ax.set_title(title)\n    ax.set_xlabel(\"Lateral Position\")\n    ax.set_ylabel(\"Anterior-Posterior Position\")\n\n    # Add colorbar with voltage units\n    cbar = plt.colorbar(im, ax=ax)\n    cbar.set_label(\"Voltage (mV)\")\n\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.create_comparison_plot","title":"create_comparison_plot","text":"<pre><code>create_comparison_plot(fields: List[ndarray], titles: List[str]) -&gt; plt.Figure\n</code></pre> <p>Create comparison plot of multiple fields.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def create_comparison_plot(fields: List[np.ndarray], titles: List[str]) -&gt; plt.Figure:\n    \"\"\"Create comparison plot of multiple fields.\"\"\"\n    num_fields = len(fields)\n    cols = min(3, num_fields)\n    rows = (num_fields + cols - 1) // cols\n\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n\n    if num_fields == 1:\n        axes = [axes]  # type: ignore[assignment]\n    elif rows == 1:\n        axes = axes.flatten()  # type: ignore[assignment]\n    else:\n        axes = axes.flatten()  # type: ignore[assignment]\n\n    for i, (field, t) in enumerate(zip(fields, titles)):\n        im = axes[i].imshow(field, cmap=\"viridis\", aspect=\"auto\")\n        axes[i].set_title(t)\n        plt.colorbar(im, ax=axes[i])\n\n    # Hide unused subplots\n    for i in range(num_fields, len(axes)):\n        axes[i].set_visible(False)\n\n    plt.tight_layout()\n    return fig\n</code></pre>"},{"location":"api/analysis/visualization/#mneme.analysis.visualization.save_animation","title":"save_animation","text":"<pre><code>save_animation(ani: FuncAnimation, filename: str, fps: int = 10) -&gt; None\n</code></pre> <p>Save animation to file.</p> Source code in <code>src/mneme/analysis/visualization.py</code> <pre><code>def save_animation(ani: animation.FuncAnimation, filename: str, fps: int = 10) -&gt; None:\n    \"\"\"Save animation to file.\"\"\"\n    try:\n        writer = animation.PillowWriter(fps=fps)\n        ani.save(filename, writer=writer)\n    except Exception as e:\n        warnings.warn(f\"Failed to save animation: {e}\")\n        print(\"To save animations, install pillow: pip install pillow\")\n</code></pre>"},{"location":"api/core/attractors/","title":"Attractors","text":"<p>Attractor detection and dynamical systems analysis for field time series.</p>"},{"location":"api/core/attractors/#recurrence-analysis","title":"Recurrence Analysis","text":""},{"location":"api/core/attractors/#mneme.core.attractors.RecurrenceAnalysis","title":"RecurrenceAnalysis","text":"<pre><code>RecurrenceAnalysis(threshold: float = 0.1, min_persistence: float = 0.1, embedding_dimension: int = 3, time_delay: int = 1)\n</code></pre> <p>               Bases: <code>BaseAttractorDetector</code></p> <p>Detect attractors using recurrence analysis.</p> <p>Initialize recurrence-based detector.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Recurrence threshold</p> <code>0.1</code> <code>min_persistence</code> <code>float</code> <p>Minimum attractor persistence</p> <code>0.1</code> <code>embedding_dimension</code> <code>int</code> <p>Embedding dimension for delay embedding</p> <code>3</code> <code>time_delay</code> <code>int</code> <p>Time delay for embedding</p> <code>1</code> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def __init__(\n    self,\n    threshold: float = 0.1,\n    min_persistence: float = 0.1,\n    embedding_dimension: int = 3,\n    time_delay: int = 1\n):\n    \"\"\"\n    Initialize recurrence-based detector.\n\n    Parameters\n    ----------\n    threshold : float\n        Recurrence threshold\n    min_persistence : float\n        Minimum attractor persistence\n    embedding_dimension : int\n        Embedding dimension for delay embedding\n    time_delay : int\n        Time delay for embedding\n    \"\"\"\n    super().__init__(threshold)\n    self.min_persistence = min_persistence\n    self.embedding_dimension = embedding_dimension\n    self.time_delay = time_delay\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.RecurrenceAnalysis.detect","title":"detect","text":"<pre><code>detect(trajectory: ndarray) -&gt; List[Attractor]\n</code></pre> <p>Detect attractors using recurrence analysis.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def detect(self, trajectory: np.ndarray) -&gt; List[Attractor]:\n    \"\"\"Detect attractors using recurrence analysis.\"\"\"\n    # Embed trajectory if needed\n    if trajectory.ndim == 1:\n        embedded_trajectory = embed_trajectory(trajectory, self.embedding_dimension, self.time_delay)\n    else:\n        embedded_trajectory = trajectory\n\n    # Compute recurrence matrix\n    recurrence_matrix = self.compute_recurrence_matrix(embedded_trajectory)\n\n    # Find recurrent regions\n    recurrent_regions = self._find_recurrent_regions(recurrence_matrix)\n\n    # Cluster trajectory points to find attractors\n    attractors = self._cluster_attractors(embedded_trajectory, recurrent_regions)\n\n    return attractors\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.RecurrenceAnalysis.characterize","title":"characterize","text":"<pre><code>characterize(attractor: Attractor, trajectory: ndarray) -&gt; Dict[str, Any]\n</code></pre> <p>Characterize attractor using recurrence quantification.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def characterize(self, attractor: Attractor, trajectory: np.ndarray) -&gt; Dict[str, Any]:\n    \"\"\"Characterize attractor using recurrence quantification.\"\"\"\n    if attractor.trajectory_indices is None:\n        return {}\n\n    # Extract attractor trajectory\n    attractor_trajectory = trajectory[attractor.trajectory_indices]\n\n    # Compute recurrence matrix for attractor\n    recurrence_matrix = self.compute_recurrence_matrix(attractor_trajectory)\n\n    # Recurrence quantification analysis\n    properties = {}\n\n    # Recurrence rate\n    properties['recurrence_rate'] = np.sum(recurrence_matrix) / recurrence_matrix.size\n\n    # Determinism (fraction of recurrent points forming diagonal lines)\n    properties['determinism'] = self._compute_determinism(recurrence_matrix)\n\n    # Average diagonal line length\n    properties['avg_diagonal_length'] = self._compute_avg_diagonal_length(recurrence_matrix)\n\n    # Laminarity (fraction of recurrent points forming vertical lines)\n    properties['laminarity'] = self._compute_laminarity(recurrence_matrix)\n\n    # Entropy of diagonal line lengths\n    properties['entropy'] = self._compute_entropy(recurrence_matrix)\n\n    return properties\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.RecurrenceAnalysis.compute_recurrence_matrix","title":"compute_recurrence_matrix","text":"<pre><code>compute_recurrence_matrix(trajectory: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute recurrence matrix for trajectory.</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>ndarray</code> <p>Input trajectory</p> required <p>Returns:</p> Name Type Description <code>recurrence_matrix</code> <code>ndarray</code> <p>Binary recurrence matrix</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def compute_recurrence_matrix(self, trajectory: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute recurrence matrix for trajectory.\n\n    Parameters\n    ----------\n    trajectory : np.ndarray\n        Input trajectory\n\n    Returns\n    -------\n    recurrence_matrix : np.ndarray\n        Binary recurrence matrix\n    \"\"\"\n    from scipy.spatial.distance import pdist, squareform\n\n    n_points = len(trajectory)\n\n    # Compute pairwise distances\n    distances = squareform(pdist(trajectory))\n\n    # Create recurrence matrix\n    recurrence_matrix = distances &lt; self.threshold\n\n    return recurrence_matrix.astype(int)\n</code></pre>"},{"location":"api/core/attractors/#lyapunov-analysis","title":"Lyapunov Analysis","text":""},{"location":"api/core/attractors/#mneme.core.attractors.LyapunovAnalysis","title":"LyapunovAnalysis","text":"<pre><code>LyapunovAnalysis(threshold: float = 0.1, n_neighbors: int = 10, evolution_time: int = 10)\n</code></pre> <p>               Bases: <code>BaseAttractorDetector</code></p> <p>Detect and characterize attractors using Lyapunov exponents.</p> <p>Initialize Lyapunov-based detector.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Detection threshold</p> <code>0.1</code> <code>n_neighbors</code> <code>int</code> <p>Number of neighbors for local analysis</p> <code>10</code> <code>evolution_time</code> <code>int</code> <p>Time steps for evolution</p> <code>10</code> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def __init__(\n    self,\n    threshold: float = 0.1,\n    n_neighbors: int = 10,\n    evolution_time: int = 10\n):\n    \"\"\"\n    Initialize Lyapunov-based detector.\n\n    Parameters\n    ----------\n    threshold : float\n        Detection threshold\n    n_neighbors : int\n        Number of neighbors for local analysis\n    evolution_time : int\n        Time steps for evolution\n    \"\"\"\n    super().__init__(threshold)\n    self.n_neighbors = n_neighbors\n    self.evolution_time = evolution_time\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.LyapunovAnalysis.detect","title":"detect","text":"<pre><code>detect(trajectory: ndarray) -&gt; List[Attractor]\n</code></pre> <p>Detect attractors using Lyapunov analysis.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def detect(self, trajectory: np.ndarray) -&gt; List[Attractor]:\n    \"\"\"Detect attractors using Lyapunov analysis.\"\"\"\n    # Embed trajectory if needed\n    if trajectory.ndim == 1:\n        embedded_trajectory = embed_trajectory(trajectory, 3, 1)\n    else:\n        embedded_trajectory = trajectory\n\n    # Compute local Lyapunov exponents\n    lyapunov_exponents = self._compute_local_lyapunov_exponents(embedded_trajectory)\n\n    # Find regions with negative Lyapunov exponents (attracting regions)\n    attracting_regions = lyapunov_exponents &lt; -self.threshold\n\n    # Cluster attracting regions\n    attractors = self._cluster_attracting_regions(embedded_trajectory, attracting_regions, lyapunov_exponents)\n\n    return attractors\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.LyapunovAnalysis.characterize","title":"characterize","text":"<pre><code>characterize(attractor: Attractor, trajectory: ndarray) -&gt; Dict[str, Any]\n</code></pre> <p>Compute basic Lyapunov characterization for an attractor (MVP).</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def characterize(self, attractor: Attractor, trajectory: np.ndarray) -&gt; Dict[str, Any]:\n    \"\"\"Compute basic Lyapunov characterization for an attractor (MVP).\"\"\"\n    if attractor.trajectory_indices is None or len(attractor.trajectory_indices) == 0:\n        return {}\n    indices = np.asarray(attractor.trajectory_indices)\n    local_exponents = self._compute_local_lyapunov_exponents(trajectory)\n    valid = indices[indices &lt; len(local_exponents)]\n    if len(valid) == 0:\n        return {}\n    vals = local_exponents[valid]\n    mean_lyap = float(np.mean(vals))\n    stability = 'attracting' if mean_lyap &lt; -self.threshold else 'neutral' if mean_lyap &lt; self.threshold else 'repelling'\n    return {'mean_lyapunov': mean_lyap, 'stability': stability}\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.LyapunovAnalysis.compute_lyapunov_spectrum","title":"compute_lyapunov_spectrum","text":"<pre><code>compute_lyapunov_spectrum(trajectory: ndarray, dt: float = 1.0, n_exponents: Optional[int] = None) -&gt; np.ndarray\n</code></pre> <p>Compute Lyapunov exponent spectrum using the Wolf algorithm.</p> <p>The Lyapunov spectrum characterizes the rate of separation of infinitesimally close trajectories. A positive exponent indicates chaos, while all negative exponents indicate a stable attractor.</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>ndarray</code> <p>Input trajectory, shape (n_timesteps, n_dimensions)</p> required <code>dt</code> <code>float</code> <p>Time step between observations</p> <code>1.0</code> <code>n_exponents</code> <code>int</code> <p>Number of exponents to compute. If None, computes all (equal to embedding dimension).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>spectrum</code> <code>ndarray</code> <p>Lyapunov exponents in descending order (largest first)</p> Notes <p>Uses the Wolf algorithm with QR decomposition for orthogonalization. The algorithm estimates local Jacobians from the trajectory data and tracks the evolution of perturbation vectors.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def compute_lyapunov_spectrum(\n    self,\n    trajectory: np.ndarray,\n    dt: float = 1.0,\n    n_exponents: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute Lyapunov exponent spectrum using the Wolf algorithm.\n\n    The Lyapunov spectrum characterizes the rate of separation of\n    infinitesimally close trajectories. A positive exponent indicates\n    chaos, while all negative exponents indicate a stable attractor.\n\n    Parameters\n    ----------\n    trajectory : np.ndarray\n        Input trajectory, shape (n_timesteps, n_dimensions)\n    dt : float\n        Time step between observations\n    n_exponents : int, optional\n        Number of exponents to compute. If None, computes all\n        (equal to embedding dimension).\n\n    Returns\n    -------\n    spectrum : np.ndarray\n        Lyapunov exponents in descending order (largest first)\n\n    Notes\n    -----\n    Uses the Wolf algorithm with QR decomposition for orthogonalization.\n    The algorithm estimates local Jacobians from the trajectory data\n    and tracks the evolution of perturbation vectors.\n    \"\"\"\n    return compute_lyapunov_spectrum(\n        trajectory, \n        dt=dt, \n        n_exponents=n_exponents,\n        n_neighbors=self.n_neighbors\n    )\n</code></pre>"},{"location":"api/core/attractors/#convenience-functions","title":"Convenience Functions","text":""},{"location":"api/core/attractors/#mneme.core.attractors.compute_lyapunov_spectrum","title":"compute_lyapunov_spectrum","text":"<pre><code>compute_lyapunov_spectrum(trajectory: ndarray, dt: float = 1.0, n_exponents: Optional[int] = None, n_neighbors: int = 10, orthog_interval: int = 10) -&gt; np.ndarray\n</code></pre> <p>Compute Lyapunov exponent spectrum from trajectory data.</p> <p>Uses the Wolf algorithm with data-driven Jacobian estimation. The algorithm tracks how perturbation vectors grow or shrink along the trajectory, using QR decomposition for orthogonalization.</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>ndarray</code> <p>Phase space trajectory, shape (n_timesteps, n_dimensions). Can also be 1D, in which case delay embedding is applied.</p> required <code>dt</code> <code>float</code> <p>Time step between observations</p> <code>1.0</code> <code>n_exponents</code> <code>int</code> <p>Number of exponents to compute. If None, computes all (equal to embedding dimension).</p> <code>None</code> <code>n_neighbors</code> <code>int</code> <p>Number of neighbors for local Jacobian estimation</p> <code>10</code> <code>orthog_interval</code> <code>int</code> <p>Number of steps between QR orthogonalizations</p> <code>10</code> <p>Returns:</p> Name Type Description <code>spectrum</code> <code>ndarray</code> <p>Lyapunov exponents in descending order (largest first). Positive values indicate chaos, negative indicate stability.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; # Lorenz attractor trajectory (chaotic)\n&gt;&gt;&gt; # spectrum = compute_lyapunov_spectrum(lorenz_trajectory, dt=0.01)\n&gt;&gt;&gt; # Expect: [+, 0, -] pattern for Lorenz\n</code></pre> <pre><code>&gt;&gt;&gt; # Simple oscillator (non-chaotic)\n&gt;&gt;&gt; t = np.linspace(0, 100, 10000)\n&gt;&gt;&gt; trajectory = np.column_stack([np.sin(t), np.cos(t)])\n&gt;&gt;&gt; spectrum = compute_lyapunov_spectrum(trajectory, dt=0.01)\n&gt;&gt;&gt; # Expect: all exponents \u2264 0\n</code></pre> Notes <p>The algorithm: 1. Estimates local Jacobians using least-squares on neighbors 2. Propagates perturbation vectors using these Jacobians 3. Applies QR decomposition periodically to orthogonalize 4. Averages log growth rates to get Lyapunov exponents</p> <p>For reliable results, trajectory should be long (&gt;1000 points) and well-sampled relative to the dynamics.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def compute_lyapunov_spectrum(\n    trajectory: np.ndarray,\n    dt: float = 1.0,\n    n_exponents: Optional[int] = None,\n    n_neighbors: int = 10,\n    orthog_interval: int = 10,\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute Lyapunov exponent spectrum from trajectory data.\n\n    Uses the Wolf algorithm with data-driven Jacobian estimation.\n    The algorithm tracks how perturbation vectors grow or shrink\n    along the trajectory, using QR decomposition for orthogonalization.\n\n    Parameters\n    ----------\n    trajectory : np.ndarray\n        Phase space trajectory, shape (n_timesteps, n_dimensions).\n        Can also be 1D, in which case delay embedding is applied.\n    dt : float\n        Time step between observations\n    n_exponents : int, optional\n        Number of exponents to compute. If None, computes all\n        (equal to embedding dimension).\n    n_neighbors : int\n        Number of neighbors for local Jacobian estimation\n    orthog_interval : int\n        Number of steps between QR orthogonalizations\n\n    Returns\n    -------\n    spectrum : np.ndarray\n        Lyapunov exponents in descending order (largest first).\n        Positive values indicate chaos, negative indicate stability.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; # Lorenz attractor trajectory (chaotic)\n    &gt;&gt;&gt; # spectrum = compute_lyapunov_spectrum(lorenz_trajectory, dt=0.01)\n    &gt;&gt;&gt; # Expect: [+, 0, -] pattern for Lorenz\n\n    &gt;&gt;&gt; # Simple oscillator (non-chaotic)\n    &gt;&gt;&gt; t = np.linspace(0, 100, 10000)\n    &gt;&gt;&gt; trajectory = np.column_stack([np.sin(t), np.cos(t)])\n    &gt;&gt;&gt; spectrum = compute_lyapunov_spectrum(trajectory, dt=0.01)\n    &gt;&gt;&gt; # Expect: all exponents \u2264 0\n\n    Notes\n    -----\n    The algorithm:\n    1. Estimates local Jacobians using least-squares on neighbors\n    2. Propagates perturbation vectors using these Jacobians\n    3. Applies QR decomposition periodically to orthogonalize\n    4. Averages log growth rates to get Lyapunov exponents\n\n    For reliable results, trajectory should be long (&gt;1000 points)\n    and well-sampled relative to the dynamics.\n    \"\"\"\n    from scipy.spatial import cKDTree\n\n    # Handle 1D input via delay embedding\n    if trajectory.ndim == 1:\n        trajectory = embed_trajectory(trajectory, embedding_dimension=3, time_delay=1)\n\n    n_points, n_dims = trajectory.shape\n\n    if n_exponents is None:\n        n_exponents = n_dims\n    n_exponents = min(n_exponents, n_dims)\n\n    if n_points &lt; MIN_TRAJECTORY_LENGTH:\n        raise ValueError(\n            f\"Trajectory too short ({n_points} points). \"\n            f\"Need at least {MIN_TRAJECTORY_LENGTH} points.\"\n        )\n\n    # Build KD-tree for neighbor queries\n    tree = cKDTree(trajectory[:-1])  # Exclude last point (no successor)\n\n    # Initialize perturbation vectors as orthonormal basis\n    Q = np.eye(n_dims, n_exponents)  # n_dims x n_exponents\n\n    # Track cumulative growth for each exponent\n    lyapunov_sums = np.zeros(n_exponents)\n    n_orthog = 0\n\n    # Process trajectory step by step, orthogonalizing periodically\n    steps_since_orthog = 0\n\n    for i in range(n_points - 2):\n        # Estimate local Jacobian (flow map derivative)\n        J_local = _estimate_local_jacobian(trajectory, i, tree, n_neighbors, dt)\n\n        if J_local is None:\n            continue\n\n        # Propagate perturbation vectors: Q_new = J @ Q\n        # J is already the flow map derivative (not d/dt), so we just multiply\n        Q = J_local @ Q\n\n        steps_since_orthog += 1\n\n        # Periodically orthogonalize using QR\n        if steps_since_orthog &gt;= orthog_interval:\n            Q, R = np.linalg.qr(Q)\n\n            # Accumulate log of diagonal elements (growth factors)\n            for k in range(n_exponents):\n                r_kk = abs(R[k, k])\n                if r_kk &gt; 1e-10:\n                    lyapunov_sums[k] += np.log(r_kk)\n\n            n_orthog += 1\n            steps_since_orthog = 0\n\n    if n_orthog == 0:\n        raise ValueError(\"Could not compute Jacobians. Check trajectory quality.\")\n\n    # Compute Lyapunov exponents\n    # Each orthogonalization covers orthog_interval time steps\n    total_time = n_orthog * orthog_interval * dt\n    spectrum = lyapunov_sums / total_time\n\n    # Sort in descending order (largest first)\n    spectrum = np.sort(spectrum)[::-1]\n\n    return spectrum\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.classify_attractor_by_lyapunov","title":"classify_attractor_by_lyapunov","text":"<pre><code>classify_attractor_by_lyapunov(spectrum: ndarray, tolerance: float = 0.01) -&gt; AttractorType\n</code></pre> <p>Classify attractor type based on Lyapunov spectrum.</p> <p>Parameters:</p> Name Type Description Default <code>spectrum</code> <code>ndarray</code> <p>Lyapunov exponents (largest first)</p> required <code>tolerance</code> <code>float</code> <p>Threshold for considering an exponent as zero</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>attractor_type</code> <code>AttractorType</code> <p>Classification based on spectrum pattern</p> Notes <p>Classification rules: - Fixed point: all exponents &lt; -tolerance - Limit cycle: one exponent \u2248 0, rest &lt; 0 - Quasi-periodic (torus): two exponents \u2248 0, rest &lt; 0 - Strange attractor: at least one exponent &gt; tolerance</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def classify_attractor_by_lyapunov(spectrum: np.ndarray, tolerance: float = 0.01) -&gt; AttractorType:\n    \"\"\"\n    Classify attractor type based on Lyapunov spectrum.\n\n    Parameters\n    ----------\n    spectrum : np.ndarray\n        Lyapunov exponents (largest first)\n    tolerance : float\n        Threshold for considering an exponent as zero\n\n    Returns\n    -------\n    attractor_type : AttractorType\n        Classification based on spectrum pattern\n\n    Notes\n    -----\n    Classification rules:\n    - Fixed point: all exponents &lt; -tolerance\n    - Limit cycle: one exponent \u2248 0, rest &lt; 0\n    - Quasi-periodic (torus): two exponents \u2248 0, rest &lt; 0\n    - Strange attractor: at least one exponent &gt; tolerance\n    \"\"\"\n    n_zero = np.sum(np.abs(spectrum) &lt; tolerance)\n    n_positive = np.sum(spectrum &gt; tolerance)\n    n_negative = np.sum(spectrum &lt; -tolerance)\n\n    if n_positive &gt; 0:\n        return AttractorType.STRANGE\n    elif n_zero == 0:\n        return AttractorType.FIXED_POINT\n    elif n_zero == 1:\n        return AttractorType.LIMIT_CYCLE\n    elif n_zero &gt;= 2:\n        return AttractorType.QUASI_PERIODIC\n    else:\n        return AttractorType.LIMIT_CYCLE\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.kaplan_yorke_dimension","title":"kaplan_yorke_dimension","text":"<pre><code>kaplan_yorke_dimension(spectrum: ndarray) -&gt; float\n</code></pre> <p>Compute Kaplan-Yorke (Lyapunov) dimension from spectrum.</p> <p>The Kaplan-Yorke dimension provides an estimate of the attractor's fractal dimension based on Lyapunov exponents.</p> <p>Parameters:</p> Name Type Description Default <code>spectrum</code> <code>ndarray</code> <p>Lyapunov exponents in descending order</p> required <p>Returns:</p> Name Type Description <code>dimension</code> <code>float</code> <p>Kaplan-Yorke dimension estimate</p> Notes <p>D_KY = j + (\u03bb_1 + \u03bb_2 + ... + \u03bb_j) / |\u03bb_{j+1}|</p> <p>where j is the largest index such that the sum of the first j exponents is non-negative.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def kaplan_yorke_dimension(spectrum: np.ndarray) -&gt; float:\n    \"\"\"\n    Compute Kaplan-Yorke (Lyapunov) dimension from spectrum.\n\n    The Kaplan-Yorke dimension provides an estimate of the\n    attractor's fractal dimension based on Lyapunov exponents.\n\n    Parameters\n    ----------\n    spectrum : np.ndarray\n        Lyapunov exponents in descending order\n\n    Returns\n    -------\n    dimension : float\n        Kaplan-Yorke dimension estimate\n\n    Notes\n    -----\n    D_KY = j + (\u03bb_1 + \u03bb_2 + ... + \u03bb_j) / |\u03bb_{j+1}|\n\n    where j is the largest index such that the sum of the first j\n    exponents is non-negative.\n    \"\"\"\n    spectrum = np.sort(spectrum)[::-1]  # Ensure descending order\n\n    # Find j: largest index where cumsum is still non-negative\n    cumsum = np.cumsum(spectrum)\n    j_indices = np.where(cumsum &gt;= 0)[0]\n\n    if len(j_indices) == 0:\n        return 0.0\n\n    j = j_indices[-1]\n\n    if j &gt;= len(spectrum) - 1:\n        # All exponents sum to non-negative (rare)\n        return float(len(spectrum))\n\n    # D_KY = j + sum(\u03bb_1..\u03bb_j) / |\u03bb_{j+1}|\n    if abs(spectrum[j + 1]) &lt; 1e-10:\n        return float(j + 1)\n\n    dimension = (j + 1) + cumsum[j] / abs(spectrum[j + 1])\n\n    return max(0.0, dimension)\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.compute_correlation_dimension","title":"compute_correlation_dimension","text":"<pre><code>compute_correlation_dimension(trajectory: ndarray, r_min: float = 0.01, r_max: float = 1.0, n_points: int = 20) -&gt; float\n</code></pre> <p>Compute correlation dimension of attractor.</p> <p>Parameters:</p> Name Type Description Default <code>trajectory</code> <code>ndarray</code> <p>Phase space trajectory</p> required <code>r_min</code> <code>float</code> <p>Range of distances to consider</p> <code>0.01</code> <code>r_max</code> <code>float</code> <p>Range of distances to consider</p> <code>0.01</code> <code>n_points</code> <code>int</code> <p>Number of distance values</p> <code>20</code> <p>Returns:</p> Name Type Description <code>dimension</code> <code>float</code> <p>Correlation dimension</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def compute_correlation_dimension(\n    trajectory: np.ndarray,\n    r_min: float = 0.01,\n    r_max: float = 1.0,\n    n_points: int = 20\n) -&gt; float:\n    \"\"\"\n    Compute correlation dimension of attractor.\n\n    Parameters\n    ----------\n    trajectory : np.ndarray\n        Phase space trajectory\n    r_min, r_max : float\n        Range of distances to consider\n    n_points : int\n        Number of distance values\n\n    Returns\n    -------\n    dimension : float\n        Correlation dimension\n    \"\"\"\n    from scipy.spatial.distance import pdist\n\n    # Compute pairwise distances\n    distances = pdist(trajectory)\n\n    # Automatically adjust range if needed\n    if r_min == 0.01 and r_max == 1.0:\n        r_min = np.percentile(distances, 1)\n        r_max = np.percentile(distances, 50)\n\n    # Create distance scales\n    scales = np.logspace(np.log10(r_min), np.log10(r_max), n_points)\n\n    # Compute correlation sums\n    correlation_sums = []\n\n    for scale in scales:\n        # Count pairs within scale\n        count = np.sum(distances &lt; scale)\n        correlation_sum = count / len(distances)\n        correlation_sums.append(correlation_sum)\n\n    # Estimate dimension from slope\n    log_scales = np.log(scales)\n    log_sums = np.log(np.array(correlation_sums) + 1e-10)\n\n    # Linear regression on the linear part\n    if len(log_scales) &gt; 2:\n        # Find linear region (middle part)\n        start_idx = len(log_scales) // 4\n        end_idx = 3 * len(log_scales) // 4\n\n        slope = np.polyfit(log_scales[start_idx:end_idx], log_sums[start_idx:end_idx], 1)[0]\n        return max(0, slope)\n    else:\n        return 0.0\n</code></pre>"},{"location":"api/core/attractors/#clustering-based-detection","title":"Clustering-Based Detection","text":""},{"location":"api/core/attractors/#mneme.core.attractors.ClusteringDetector","title":"ClusteringDetector","text":"<pre><code>ClusteringDetector(threshold: float = 0.1, min_samples: int = 10, clustering_method: str = 'dbscan')\n</code></pre> <p>               Bases: <code>BaseAttractorDetector</code></p> <p>Detect attractors using density-based clustering.</p> <p>Initialize clustering-based detector.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>Detection threshold</p> <code>0.1</code> <code>min_samples</code> <code>int</code> <p>Minimum samples per cluster</p> <code>10</code> <code>clustering_method</code> <code>str</code> <p>Clustering algorithm to use</p> <code>'dbscan'</code> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def __init__(\n    self,\n    threshold: float = 0.1,\n    min_samples: int = 10,\n    clustering_method: str = \"dbscan\"\n):\n    \"\"\"\n    Initialize clustering-based detector.\n\n    Parameters\n    ----------\n    threshold : float\n        Detection threshold\n    min_samples : int\n        Minimum samples per cluster\n    clustering_method : str\n        Clustering algorithm to use\n    \"\"\"\n    super().__init__(threshold)\n    self.min_samples = min_samples\n    self.clustering_method = clustering_method\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.ClusteringDetector.detect","title":"detect","text":"<pre><code>detect(trajectory: ndarray) -&gt; List[Attractor]\n</code></pre> <p>Detect attractors using clustering.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def detect(self, trajectory: np.ndarray) -&gt; List[Attractor]:\n    \"\"\"Detect attractors using clustering.\"\"\"\n    from sklearn.cluster import DBSCAN\n\n    # Embed trajectory if needed\n    if trajectory.ndim == 1:\n        embedded_trajectory = embed_trajectory(trajectory, 3, 1)\n    else:\n        embedded_trajectory = trajectory\n\n    # Apply clustering\n    if self.clustering_method == \"dbscan\":\n        clustering = DBSCAN(eps=self.threshold, min_samples=self.min_samples)\n        labels = clustering.fit_predict(embedded_trajectory)\n    else:\n        from sklearn.cluster import KMeans\n        # Estimate number of clusters\n        n_clusters = max(2, min(10, len(embedded_trajectory) // 50))\n        clustering = KMeans(n_clusters=n_clusters, random_state=42)\n        labels = clustering.fit_predict(embedded_trajectory)\n\n    # Convert clusters to attractors\n    attractors = []\n\n    for label in np.unique(labels):\n        if label == -1:  # Noise in DBSCAN\n            continue\n\n        cluster_mask = labels == label\n        cluster_points = embedded_trajectory[cluster_mask]\n        cluster_indices = np.where(cluster_mask)[0]\n\n        if len(cluster_points) &lt; self.min_samples:\n            continue\n\n        # Compute attractor properties\n        center = np.mean(cluster_points, axis=0)\n        basin_size = len(cluster_points) / len(embedded_trajectory)\n\n        # Estimate attractor dimension using correlation dimension\n        dimension = self._estimate_correlation_dimension(cluster_points)\n\n        # Classify attractor type based on point distribution\n        attractor_type = self._classify_attractor_by_clustering(cluster_points)\n\n        attractor = Attractor(\n            type=attractor_type,\n            center=center,\n            basin_size=basin_size,\n            dimension=dimension,\n            trajectory_indices=cluster_indices.tolist()\n        )\n\n        attractors.append(attractor)\n\n    return attractors\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.ClusteringDetector.characterize","title":"characterize","text":"<pre><code>characterize(attractor: Attractor, trajectory: ndarray) -&gt; Dict[str, Any]\n</code></pre> <p>Characterize attractor geometry using clustering (MVP).</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def characterize(self, attractor: Attractor, trajectory: np.ndarray) -&gt; Dict[str, Any]:\n    \"\"\"Characterize attractor geometry using clustering (MVP).\"\"\"\n    if attractor.trajectory_indices is None or len(attractor.trajectory_indices) == 0:\n        return {}\n    pts = trajectory[np.asarray(attractor.trajectory_indices)]\n    centroid = np.mean(pts, axis=0)\n    dists = np.linalg.norm(pts - centroid, axis=1)\n    return {\n        'radius_mean': float(np.mean(dists)),\n        'radius_std': float(np.std(dists)),\n        'num_points': int(len(pts)),\n    }\n</code></pre>"},{"location":"api/core/attractors/#dispatcher","title":"Dispatcher","text":""},{"location":"api/core/attractors/#mneme.core.attractors.AttractorDetector","title":"AttractorDetector","text":"<pre><code>AttractorDetector(method: str = 'recurrence', threshold: float = 0.1, **kwargs)\n</code></pre> <p>Main attractor detection class combining multiple methods.</p> <p>Initialize attractor detector.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Detection method ('recurrence', 'lyapunov', 'clustering')</p> <code>'recurrence'</code> <code>threshold</code> <code>float</code> <p>Detection threshold</p> <code>0.1</code> <code>**kwargs</code> <p>Method-specific parameters</p> <code>{}</code> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def __init__(\n    self,\n    method: str = \"recurrence\",\n    threshold: float = 0.1,\n    **kwargs\n):\n    \"\"\"\n    Initialize attractor detector.\n\n    Parameters\n    ----------\n    method : str\n        Detection method ('recurrence', 'lyapunov', 'clustering')\n    threshold : float\n        Detection threshold\n    **kwargs\n        Method-specific parameters\n    \"\"\"\n    self.method = method\n    self.threshold = threshold\n    self.method_params = kwargs\n    self._detector = self._initialize_detector()\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.AttractorDetector.detect","title":"detect","text":"<pre><code>detect(trajectory: ndarray) -&gt; List[Attractor]\n</code></pre> <p>Detect attractors in trajectory.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def detect(self, trajectory: np.ndarray) -&gt; List[Attractor]:\n    \"\"\"Detect attractors in trajectory.\"\"\"\n    return self._detector.detect(trajectory)\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.AttractorDetector.characterize","title":"characterize","text":"<pre><code>characterize(attractor: Attractor, trajectory: ndarray) -&gt; Dict[str, Any]\n</code></pre> <p>Characterize attractor properties.</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def characterize(self, attractor: Attractor, trajectory: np.ndarray) -&gt; Dict[str, Any]:\n    \"\"\"Characterize attractor properties.\"\"\"\n    return self._detector.characterize(attractor, trajectory)\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.AttractorDetector.classify_attractor","title":"classify_attractor","text":"<pre><code>classify_attractor(attractor: Attractor) -&gt; AttractorType\n</code></pre> <p>Classify attractor type based on simple heuristics (MVP).</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def classify_attractor(self, attractor: Attractor) -&gt; AttractorType:\n    \"\"\"Classify attractor type based on simple heuristics (MVP).\"\"\"\n    if attractor.dimension is not None:\n        if attractor.dimension &lt; 0.2:\n            return AttractorType.FIXED_POINT\n        if attractor.dimension &lt; 1.2:\n            return AttractorType.LIMIT_CYCLE\n        return AttractorType.STRANGE\n    if attractor.lyapunov_exponents is not None and len(attractor.lyapunov_exponents) &gt; 0:\n        lyap = float(np.mean(attractor.lyapunov_exponents))\n        if lyap &lt; -0.1:\n            return AttractorType.FIXED_POINT\n        if lyap &lt; 0.05:\n            return AttractorType.LIMIT_CYCLE\n        return AttractorType.STRANGE\n    if attractor.basin_size &lt; 0.02:\n        return AttractorType.FIXED_POINT\n    return AttractorType.LIMIT_CYCLE\n</code></pre>"},{"location":"api/core/attractors/#embedding-utilities","title":"Embedding Utilities","text":""},{"location":"api/core/attractors/#mneme.core.attractors.embed_trajectory","title":"embed_trajectory","text":"<pre><code>embed_trajectory(time_series: TimeSeries, embedding_dimension: int, time_delay: int) -&gt; np.ndarray\n</code></pre> <p>Create delay embedding of time series.</p> <p>Parameters:</p> Name Type Description Default <code>time_series</code> <code>ndarray</code> <p>Input time series, shape (n_timesteps,) or (n_timesteps, n_features)</p> required <code>embedding_dimension</code> <code>int</code> <p>Embedding dimension</p> required <code>time_delay</code> <code>int</code> <p>Time delay</p> required <p>Returns:</p> Name Type Description <code>embedded</code> <code>ndarray</code> <p>Embedded trajectory</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def embed_trajectory(\n    time_series: TimeSeries,\n    embedding_dimension: int,\n    time_delay: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Create delay embedding of time series.\n\n    Parameters\n    ----------\n    time_series : np.ndarray\n        Input time series, shape (n_timesteps,) or (n_timesteps, n_features)\n    embedding_dimension : int\n        Embedding dimension\n    time_delay : int\n        Time delay\n\n    Returns\n    -------\n    embedded : np.ndarray\n        Embedded trajectory\n    \"\"\"\n    if time_series.ndim == 1:\n        time_series = time_series.reshape(-1, 1)\n\n    n_points = len(time_series) - (embedding_dimension - 1) * time_delay\n    if n_points &lt;= 0:\n        raise ValueError(\"Time series too short for embedding\")\n\n    embedded = np.zeros((n_points, embedding_dimension * time_series.shape[1]))\n\n    for i in range(embedding_dimension):\n        start_idx = i * time_delay\n        end_idx = start_idx + n_points\n        dim_slice = slice(i * time_series.shape[1], (i + 1) * time_series.shape[1])\n        embedded[:, dim_slice] = time_series[start_idx:end_idx]\n\n    return embedded\n</code></pre>"},{"location":"api/core/attractors/#mneme.core.attractors.estimate_embedding_parameters","title":"estimate_embedding_parameters","text":"<pre><code>estimate_embedding_parameters(time_series: TimeSeries, max_dimension: int = 10, max_delay: int = 100) -&gt; Tuple[int, int]\n</code></pre> <p>Estimate optimal embedding dimension and time delay.</p> <p>Parameters:</p> Name Type Description Default <code>time_series</code> <code>ndarray</code> <p>Input time series</p> required <code>max_dimension</code> <code>int</code> <p>Maximum dimension to test</p> <code>10</code> <code>max_delay</code> <code>int</code> <p>Maximum delay to test</p> <code>100</code> <p>Returns:</p> Name Type Description <code>embedding_dimension</code> <code>int</code> <p>Optimal embedding dimension</p> <code>time_delay</code> <code>int</code> <p>Optimal time delay</p> Source code in <code>src/mneme/core/attractors.py</code> <pre><code>def estimate_embedding_parameters(\n    time_series: TimeSeries,\n    max_dimension: int = 10,\n    max_delay: int = 100\n) -&gt; Tuple[int, int]:\n    \"\"\"\n    Estimate optimal embedding dimension and time delay.\n\n    Parameters\n    ----------\n    time_series : np.ndarray\n        Input time series\n    max_dimension : int\n        Maximum dimension to test\n    max_delay : int\n        Maximum delay to test\n\n    Returns\n    -------\n    embedding_dimension : int\n        Optimal embedding dimension\n    time_delay : int\n        Optimal time delay\n    \"\"\"\n    if time_series.ndim &gt; 1:\n        time_series = time_series.flatten()\n\n    # Estimate time delay using first minimum of mutual information\n    time_delay = _estimate_time_delay_mutual_info(time_series, max_delay)\n\n    # Estimate embedding dimension using false nearest neighbors\n    embedding_dimension = _estimate_dimension_fnn(time_series, time_delay, max_dimension)\n\n    return embedding_dimension, time_delay\n</code></pre>"},{"location":"api/core/field_theory/","title":"Field Theory","text":"<p>Field reconstruction from sparse observations using Gaussian Processes, Information Field Theory, and Neural Fields.</p>"},{"location":"api/core/field_theory/#factory-function","title":"Factory Function","text":""},{"location":"api/core/field_theory/#mneme.core.field_theory.create_reconstructor","title":"create_reconstructor","text":"<pre><code>create_reconstructor(method: str = 'ift', resolution: Tuple[int, int] = (256, 256), **kwargs) -&gt; BaseFieldReconstructor\n</code></pre> <p>Factory function to create field reconstructors.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Reconstruction method: - 'ift' or 'sparse_gp': Sparse GP (scalable, default) - 'dense_ift': Dense matrix IFT (exact, slow) - 'gp' or 'gaussian_process': Standard GP - 'neural' or 'neural_field': Neural network</p> <code>'ift'</code> <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution</p> <code>(256, 256)</code> <code>**kwargs</code> <p>Method-specific parameters</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>reconstructor</code> <code>BaseFieldReconstructor</code> <p>Configured reconstructor</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def create_reconstructor(\n    method: str = \"ift\",\n    resolution: Tuple[int, int] = (256, 256),\n    **kwargs\n) -&gt; BaseFieldReconstructor:\n    \"\"\"\n    Factory function to create field reconstructors.\n\n    Parameters\n    ----------\n    method : str\n        Reconstruction method:\n        - 'ift' or 'sparse_gp': Sparse GP (scalable, default)\n        - 'dense_ift': Dense matrix IFT (exact, slow)\n        - 'gp' or 'gaussian_process': Standard GP\n        - 'neural' or 'neural_field': Neural network\n    resolution : Tuple[int, int]\n        Output field resolution\n    **kwargs\n        Method-specific parameters\n\n    Returns\n    -------\n    reconstructor : BaseFieldReconstructor\n        Configured reconstructor\n    \"\"\"\n    method_lower = method.lower()\n\n    if method_lower in ('ift', 'sparse_gp', 'sparse'):\n        return SparseGPReconstructor(resolution, **kwargs)\n    elif method_lower == 'dense_ift':\n        return DenseIFTReconstructor(resolution, **kwargs)\n    elif method_lower in ('gp', 'gaussian_process'):\n        return GaussianProcessReconstructor(resolution, **kwargs)\n    elif method_lower in ('neural', 'neural_field'):\n        return NeuralFieldReconstructor(resolution, **kwargs)\n    else:\n        raise ValueError(f\"Unknown reconstruction method: {method}\")\n</code></pre>"},{"location":"api/core/field_theory/#reconstructors","title":"Reconstructors","text":""},{"location":"api/core/field_theory/#mneme.core.field_theory.SparseGPReconstructor","title":"SparseGPReconstructor","text":"<pre><code>SparseGPReconstructor(resolution: Tuple[int, int] = (256, 256), n_inducing: int = 500, kernel: str = 'rbf', length_scale: float = 0.1, noise_level: float = 0.1, optimize_hyperparameters: bool = True, random_state: Optional[int] = None, correlation_length: Optional[float] = None, power_spectrum_model: Optional[str] = None)\n</code></pre> <p>               Bases: <code>BaseFieldReconstructor</code></p> <p>Sparse Gaussian Process reconstructor using inducing points.</p> <p>This is a scalable approximation to full GP regression that uses a subset of inducing points to approximate the full covariance structure. Complexity is O(nm\u00b2) instead of O(n\u00b3) where m &lt;&lt; n.</p> <p>This is the DEFAULT method for IFT reconstruction as it scales to large field sizes while maintaining good accuracy.</p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution</p> <code>(256, 256)</code> <code>n_inducing</code> <code>int</code> <p>Number of inducing points. More points = better accuracy but slower. Default 500 works well for most bioelectric fields.</p> <code>500</code> <code>kernel</code> <code>str</code> <p>Kernel type: 'rbf', 'matern', 'exponential'</p> <code>'rbf'</code> <code>length_scale</code> <code>float</code> <p>Kernel length scale (correlation length)</p> <code>0.1</code> <code>noise_level</code> <code>float</code> <p>Observation noise level</p> <code>0.1</code> <code>optimize_hyperparameters</code> <code>bool</code> <p>Whether to optimize kernel hyperparameters during fitting</p> <code>True</code> <code>random_state</code> <code>int</code> <p>Random seed for inducing point selection</p> <code>None</code> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def __init__(\n    self,\n    resolution: Tuple[int, int] = (256, 256),\n    n_inducing: int = 500,\n    kernel: str = \"rbf\",\n    length_scale: float = 0.1,\n    noise_level: float = 0.1,\n    optimize_hyperparameters: bool = True,\n    random_state: Optional[int] = None,\n    # Legacy parameter mapping from IFT\n    correlation_length: Optional[float] = None,\n    power_spectrum_model: Optional[str] = None,\n):\n    super().__init__(resolution)\n\n    self.n_inducing = n_inducing\n    self.optimize_hyperparameters = optimize_hyperparameters\n    self.random_state = random_state\n\n    # Map legacy IFT parameters\n    if correlation_length is not None:\n        # Convert from pixel-space to normalized [0,1] space\n        length_scale = correlation_length / max(resolution)\n    self.length_scale = length_scale\n\n    if power_spectrum_model is not None:\n        # Map power spectrum model to kernel type\n        kernel_map = {\n            'power_law': 'rbf',\n            'gaussian': 'rbf',\n            'exponential': 'matern',\n        }\n        kernel = kernel_map.get(power_spectrum_model, 'rbf')\n    self.kernel = kernel\n\n    self.noise_level = noise_level\n\n    # Internal state\n    self._gp = None\n    self._grid_points = None\n    self._last_predictions = None\n    self._last_std = None\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.SparseGPReconstructor.fit","title":"fit","text":"<pre><code>fit(observations: ndarray, positions: ndarray) -&gt; SparseGPReconstructor\n</code></pre> <p>Fit Sparse GP to observations using inducing points.</p> <p>For efficiency, we subsample the observations to create inducing points when the number of observations exceeds n_inducing.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'SparseGPReconstructor':\n    \"\"\"Fit Sparse GP to observations using inducing points.\n\n    For efficiency, we subsample the observations to create inducing points\n    when the number of observations exceeds n_inducing.\n    \"\"\"\n    from sklearn.gaussian_process import GaussianProcessRegressor\n\n    self.observations = observations\n    self.positions = positions\n    n_obs = len(observations)\n\n    # Normalize positions to [0, 1] for numerical stability\n    self._pos_min = positions.min(axis=0)\n    self._pos_max = positions.max(axis=0)\n    self._pos_range = self._pos_max - self._pos_min\n    self._pos_range[self._pos_range == 0] = 1.0  # Avoid division by zero\n\n    positions_norm = (positions - self._pos_min) / self._pos_range\n\n    # Select inducing points if we have more observations than n_inducing\n    if n_obs &gt; self.n_inducing:\n        rng = np.random.RandomState(self.random_state)\n        inducing_idx = rng.choice(n_obs, size=self.n_inducing, replace=False)\n        X_train = positions_norm[inducing_idx]\n        y_train = observations[inducing_idx]\n    else:\n        X_train = positions_norm\n        y_train = observations\n\n    # Normalize observations\n    self._y_mean = y_train.mean()\n    self._y_std = y_train.std()\n    if self._y_std == 0:\n        self._y_std = 1.0\n    y_train_norm = (y_train - self._y_mean) / self._y_std\n\n    # Create and fit GP\n    kernel = self._create_kernel()\n\n    self._gp = GaussianProcessRegressor(\n        kernel=kernel,\n        n_restarts_optimizer=5 if self.optimize_hyperparameters else 0,\n        normalize_y=False,  # We already normalized\n        random_state=self.random_state,\n    )\n\n    self._gp.fit(X_train, y_train_norm)\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.SparseGPReconstructor.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(grid_points: Optional[ndarray] = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct field using the fitted Sparse GP.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n    \"\"\"Reconstruct field using the fitted Sparse GP.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"SparseGP reconstructor must be fitted first\")\n\n    if grid_points is None:\n        grid_points = create_grid_points(self.resolution)\n\n    self._grid_points = grid_points\n\n    # Normalize grid points to same space as training data\n    grid_norm = (grid_points - self._pos_min) / self._pos_range\n\n    # Predict in batches for memory efficiency\n    batch_size = GP_PREDICTION_BATCH_SIZE\n    n_points = len(grid_norm)\n\n    predictions = np.zeros(n_points)\n    stds = np.zeros(n_points)\n\n    for i in range(0, n_points, batch_size):\n        batch = grid_norm[i:i+batch_size]\n        pred, std = self._gp.predict(batch, return_std=True)\n        predictions[i:i+batch_size] = pred\n        stds[i:i+batch_size] = std\n\n    # Denormalize predictions\n    predictions = predictions * self._y_std + self._y_mean\n    stds = stds * self._y_std\n\n    self._last_predictions = predictions\n    self._last_std = stds\n\n    # Reshape to 2D if using regular grid\n    if n_points == self.resolution[0] * self.resolution[1]:\n        return predictions.reshape(self.resolution)\n\n    return predictions\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.SparseGPReconstructor.uncertainty","title":"uncertainty","text":"<pre><code>uncertainty() -&gt; np.ndarray\n</code></pre> <p>Return uncertainty estimates from Sparse GP.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def uncertainty(self) -&gt; np.ndarray:\n    \"\"\"Return uncertainty estimates from Sparse GP.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"SparseGP reconstructor must be fitted first\")\n\n    if self._last_std is None:\n        # Need to run reconstruct first\n        self.reconstruct()\n\n    n_points = len(self._last_std)\n\n    if n_points == self.resolution[0] * self.resolution[1]:\n        return self._last_std.reshape(self.resolution)\n\n    return self._last_std\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.DenseIFTReconstructor","title":"DenseIFTReconstructor","text":"<pre><code>DenseIFTReconstructor(resolution: Tuple[int, int] = (256, 256), power_spectrum_model: str = 'gaussian', correlation_length: float = 10.0, noise_var: float = 0.1)\n</code></pre> <p>               Bases: <code>BaseFieldReconstructor</code></p> <p>Dense Information Field Theory based reconstruction.</p> <p>WARNING: This implementation uses full dense matrices and has O(n\u00b3) complexity. It will be very slow or run out of memory for large fields (e.g., 256\u00d7256 = 65K points requires ~34GB for covariance matrix).</p> <p>Use this only for: - Small fields (&lt; 64\u00d764) - When you need exact IFT computation - Educational/debugging purposes</p> <p>For production use with larger fields, use the default SparseGPReconstructor.</p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution</p> <code>(256, 256)</code> <code>power_spectrum_model</code> <code>str</code> <p>Power spectrum model ('power_law', 'gaussian', 'exponential')</p> <code>'gaussian'</code> <code>correlation_length</code> <code>float</code> <p>Correlation length scale in pixels</p> <code>10.0</code> <code>noise_var</code> <code>float</code> <p>Observation noise variance</p> <code>0.1</code> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def __init__(\n    self,\n    resolution: Tuple[int, int] = (256, 256),\n    power_spectrum_model: str = \"gaussian\",\n    correlation_length: float = 10.0,\n    noise_var: float = 0.1,\n):\n    super().__init__(resolution)\n    self.power_spectrum_model = power_spectrum_model\n    self.correlation_length = correlation_length\n    self.noise_var = noise_var\n\n    # Warn if resolution is too large\n    n_grid = resolution[0] * resolution[1]\n    if n_grid &gt; self.MAX_RECOMMENDED_SIZE:\n        warnings.warn(\n            f\"DenseIFTReconstructor with resolution {resolution} ({n_grid} points) \"\n            f\"will require {n_grid**2 * 8 / 1e9:.1f} GB of memory and be very slow. \"\n            f\"Consider using the default SparseGPReconstructor instead (method='ift').\",\n            UserWarning\n        )\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.DenseIFTReconstructor.fit","title":"fit","text":"<pre><code>fit(observations: ndarray, positions: ndarray) -&gt; DenseIFTReconstructor\n</code></pre> <p>Fit IFT model to observations using dense matrices.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'DenseIFTReconstructor':\n    \"\"\"Fit IFT model to observations using dense matrices.\"\"\"\n    self.observations = observations\n    self.positions = positions\n    self.n_observations = len(observations)\n\n    # Set up response operator matrix\n    self._setup_response_operator()\n\n    # Compute prior covariance\n    self._compute_prior_covariance()\n\n    # Compute posterior parameters\n    self._compute_posterior()\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.DenseIFTReconstructor.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(grid_points: Optional[ndarray] = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct field using dense IFT.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n    \"\"\"Reconstruct field using dense IFT.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"DenseIFT reconstructor must be fitted first\")\n\n    if grid_points is None:\n        field_1d = self.posterior_mean\n        return field_1d.reshape(self.resolution)\n    else:\n        from scipy.spatial import cKDTree\n        tree = cKDTree(self.grid_points)\n        _, indices = tree.query(grid_points)\n        field_1d = self.posterior_mean[indices]\n        return field_1d.reshape(self.resolution)\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.DenseIFTReconstructor.uncertainty","title":"uncertainty","text":"<pre><code>uncertainty() -&gt; np.ndarray\n</code></pre> <p>Compute IFT uncertainty estimates.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def uncertainty(self) -&gt; np.ndarray:\n    \"\"\"Compute IFT uncertainty estimates.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"DenseIFT reconstructor must be fitted first\")\n\n    uncertainty_1d = np.sqrt(np.diag(self.posterior_cov))\n    return uncertainty_1d.reshape(self.resolution)\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.GaussianProcessReconstructor","title":"GaussianProcessReconstructor","text":"<pre><code>GaussianProcessReconstructor(resolution: Tuple[int, int] = (256, 256), kernel: str = 'rbf', length_scale: float = 10.0, noise_level: float = 0.1)\n</code></pre> <p>               Bases: <code>BaseFieldReconstructor</code></p> <p>Standard Gaussian Process based field reconstruction.</p> <p>This uses sklearn's GaussianProcessRegressor directly without inducing point approximation. Good for moderate-sized datasets.</p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution</p> <code>(256, 256)</code> <code>kernel</code> <code>str</code> <p>Kernel type ('rbf', 'matern', 'periodic')</p> <code>'rbf'</code> <code>length_scale</code> <code>float</code> <p>Kernel length scale</p> <code>10.0</code> <code>noise_level</code> <code>float</code> <p>Observation noise level</p> <code>0.1</code> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def __init__(\n    self,\n    resolution: Tuple[int, int] = (256, 256),\n    kernel: str = \"rbf\",\n    length_scale: float = 10.0,\n    noise_level: float = 0.1\n):\n    super().__init__(resolution)\n    self.kernel = kernel\n    self.length_scale = length_scale\n    self.noise_level = noise_level\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.GaussianProcessReconstructor.fit","title":"fit","text":"<pre><code>fit(observations: ndarray, positions: ndarray) -&gt; GaussianProcessReconstructor\n</code></pre> <p>Fit Gaussian Process to observations.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'GaussianProcessReconstructor':\n    \"\"\"Fit Gaussian Process to observations.\"\"\"\n    self.observations = observations\n    self.positions = positions\n    self.n_observations = len(observations)\n\n    # Compute kernel matrix\n    self.K = self._compute_kernel_matrix(positions, positions)\n\n    # Add noise to diagonal\n    self.K += self.noise_level**2 * np.eye(self.n_observations)\n\n    # Compute inverse (with regularization)\n    try:\n        self.K_inv = np.linalg.inv(self.K)\n    except np.linalg.LinAlgError:\n        self.K += 1e-6 * np.eye(self.n_observations)\n        self.K_inv = np.linalg.inv(self.K)\n\n    # Precompute alpha for efficiency\n    self.alpha = self.K_inv @ observations\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.GaussianProcessReconstructor.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(grid_points: Optional[ndarray] = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct field using Gaussian Process.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n    \"\"\"Reconstruct field using Gaussian Process.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"GP reconstructor must be fitted first\")\n\n    if grid_points is None:\n        grid_points = create_grid_points(self.resolution)\n\n    K_star = self._compute_kernel_matrix(grid_points, self.positions)\n    mu = K_star @ self.alpha\n\n    if grid_points.shape[0] == self.resolution[0] * self.resolution[1]:\n        mu = mu.reshape(self.resolution)\n\n    self._last_grid_points = grid_points\n    self._last_K_star = K_star\n    self._last_mu = mu\n\n    return mu\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.GaussianProcessReconstructor.uncertainty","title":"uncertainty","text":"<pre><code>uncertainty() -&gt; np.ndarray\n</code></pre> <p>Compute GP uncertainty (posterior variance).</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def uncertainty(self) -&gt; np.ndarray:\n    \"\"\"Compute GP uncertainty (posterior variance).\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"GP reconstructor must be fitted first\")\n\n    if not hasattr(self, '_last_grid_points'):\n        raise RuntimeError(\"Must call reconstruct() before uncertainty()\")\n\n    K_star_star = self._compute_kernel_matrix(self._last_grid_points, self._last_grid_points)\n    var = np.diag(K_star_star - self._last_K_star @ self.K_inv @ self._last_K_star.T)\n    var = np.maximum(var, 0)\n\n    if var.shape[0] == self.resolution[0] * self.resolution[1]:\n        var = var.reshape(self.resolution)\n\n    return np.sqrt(var)\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.NeuralFieldReconstructor","title":"NeuralFieldReconstructor","text":"<pre><code>NeuralFieldReconstructor(resolution: Tuple[int, int] = (256, 256), hidden_dims: Tuple[int, ...] = (256, 128, 64), activation: str = 'relu', positional_encoding_dims: int = 32, n_epochs: int = 1000, learning_rate: float = 0.001, verbose: bool = False)\n</code></pre> <p>               Bases: <code>BaseFieldReconstructor</code></p> <p>Neural field based reconstruction using coordinate networks.</p> <p>This uses a neural network to learn a continuous field representation from sparse observations. Includes positional encoding for better high-frequency detail capture.</p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution</p> <code>(256, 256)</code> <code>hidden_dims</code> <code>Tuple[int, ...]</code> <p>Hidden layer dimensions</p> <code>(256, 128, 64)</code> <code>activation</code> <code>str</code> <p>Activation function ('relu', 'tanh', 'sigmoid')</p> <code>'relu'</code> <code>positional_encoding_dims</code> <code>int</code> <p>Number of positional encoding frequencies</p> <code>32</code> <code>n_epochs</code> <code>int</code> <p>Number of training epochs</p> <code>1000</code> <code>learning_rate</code> <code>float</code> <p>Learning rate for optimization</p> <code>0.001</code> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def __init__(\n    self,\n    resolution: Tuple[int, int] = (256, 256),\n    hidden_dims: Tuple[int, ...] = (256, 128, 64),\n    activation: str = \"relu\",\n    positional_encoding_dims: int = 32,\n    n_epochs: int = 1000,\n    learning_rate: float = 0.001,\n    verbose: bool = False,\n):\n    super().__init__(resolution)\n    self.hidden_dims = hidden_dims\n    self.activation = activation\n    self.positional_encoding_dims = positional_encoding_dims\n    self.n_epochs = n_epochs\n    self.learning_rate = learning_rate\n    self.verbose = verbose\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.NeuralFieldReconstructor.fit","title":"fit","text":"<pre><code>fit(observations: ndarray, positions: ndarray) -&gt; NeuralFieldReconstructor\n</code></pre> <p>Train neural field on observations.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'NeuralFieldReconstructor':\n    \"\"\"Train neural field on observations.\"\"\"\n    import torch\n    import torch.nn as nn\n    import torch.optim as optim\n\n    self.observations = observations\n    self.positions = positions\n\n    # Normalize positions to [-1, 1]\n    self._pos_min = positions.min(axis=0)\n    self._pos_max = positions.max(axis=0)\n    positions_norm = 2 * (positions - self._pos_min) / (self._pos_max - self._pos_min + 1e-8) - 1\n\n    # Normalize observations\n    self._y_mean = observations.mean()\n    self._y_std = observations.std()\n    if self._y_std == 0:\n        self._y_std = 1.0\n    obs_norm = (observations - self._y_mean) / self._y_std\n\n    # Create neural network\n    self.network = self._create_network()\n\n    # Convert to torch tensors\n    pos_tensor = torch.FloatTensor(positions_norm)\n    obs_tensor = torch.FloatTensor(obs_norm)\n\n    # Apply positional encoding\n    if self.positional_encoding_dims &gt; 0:\n        pos_tensor = self._positional_encoding(pos_tensor)\n\n    # Training\n    optimizer = optim.Adam(self.network.parameters(), lr=self.learning_rate)\n    criterion = nn.MSELoss()\n\n    for epoch in range(self.n_epochs):\n        optimizer.zero_grad()\n        pred = self.network(pos_tensor).squeeze()\n        loss = criterion(pred, obs_tensor)\n        loss.backward()\n        optimizer.step()\n\n        if self.verbose and (epoch + 1) % 100 == 0:\n            print(f\"Epoch {epoch+1}/{self.n_epochs}, Loss: {loss.item():.6f}\")\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.NeuralFieldReconstructor.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(grid_points: Optional[ndarray] = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct field using trained neural network.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n    \"\"\"Reconstruct field using trained neural network.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Neural field must be fitted first\")\n\n    import torch\n\n    if grid_points is None:\n        grid_points = create_grid_points(self.resolution)\n\n    # Normalize grid points\n    grid_norm = 2 * (grid_points - self._pos_min) / (self._pos_max - self._pos_min + 1e-8) - 1\n\n    pos_tensor = torch.FloatTensor(grid_norm)\n\n    if self.positional_encoding_dims &gt; 0:\n        pos_tensor = self._positional_encoding(pos_tensor)\n\n    with torch.no_grad():\n        pred = self.network(pos_tensor).squeeze().numpy()\n\n    # Denormalize\n    pred = pred * self._y_std + self._y_mean\n\n    if grid_points.shape[0] == self.resolution[0] * self.resolution[1]:\n        pred = pred.reshape(self.resolution)\n\n    return pred\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.NeuralFieldReconstructor.uncertainty","title":"uncertainty","text":"<pre><code>uncertainty() -&gt; np.ndarray\n</code></pre> <p>Estimate uncertainty (placeholder - returns zeros).</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def uncertainty(self) -&gt; np.ndarray:\n    \"\"\"Estimate uncertainty (placeholder - returns zeros).\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Neural field must be fitted first\")\n\n    # Neural fields don't provide uncertainty by default\n    # Could be improved with MC dropout or ensemble methods\n    return np.zeros(self.resolution)\n</code></pre>"},{"location":"api/core/field_theory/#base-class","title":"Base Class","text":""},{"location":"api/core/field_theory/#mneme.core.field_theory.BaseFieldReconstructor","title":"BaseFieldReconstructor","text":"<pre><code>BaseFieldReconstructor(resolution: Tuple[int, int] = (256, 256))\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for field reconstruction methods.</p> <p>Initialize field reconstructor.</p> <p>Parameters:</p> Name Type Description Default <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution (height, width)</p> <code>(256, 256)</code> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def __init__(self, resolution: Tuple[int, int] = (256, 256)):\n    \"\"\"\n    Initialize field reconstructor.\n\n    Parameters\n    ----------\n    resolution : Tuple[int, int]\n        Output field resolution (height, width)\n    \"\"\"\n    self.resolution = resolution\n    self.is_fitted = False\n    self.observations = None\n    self.positions = None\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.BaseFieldReconstructor.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(observations: ndarray, positions: ndarray) -&gt; BaseFieldReconstructor\n</code></pre> <p>Fit the reconstructor to observations.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ndarray</code> <p>Observed field values, shape (n_observations,)</p> required <code>positions</code> <code>ndarray</code> <p>Observation positions, shape (n_observations, 2)</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>BaseFieldReconstructor</code> <p>Fitted reconstructor</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>@abstractmethod\ndef fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'BaseFieldReconstructor':\n    \"\"\"\n    Fit the reconstructor to observations.\n\n    Parameters\n    ----------\n    observations : np.ndarray\n        Observed field values, shape (n_observations,)\n    positions : np.ndarray\n        Observation positions, shape (n_observations, 2)\n\n    Returns\n    -------\n    self : BaseFieldReconstructor\n        Fitted reconstructor\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.BaseFieldReconstructor.reconstruct","title":"reconstruct  <code>abstractmethod</code>","text":"<pre><code>reconstruct(grid_points: Optional[ndarray] = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct the continuous field.</p> <p>Parameters:</p> Name Type Description Default <code>grid_points</code> <code>ndarray</code> <p>Points at which to evaluate field, shape (n_points, 2) If None, uses regular grid based on resolution</p> <code>None</code> <p>Returns:</p> Name Type Description <code>field</code> <code>ndarray</code> <p>Reconstructed field values</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>@abstractmethod\ndef reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n    \"\"\"\n    Reconstruct the continuous field.\n\n    Parameters\n    ----------\n    grid_points : np.ndarray, optional\n        Points at which to evaluate field, shape (n_points, 2)\n        If None, uses regular grid based on resolution\n\n    Returns\n    -------\n    field : np.ndarray\n        Reconstructed field values\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.BaseFieldReconstructor.uncertainty","title":"uncertainty  <code>abstractmethod</code>","text":"<pre><code>uncertainty() -&gt; np.ndarray\n</code></pre> <p>Return reconstruction uncertainty estimates.</p> <p>Returns:</p> Name Type Description <code>uncertainty</code> <code>ndarray</code> <p>Uncertainty values at each grid point</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>@abstractmethod\ndef uncertainty(self) -&gt; np.ndarray:\n    \"\"\"\n    Return reconstruction uncertainty estimates.\n\n    Returns\n    -------\n    uncertainty : np.ndarray\n        Uncertainty values at each grid point\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/core/field_theory/#dispatcher","title":"Dispatcher","text":""},{"location":"api/core/field_theory/#mneme.core.field_theory.FieldReconstructor","title":"FieldReconstructor","text":"<pre><code>FieldReconstructor(method: Union[str, ReconstructionMethod] = ReconstructionMethod.IFT, resolution: Tuple[int, int] = (256, 256), **kwargs)\n</code></pre> <p>               Bases: <code>BaseFieldReconstructor</code></p> <p>Main field reconstruction class with multiple backend methods.</p> <p>This is the primary interface for field reconstruction. It dispatches to specialized backend implementations based on the chosen method.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str or ReconstructionMethod</code> <p>Reconstruction method to use: - 'ift': Sparse GP-based IFT (default, scalable) - 'dense_ift': Dense matrix IFT (exact but O(n\u00b3), for small fields only) - 'gaussian_process': Standard GP reconstruction - 'neural_field': Neural network-based reconstruction</p> <code>IFT</code> <code>resolution</code> <code>Tuple[int, int]</code> <p>Output field resolution (height, width)</p> <code>(256, 256)</code> <code>**kwargs</code> <p>Additional method-specific parameters</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from mneme.core.field_theory import FieldReconstructor\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Create reconstructor (uses scalable Sparse GP by default)\n&gt;&gt;&gt; reconstructor = FieldReconstructor(resolution=(128, 128))\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Fit to sparse observations\n&gt;&gt;&gt; positions = np.random.rand(100, 2)  # 100 observation points\n&gt;&gt;&gt; observations = np.sin(2 * np.pi * positions[:, 0])  # Some field values\n&gt;&gt;&gt; reconstructor.fit(observations, positions)\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Reconstruct full field\n&gt;&gt;&gt; field = reconstructor.reconstruct()\n&gt;&gt;&gt; uncertainty = reconstructor.uncertainty()\n</code></pre> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def __init__(\n    self, \n    method: Union[str, ReconstructionMethod] = ReconstructionMethod.IFT,\n    resolution: Tuple[int, int] = (256, 256),\n    **kwargs\n):\n    super().__init__(resolution)\n\n    # Handle string method names\n    if isinstance(method, str):\n        method_lower = method.lower()\n        if method_lower == 'dense_ift':\n            self.method = ReconstructionMethod.IFT\n            self._use_dense = True\n        else:\n            self.method = ReconstructionMethod(method_lower)\n            self._use_dense = False\n    else:\n        self.method = method\n        self._use_dense = kwargs.pop('use_dense', False)\n\n    self.method_params = kwargs\n    self._backend = None\n    self._initialize_backend()\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.FieldReconstructor.fit","title":"fit","text":"<pre><code>fit(observations: ndarray, positions: ndarray) -&gt; FieldReconstructor\n</code></pre> <p>Fit the reconstructor to observations.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def fit(self, observations: np.ndarray, positions: np.ndarray) -&gt; 'FieldReconstructor':\n    \"\"\"Fit the reconstructor to observations.\"\"\"\n    self._backend.fit(observations, positions)\n    self.is_fitted = True\n    self.observations = observations\n    self.positions = positions\n    return self\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.FieldReconstructor.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(grid_points: Optional[ndarray] = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct the continuous field.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def reconstruct(self, grid_points: Optional[np.ndarray] = None) -&gt; np.ndarray:\n    \"\"\"Reconstruct the continuous field.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Reconstructor must be fitted before reconstruction\")\n    return self._backend.reconstruct(grid_points)\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.FieldReconstructor.uncertainty","title":"uncertainty","text":"<pre><code>uncertainty() -&gt; np.ndarray\n</code></pre> <p>Return reconstruction uncertainty estimates.</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def uncertainty(self) -&gt; np.ndarray:\n    \"\"\"Return reconstruction uncertainty estimates.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Reconstructor must be fitted before computing uncertainty\")\n    return self._backend.uncertainty()\n</code></pre>"},{"location":"api/core/field_theory/#mneme.core.field_theory.FieldReconstructor.fit_reconstruct","title":"fit_reconstruct","text":"<pre><code>fit_reconstruct(observations: ndarray, positions: ndarray, grid_points: Optional[ndarray] = None) -&gt; ReconstructionResult\n</code></pre> <p>Convenience method to fit and reconstruct in one call.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ndarray</code> <p>Observed field values</p> required <code>positions</code> <code>ndarray</code> <p>Observation positions</p> required <code>grid_points</code> <code>ndarray</code> <p>Points at which to evaluate field</p> <code>None</code> <p>Returns:</p> Name Type Description <code>result</code> <code>ReconstructionResult</code> <p>Complete reconstruction result</p> Source code in <code>src/mneme/core/field_theory.py</code> <pre><code>def fit_reconstruct(\n    self, \n    observations: np.ndarray, \n    positions: np.ndarray,\n    grid_points: Optional[np.ndarray] = None\n) -&gt; ReconstructionResult:\n    \"\"\"\n    Convenience method to fit and reconstruct in one call.\n\n    Parameters\n    ----------\n    observations : np.ndarray\n        Observed field values\n    positions : np.ndarray\n        Observation positions\n    grid_points : np.ndarray, optional\n        Points at which to evaluate field\n\n    Returns\n    -------\n    result : ReconstructionResult\n        Complete reconstruction result\n    \"\"\"\n    import time\n    start_time = time.time()\n\n    self.fit(observations, positions)\n    field_data = self.reconstruct(grid_points)\n    uncertainty_data = self.uncertainty()\n\n    computation_time = time.time() - start_time\n\n    field = Field(\n        data=field_data,\n        resolution=self.resolution,\n        metadata={\"method\": self.method.value}\n    )\n\n    return ReconstructionResult(\n        field=field,\n        uncertainty=uncertainty_data,\n        method=self.method,\n        parameters=self.method_params,\n        computation_time=computation_time\n    )\n</code></pre>"},{"location":"api/core/topology/","title":"Topology","text":"<p>Persistent homology computation and topological distance metrics for field data.</p>"},{"location":"api/core/topology/#primary-interface","title":"Primary Interface","text":""},{"location":"api/core/topology/#mneme.core.topology.PersistentHomology","title":"PersistentHomology","text":"<pre><code>PersistentHomology(max_dimension: int = 2, filtration: Union[str, FiltrationMethod] = FiltrationMethod.SUBLEVEL, persistence_threshold: float = 0.05, compute_cycles: bool = True)\n</code></pre> <p>               Bases: <code>BaseTopologyAnalyzer</code></p> <p>Compute persistent homology of fields.</p> <p>Initialize persistent homology analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>max_dimension</code> <code>int</code> <p>Maximum homological dimension</p> <code>2</code> <code>filtration</code> <code>str or FiltrationMethod</code> <p>Type of filtration to use</p> <code>SUBLEVEL</code> <code>persistence_threshold</code> <code>float</code> <p>Minimum persistence to consider significant</p> <code>0.05</code> <code>compute_cycles</code> <code>bool</code> <p>Whether to compute representative cycles</p> <code>True</code> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def __init__(\n    self,\n    max_dimension: int = 2,\n    filtration: Union[str, FiltrationMethod] = FiltrationMethod.SUBLEVEL,\n    persistence_threshold: float = 0.05,\n    compute_cycles: bool = True\n):\n    \"\"\"\n    Initialize persistent homology analyzer.\n\n    Parameters\n    ----------\n    max_dimension : int\n        Maximum homological dimension\n    filtration : str or FiltrationMethod\n        Type of filtration to use\n    persistence_threshold : float\n        Minimum persistence to consider significant\n    compute_cycles : bool\n        Whether to compute representative cycles\n    \"\"\"\n    super().__init__(max_dimension)\n    self.filtration = FiltrationMethod(filtration) if isinstance(filtration, str) else filtration\n    self.persistence_threshold = persistence_threshold\n    self.compute_cycles = compute_cycles\n    self._cycles = None\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.PersistentHomology.compute_persistence","title":"compute_persistence","text":"<pre><code>compute_persistence(field: ndarray) -&gt; List[PersistenceDiagram]\n</code></pre> <p>Compute persistence diagrams using GUDHI.</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_persistence(self, field: np.ndarray) -&gt; List[PersistenceDiagram]:\n    \"\"\"Compute persistence diagrams using GUDHI.\"\"\"\n    try:\n        import gudhi\n    except ImportError:\n        # Fallback implementation without GUDHI\n        return self._compute_persistence_simple(field)\n\n    if field.ndim != 2:\n        raise ValueError(\"Persistence computation only supports 2D fields\")\n\n    # Create cubical complex\n    if self.filtration == FiltrationMethod.SUBLEVEL:\n        # For sublevel filtration, negate the field\n        filtration_values = -field.flatten()\n    else:\n        filtration_values = field.flatten()\n\n    # Create cubical complex\n    cubical_complex = gudhi.CubicalComplex(\n        dimensions=field.shape,\n        top_dimensional_cells=filtration_values\n    )\n\n    # Compute persistence\n    cubical_complex.compute_persistence()\n\n    # Extract diagrams by dimension\n    diagrams = []\n    for dim in range(self.max_dimension + 1):\n        persistence_pairs = cubical_complex.persistence_intervals_in_dimension(dim)\n\n        if len(persistence_pairs) &gt; 0:\n            # Filter by persistence threshold\n            if self.persistence_threshold &gt; 0:\n                persistence_values = persistence_pairs[:, 1] - persistence_pairs[:, 0]\n                mask = persistence_values &gt;= self.persistence_threshold\n                persistence_pairs = persistence_pairs[mask]\n\n            diagram = PersistenceDiagram(\n                points=persistence_pairs,\n                dimension=dim,\n                threshold=self.persistence_threshold\n            )\n            diagrams.append(diagram)\n        else:\n            # Empty diagram\n            diagram = PersistenceDiagram(\n                points=np.empty((0, 2)),\n                dimension=dim,\n                threshold=self.persistence_threshold\n            )\n            diagrams.append(diagram)\n\n    # Store cycles if requested\n    if self.compute_cycles:\n        self._cycles = self._extract_cycles(cubical_complex, diagrams)\n\n    return diagrams\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.PersistentHomology.extract_features","title":"extract_features","text":"<pre><code>extract_features(diagrams: List[PersistenceDiagram]) -&gt; np.ndarray\n</code></pre> <p>Extract topological features from persistence diagrams.</p> <p>Features per dimension: count, total, max, mean, entropy, std. Guards against NaN/Inf and division by zero.</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def extract_features(self, diagrams: List[PersistenceDiagram]) -&gt; np.ndarray:\n    \"\"\"\n    Extract topological features from persistence diagrams.\n\n    Features per dimension: count, total, max, mean, entropy, std.\n    Guards against NaN/Inf and division by zero.\n    \"\"\"\n    features: list[float] = []\n\n    for diagram in diagrams:\n        if len(diagram.points) == 0:\n            dim_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n        else:\n            persistence_values = diagram.persistence\n            # Keep only finite values\n            finite_vals = persistence_values[np.isfinite(persistence_values)]\n            if finite_vals.size == 0:\n                dim_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n            else:\n                n_features = float(len(finite_vals))\n                total_persistence = float(np.sum(finite_vals))\n                max_persistence = float(np.max(finite_vals))\n                mean_persistence = float(np.mean(finite_vals))\n                with np.errstate(divide='ignore', invalid='ignore'):\n                    if total_persistence &gt; 0:\n                        p_norm = finite_vals / total_persistence\n                        entropy = float(-np.sum(p_norm * np.log(p_norm + _ENTROPY_EPS)))\n                    else:\n                        entropy = 0.0\n                std_persistence = float(np.std(finite_vals)) if finite_vals.size &gt; 1 else 0.0\n                dim_features = [\n                    n_features,\n                    total_persistence,\n                    max_persistence,\n                    mean_persistence,\n                    entropy,\n                    std_persistence,\n                ]\n\n        features.extend(dim_features)\n\n    return np.asarray(features, dtype=float)\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.PersistentHomology.get_cycles","title":"get_cycles","text":"<pre><code>get_cycles() -&gt; Optional[List[np.ndarray]]\n</code></pre> <p>Get representative cycles for persistent features.</p> <p>Returns:</p> Name Type Description <code>cycles</code> <code>List[ndarray] or None</code> <p>Representative cycles if computed</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def get_cycles(self) -&gt; Optional[List[np.ndarray]]:\n    \"\"\"\n    Get representative cycles for persistent features.\n\n    Returns\n    -------\n    cycles : List[np.ndarray] or None\n        Representative cycles if computed\n    \"\"\"\n    return self._cycles\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.PersistentHomology.compute_persistence_image","title":"compute_persistence_image","text":"<pre><code>compute_persistence_image(diagram: PersistenceDiagram, resolution: Tuple[int, int] = (50, 50), sigma: float = 0.1) -&gt; np.ndarray\n</code></pre> <p>Compute persistence image from diagram.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <code>PersistenceDiagram</code> <p>Input persistence diagram</p> required <code>resolution</code> <code>Tuple[int, int]</code> <p>Image resolution</p> <code>(50, 50)</code> <code>sigma</code> <code>float</code> <p>Gaussian kernel width</p> <code>0.1</code> <p>Returns:</p> Name Type Description <code>image</code> <code>ndarray</code> <p>Persistence image</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_persistence_image(\n    self,\n    diagram: PersistenceDiagram,\n    resolution: Tuple[int, int] = (50, 50),\n    sigma: float = 0.1\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute persistence image from diagram.\n\n    Parameters\n    ----------\n    diagram : PersistenceDiagram\n        Input persistence diagram\n    resolution : Tuple[int, int]\n        Image resolution\n    sigma : float\n        Gaussian kernel width\n\n    Returns\n    -------\n    image : np.ndarray\n        Persistence image\n    \"\"\"\n    if len(diagram.points) == 0:\n        return np.zeros(resolution)\n\n    # Transform to birth-persistence coordinates\n    birth = diagram.points[:, 0]\n    death = diagram.points[:, 1]\n    persistence = death - birth\n\n    # Create grid\n    birth_range = (birth.min(), birth.max()) if len(birth) &gt; 0 else (0, 1)\n    pers_range = (0, persistence.max()) if len(persistence) &gt; 0 else (0, 1)\n\n    # Add small buffer\n    birth_range = (birth_range[0] - 0.1, birth_range[1] + 0.1)\n    pers_range = (pers_range[0], pers_range[1] + 0.1)\n\n    # Create coordinate grids\n    birth_coords = np.linspace(birth_range[0], birth_range[1], resolution[0])\n    pers_coords = np.linspace(pers_range[0], pers_range[1], resolution[1])\n\n    B, P = np.meshgrid(birth_coords, pers_coords, indexing='ij')\n\n    # Initialize image\n    image = np.zeros(resolution)\n\n    # Add Gaussian for each point\n    for i in range(len(birth)):\n        b_i = birth[i]\n        p_i = persistence[i]\n\n        # Weight by persistence\n        weight = p_i\n\n        # Gaussian kernel\n        gaussian = weight * np.exp(-((B - b_i)**2 + (P - p_i)**2) / (2 * sigma**2))\n        image += gaussian\n\n    return image\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.PersistentHomology.compute_persistence_landscape","title":"compute_persistence_landscape","text":"<pre><code>compute_persistence_landscape(diagram: PersistenceDiagram, k: int = 5, resolution: int = 100) -&gt; np.ndarray\n</code></pre> <p>Compute persistence landscape.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <code>PersistenceDiagram</code> <p>Input persistence diagram</p> required <code>k</code> <code>int</code> <p>Number of landscape functions</p> <code>5</code> <code>resolution</code> <code>int</code> <p>Resolution of landscape functions</p> <code>100</code> <p>Returns:</p> Name Type Description <code>landscape</code> <code>ndarray</code> <p>Persistence landscape functions</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_persistence_landscape(\n    self,\n    diagram: PersistenceDiagram,\n    k: int = 5,\n    resolution: int = 100\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute persistence landscape.\n\n    Parameters\n    ----------\n    diagram : PersistenceDiagram\n        Input persistence diagram\n    k : int\n        Number of landscape functions\n    resolution : int\n        Resolution of landscape functions\n\n    Returns\n    -------\n    landscape : np.ndarray\n        Persistence landscape functions\n    \"\"\"\n    if len(diagram.points) == 0:\n        return np.zeros((k, resolution))\n\n    # Get birth and death times\n    birth = diagram.points[:, 0]\n    death = diagram.points[:, 1]\n\n    # Create parameter range\n    t_min = birth.min()\n    t_max = death.max()\n    t_range = np.linspace(t_min, t_max, resolution)\n\n    # Initialize landscape functions\n    landscape = np.zeros((k, resolution))\n\n    # Compute landscape functions\n    for i, t in enumerate(t_range):\n        # Compute landscape values at t\n        values = []\n\n        for j in range(len(birth)):\n            b = birth[j]\n            d = death[j]\n\n            if b &lt;= t &lt;= d:\n                # Triangle function\n                value = min(t - b, d - t)\n                values.append(value)\n\n        # Sort in descending order\n        values.sort(reverse=True)\n\n        # Assign to landscape functions\n        for j in range(min(k, len(values))):\n            landscape[j, i] = values[j]\n\n    return landscape\n</code></pre>"},{"location":"api/core/topology/#complex-types","title":"Complex Types","text":""},{"location":"api/core/topology/#mneme.core.topology.RipsComplex","title":"RipsComplex","text":"<pre><code>RipsComplex(max_dimension: int = 2, max_edge_length: float = np.inf)\n</code></pre> <p>               Bases: <code>BaseTopologyAnalyzer</code></p> <p>Vietoris-Rips complex for point cloud data.</p> <p>Initialize Rips complex analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>max_dimension</code> <code>int</code> <p>Maximum dimension for complex</p> <code>2</code> <code>max_edge_length</code> <code>float</code> <p>Maximum edge length in complex</p> <code>inf</code> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def __init__(\n    self,\n    max_dimension: int = 2,\n    max_edge_length: float = np.inf\n):\n    \"\"\"\n    Initialize Rips complex analyzer.\n\n    Parameters\n    ----------\n    max_dimension : int\n        Maximum dimension for complex\n    max_edge_length : float\n        Maximum edge length in complex\n    \"\"\"\n    super().__init__(max_dimension)\n    self.max_edge_length = max_edge_length\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.RipsComplex.compute_persistence","title":"compute_persistence","text":"<pre><code>compute_persistence(point_cloud: ndarray) -&gt; List[PersistenceDiagram]\n</code></pre> <p>Compute persistence diagrams for a 2D/ND point cloud using GUDHI Rips.</p> <p>Falls back to a scipy-based distance-matrix approximation when GUDHI is not installed.  The fallback only computes 0-dimensional persistence (connected components).</p> <p>Parameters:</p> Name Type Description Default <code>point_cloud</code> <code>ndarray</code> <p>Array of shape (n_points, n_dims)</p> required Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_persistence(self, point_cloud: np.ndarray) -&gt; List[PersistenceDiagram]:\n    \"\"\"Compute persistence diagrams for a 2D/ND point cloud using GUDHI Rips.\n\n    Falls back to a scipy-based distance-matrix approximation when GUDHI\n    is not installed.  The fallback only computes 0-dimensional persistence\n    (connected components).\n\n    Parameters\n    ----------\n    point_cloud : np.ndarray\n        Array of shape (n_points, n_dims)\n    \"\"\"\n    if point_cloud.ndim != 2:\n        raise ValueError(\"point_cloud must be 2D (n_points, n_dims)\")\n\n    try:\n        import gudhi\n    except ImportError:\n        return self._compute_persistence_fallback(point_cloud)\n\n    rips = gudhi.RipsComplex(points=point_cloud, max_edge_length=float(self.max_edge_length))\n    st = rips.create_simplex_tree(max_dimension=self.max_dimension)\n    st.compute_persistence()\n\n    diagrams: List[PersistenceDiagram] = []\n    for dim in range(self.max_dimension + 1):\n        pairs = st.persistence_intervals_in_dimension(dim)\n        if len(pairs) == 0:\n            diagrams.append(PersistenceDiagram(points=np.empty((0, 2)), dimension=dim, threshold=None))\n        else:\n            points = np.asarray(pairs)\n            diagrams.append(PersistenceDiagram(points=points, dimension=dim, threshold=None))\n    return diagrams\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.RipsComplex.extract_features","title":"extract_features","text":"<pre><code>extract_features(diagrams: List[PersistenceDiagram]) -&gt; np.ndarray\n</code></pre> <p>Extract topological features from Rips persistence (mirrors cubical).</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def extract_features(self, diagrams: List[PersistenceDiagram]) -&gt; np.ndarray:\n    \"\"\"Extract topological features from Rips persistence (mirrors cubical).\"\"\"\n    features: list[float] = []\n    for diagram in diagrams:\n        if len(diagram.points) == 0:\n            dim_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n        else:\n            persistence_values = diagram.persistence\n            finite_vals = persistence_values[np.isfinite(persistence_values)]\n            if finite_vals.size == 0:\n                dim_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n            else:\n                n_features = float(len(finite_vals))\n                total_persistence = float(np.sum(finite_vals))\n                max_persistence = float(np.max(finite_vals))\n                mean_persistence = float(np.mean(finite_vals))\n                with np.errstate(divide='ignore', invalid='ignore'):\n                    if total_persistence &gt; 0:\n                        p_norm = finite_vals / total_persistence\n                        entropy = float(-np.sum(p_norm * np.log(p_norm + _ENTROPY_EPS)))\n                    else:\n                        entropy = 0.0\n                std_persistence = float(np.std(finite_vals)) if finite_vals.size &gt; 1 else 0.0\n                dim_features = [n_features, total_persistence, max_persistence, mean_persistence, entropy, std_persistence]\n        features.extend(dim_features)\n    return np.asarray(features, dtype=float)\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.AlphaComplex","title":"AlphaComplex","text":"<pre><code>AlphaComplex(max_dimension: int = 2)\n</code></pre> <p>               Bases: <code>BaseTopologyAnalyzer</code></p> <p>Alpha complex for point cloud data.</p> <p>Initialize Alpha complex analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>max_dimension</code> <code>int</code> <p>Maximum dimension for complex</p> <code>2</code> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def __init__(self, max_dimension: int = 2):\n    \"\"\"\n    Initialize Alpha complex analyzer.\n\n    Parameters\n    ----------\n    max_dimension : int\n        Maximum dimension for complex\n    \"\"\"\n    super().__init__(max_dimension)\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.AlphaComplex.compute_persistence","title":"compute_persistence","text":"<pre><code>compute_persistence(point_cloud: ndarray) -&gt; List[PersistenceDiagram]\n</code></pre> <p>Compute persistence using GUDHI Alpha complex.</p> <p>Falls back to a Delaunay-based scipy approximation when GUDHI is not installed (0-dimensional persistence only).</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_persistence(self, point_cloud: np.ndarray) -&gt; List[PersistenceDiagram]:\n    \"\"\"Compute persistence using GUDHI Alpha complex.\n\n    Falls back to a Delaunay-based scipy approximation when GUDHI is not\n    installed (0-dimensional persistence only).\n    \"\"\"\n    if point_cloud.ndim != 2 or point_cloud.shape[1] &lt; 2:\n        raise ValueError(\"point_cloud must be (n_points, n_dims&gt;=2)\")\n\n    try:\n        import gudhi\n    except ImportError:\n        return self._compute_persistence_fallback(point_cloud)\n\n    alpha = gudhi.AlphaComplex(points=point_cloud)\n    st = alpha.create_simplex_tree()\n    st.compute_persistence()\n\n    diagrams: List[PersistenceDiagram] = []\n    for dim in range(self.max_dimension + 1):\n        pairs = st.persistence_intervals_in_dimension(dim)\n        if len(pairs) == 0:\n            diagrams.append(PersistenceDiagram(points=np.empty((0, 2)), dimension=dim, threshold=None))\n        else:\n            points = np.asarray(pairs)\n            diagrams.append(PersistenceDiagram(points=points, dimension=dim, threshold=None))\n    return diagrams\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.AlphaComplex.extract_features","title":"extract_features","text":"<pre><code>extract_features(diagrams: List[PersistenceDiagram]) -&gt; np.ndarray\n</code></pre> <p>Extract topological features from Alpha persistence (mirrors cubical).</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def extract_features(self, diagrams: List[PersistenceDiagram]) -&gt; np.ndarray:\n    \"\"\"Extract topological features from Alpha persistence (mirrors cubical).\"\"\"\n    features: list[float] = []\n    for diagram in diagrams:\n        if len(diagram.points) == 0:\n            dim_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n        else:\n            persistence_values = diagram.persistence\n            finite_vals = persistence_values[np.isfinite(persistence_values)]\n            if finite_vals.size == 0:\n                dim_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n            else:\n                n_features = float(len(finite_vals))\n                total_persistence = float(np.sum(finite_vals))\n                max_persistence = float(np.max(finite_vals))\n                mean_persistence = float(np.mean(finite_vals))\n                with np.errstate(divide='ignore', invalid='ignore'):\n                    if total_persistence &gt; 0:\n                        p_norm = finite_vals / total_persistence\n                        entropy = float(-np.sum(p_norm * np.log(p_norm + _ENTROPY_EPS)))\n                    else:\n                        entropy = 0.0\n                std_persistence = float(np.std(finite_vals)) if finite_vals.size &gt; 1 else 0.0\n                dim_features = [n_features, total_persistence, max_persistence, mean_persistence, entropy, std_persistence]\n        features.extend(dim_features)\n    return np.asarray(features, dtype=float)\n</code></pre>"},{"location":"api/core/topology/#distance-metrics","title":"Distance Metrics","text":""},{"location":"api/core/topology/#mneme.core.topology.compute_wasserstein_distance","title":"compute_wasserstein_distance","text":"<pre><code>compute_wasserstein_distance(diagram1: PersistenceDiagram, diagram2: PersistenceDiagram, p: float = 2.0) -&gt; float\n</code></pre> <p>Compute Wasserstein distance between persistence diagrams.</p> <p>Parameters:</p> Name Type Description Default <code>diagram1</code> <code>PersistenceDiagram</code> <p>Persistence diagrams to compare</p> required <code>diagram2</code> <code>PersistenceDiagram</code> <p>Persistence diagrams to compare</p> required <code>p</code> <code>float</code> <p>Wasserstein parameter (typically 1 or 2)</p> <code>2.0</code> <p>Returns:</p> Name Type Description <code>distance</code> <code>float</code> <p>Wasserstein distance</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_wasserstein_distance(\n    diagram1: PersistenceDiagram,\n    diagram2: PersistenceDiagram,\n    p: float = 2.0\n) -&gt; float:\n    \"\"\"\n    Compute Wasserstein distance between persistence diagrams.\n\n    Parameters\n    ----------\n    diagram1, diagram2 : PersistenceDiagram\n        Persistence diagrams to compare\n    p : float\n        Wasserstein parameter (typically 1 or 2)\n\n    Returns\n    -------\n    distance : float\n        Wasserstein distance\n    \"\"\"\n    try:\n        from gudhi.wasserstein import wasserstein_distance as _gudhi_wasserstein\n        # Use GUDHI implementation if available\n        return _gudhi_wasserstein(diagram1.points, diagram2.points, order=p)\n    except (ImportError, ModuleNotFoundError):\n        # Simple approximation using Hungarian algorithm\n        from scipy.optimize import linear_sum_assignment\n\n        points1 = diagram1.points\n        points2 = diagram2.points\n\n        if len(points1) == 0 and len(points2) == 0:\n            return 0.0\n\n        # Add diagonal points for unmatched points\n        diag_points1 = np.array([[(p[0] + p[1]) / 2, (p[0] + p[1]) / 2] for p in points1])\n        diag_points2 = np.array([[(p[0] + p[1]) / 2, (p[0] + p[1]) / 2] for p in points2])\n\n        # Combine points and diagonal points\n        all_points1 = np.vstack([points1, diag_points2]) if len(points2) &gt; 0 else points1\n        all_points2 = np.vstack([points2, diag_points1]) if len(points1) &gt; 0 else points2\n\n        # Compute cost matrix\n        cost_matrix = np.zeros((len(all_points1), len(all_points2)))\n        for i, p1 in enumerate(all_points1):\n            for j, p2 in enumerate(all_points2):\n                cost_matrix[i, j] = np.linalg.norm(p1 - p2, ord=p)\n\n        # Solve assignment problem\n        row_indices, col_indices = linear_sum_assignment(cost_matrix)\n\n        # Return total cost\n        return cost_matrix[row_indices, col_indices].sum()\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.compute_bottleneck_distance","title":"compute_bottleneck_distance","text":"<pre><code>compute_bottleneck_distance(diagram1: PersistenceDiagram, diagram2: PersistenceDiagram) -&gt; float\n</code></pre> <p>Compute bottleneck distance between persistence diagrams.</p> <p>Parameters:</p> Name Type Description Default <code>diagram1</code> <code>PersistenceDiagram</code> <p>Persistence diagrams to compare</p> required <code>diagram2</code> <code>PersistenceDiagram</code> <p>Persistence diagrams to compare</p> required <p>Returns:</p> Name Type Description <code>distance</code> <code>float</code> <p>Bottleneck distance</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_bottleneck_distance(\n    diagram1: PersistenceDiagram,\n    diagram2: PersistenceDiagram\n) -&gt; float:\n    \"\"\"\n    Compute bottleneck distance between persistence diagrams.\n\n    Parameters\n    ----------\n    diagram1, diagram2 : PersistenceDiagram\n        Persistence diagrams to compare\n\n    Returns\n    -------\n    distance : float\n        Bottleneck distance\n    \"\"\"\n    try:\n        import gudhi\n        # Use GUDHI implementation if available\n        return gudhi.bottleneck_distance(diagram1.points, diagram2.points)\n    except (ImportError, ModuleNotFoundError):\n        # Simple approximation\n        from scipy.optimize import linear_sum_assignment\n\n        points1 = diagram1.points\n        points2 = diagram2.points\n\n        if len(points1) == 0 and len(points2) == 0:\n            return 0.0\n\n        # Add diagonal projections\n        diag_points1 = np.array([[(p[0] + p[1]) / 2, (p[0] + p[1]) / 2] for p in points1])\n        diag_points2 = np.array([[(p[0] + p[1]) / 2, (p[0] + p[1]) / 2] for p in points2])\n\n        # Combine points\n        all_points1 = np.vstack([points1, diag_points2]) if len(points2) &gt; 0 else points1\n        all_points2 = np.vstack([points2, diag_points1]) if len(points1) &gt; 0 else points2\n\n        # Compute cost matrix (L-infinity norm)\n        cost_matrix = np.zeros((len(all_points1), len(all_points2)))\n        for i, p1 in enumerate(all_points1):\n            for j, p2 in enumerate(all_points2):\n                cost_matrix[i, j] = np.linalg.norm(p1 - p2, ord=np.inf)\n\n        # Solve assignment problem\n        row_indices, col_indices = linear_sum_assignment(cost_matrix)\n\n        # Return maximum cost (bottleneck)\n        return cost_matrix[row_indices, col_indices].max()\n</code></pre>"},{"location":"api/core/topology/#topological-descriptors","title":"Topological Descriptors","text":""},{"location":"api/core/topology/#mneme.core.topology.compute_betti_curve","title":"compute_betti_curve","text":"<pre><code>compute_betti_curve(diagram: PersistenceDiagram, filtration_values: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute Betti curve from persistence diagram.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <code>PersistenceDiagram</code> <p>Input persistence diagram</p> required <code>filtration_values</code> <code>ndarray</code> <p>Filtration values at which to compute Betti numbers</p> required <p>Returns:</p> Name Type Description <code>betti_curve</code> <code>ndarray</code> <p>Betti numbers at each filtration value</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def compute_betti_curve(\n    diagram: PersistenceDiagram,\n    filtration_values: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute Betti curve from persistence diagram.\n\n    Parameters\n    ----------\n    diagram : PersistenceDiagram\n        Input persistence diagram\n    filtration_values : np.ndarray\n        Filtration values at which to compute Betti numbers\n\n    Returns\n    -------\n    betti_curve : np.ndarray\n        Betti numbers at each filtration value\n    \"\"\"\n    betti_curve = np.zeros_like(filtration_values)\n\n    for i, t in enumerate(filtration_values):\n        # Count features alive at time t\n        alive = (diagram.points[:, 0] &lt;= t) &amp; (diagram.points[:, 1] &gt; t)\n        betti_curve[i] = np.sum(alive)\n\n    return betti_curve\n</code></pre>"},{"location":"api/core/topology/#utilities","title":"Utilities","text":""},{"location":"api/core/topology/#mneme.core.topology.filter_persistence_diagram","title":"filter_persistence_diagram","text":"<pre><code>filter_persistence_diagram(diagram: PersistenceDiagram, threshold: float) -&gt; PersistenceDiagram\n</code></pre> <p>Filter persistence diagram by persistence threshold.</p> <p>Parameters:</p> Name Type Description Default <code>diagram</code> <code>PersistenceDiagram</code> <p>Input diagram</p> required <code>threshold</code> <code>float</code> <p>Minimum persistence to keep</p> required <p>Returns:</p> Name Type Description <code>filtered</code> <code>PersistenceDiagram</code> <p>Filtered diagram</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def filter_persistence_diagram(\n    diagram: PersistenceDiagram,\n    threshold: float\n) -&gt; PersistenceDiagram:\n    \"\"\"\n    Filter persistence diagram by persistence threshold.\n\n    Parameters\n    ----------\n    diagram : PersistenceDiagram\n        Input diagram\n    threshold : float\n        Minimum persistence to keep\n\n    Returns\n    -------\n    filtered : PersistenceDiagram\n        Filtered diagram\n    \"\"\"\n    persistence = diagram.persistence\n    mask = persistence &gt;= threshold\n\n    return PersistenceDiagram(\n        points=diagram.points[mask],\n        dimension=diagram.dimension,\n        threshold=threshold\n    )\n</code></pre>"},{"location":"api/core/topology/#mneme.core.topology.field_to_point_cloud","title":"field_to_point_cloud","text":"<pre><code>field_to_point_cloud(field: ndarray, method: str = 'peaks', percentile: float = 95.0, max_points: int = DEFAULT_MAX_POINTS, normalize_coords: bool = True, seed: Optional[int] = None) -&gt; np.ndarray\n</code></pre> <p>Convert a 2D field into a 2D point cloud for Rips/Alpha backends.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>2D array (H, W)</p> required <code>method</code> <code>str</code> <p>'peaks' (local maxima above percentile) or 'threshold' (all pixels above percentile)</p> <code>'peaks'</code> <code>percentile</code> <code>float</code> <p>Value percentile for thresholding</p> <code>95.0</code> <code>max_points</code> <code>int</code> <p>Maximum number of points to return (subsampled if exceeded)</p> <code>DEFAULT_MAX_POINTS</code> <code>normalize_coords</code> <code>bool</code> <p>If True, scale coordinates to [0,1]^2</p> <code>True</code> <code>seed</code> <code>int</code> <p>Random seed for reproducible sub-sampling when the number of candidate points exceeds max_points.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pc</code> <code>ndarray</code> <p>Point cloud of shape (N, 2)</p> Source code in <code>src/mneme/core/topology.py</code> <pre><code>def field_to_point_cloud(\n    field: np.ndarray,\n    method: str = 'peaks',\n    percentile: float = 95.0,\n    max_points: int = DEFAULT_MAX_POINTS,\n    normalize_coords: bool = True,\n    seed: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"Convert a 2D field into a 2D point cloud for Rips/Alpha backends.\n\n    Parameters\n    ----------\n    field : np.ndarray\n        2D array (H, W)\n    method : str\n        'peaks' (local maxima above percentile) or 'threshold' (all pixels above percentile)\n    percentile : float\n        Value percentile for thresholding\n    max_points : int\n        Maximum number of points to return (subsampled if exceeded)\n    normalize_coords : bool\n        If True, scale coordinates to [0,1]^2\n    seed : int, optional\n        Random seed for reproducible sub-sampling when the number of\n        candidate points exceeds *max_points*.\n\n    Returns\n    -------\n    pc : np.ndarray\n        Point cloud of shape (N, 2)\n    \"\"\"\n    if field.ndim != 2:\n        raise ValueError(\"field_to_point_cloud expects a 2D array\")\n\n    h, w = field.shape\n    thr = float(np.percentile(field, percentile))\n\n    if method == 'peaks':\n        try:\n            from scipy.ndimage import maximum_filter\n            size = 3\n            neighborhood = maximum_filter(field, size=size)\n            mask = (field == neighborhood) &amp; (field &gt;= thr)\n        except Exception:\n            mask = field &gt;= thr\n    else:\n        mask = field &gt;= thr\n\n    coords = np.argwhere(mask)  # (y, x)\n\n    if coords.shape[0] == 0:\n        # Fallback: take top-k brightest pixels\n        flat_idx = np.argsort(field.ravel())[::-1][: max_points]\n        ys, xs = np.unravel_index(flat_idx, field.shape)\n        coords = np.column_stack([ys, xs])\n\n    # Subsample if too many\n    if coords.shape[0] &gt; max_points:\n        rng = np.random.RandomState(seed)\n        choice = rng.choice(coords.shape[0], size=max_points, replace=False)\n        coords = coords[choice]\n\n    # Convert to (x, y) and normalize if requested\n    pts = coords[:, ::-1].astype(np.float64)\n    if normalize_coords:\n        if w &gt; 1:\n            pts[:, 0] /= (w - 1)\n        if h &gt; 1:\n            pts[:, 1] /= (h - 1)\n    return pts\n</code></pre>"},{"location":"api/data/betse_loader/","title":"BETSE Loader","text":"<p>Load and preprocess output from BETSE (BioElectric Tissue Simulation Engine) simulations.</p>"},{"location":"api/data/betse_loader/#main-entry-point","title":"Main Entry Point","text":""},{"location":"api/data/betse_loader/#mneme.data.betse_loader.betse_to_field","title":"betse_to_field","text":"<pre><code>betse_to_field(vmem_dir: Union[str, Path], resolution: Tuple[int, int] = DEFAULT_GRID_RESOLUTION, method: str = 'cubic') -&gt; Field\n</code></pre> <p>Load BETSE data and return a Mneme Field object.</p> <p>This is the main entry point for feeding BETSE simulation output into the Mneme analysis pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>vmem_dir</code> <code>str or Path</code> <p>Directory containing Vmem2D_*.csv files.</p> required <code>resolution</code> <code>Tuple[int, int]</code> <p>Grid resolution for interpolation.</p> <code>DEFAULT_GRID_RESOLUTION</code> <code>method</code> <code>str</code> <p>Interpolation method ('linear', 'cubic', 'nearest').</p> <code>'cubic'</code> <p>Returns:</p> Name Type Description <code>field</code> <code>Field</code> <p>Mneme Field with shape (n_timesteps, rows, cols) if multiple frames, or (rows, cols) for a single frame.</p> Source code in <code>src/mneme/data/betse_loader.py</code> <pre><code>def betse_to_field(\n    vmem_dir: Union[str, Path],\n    resolution: Tuple[int, int] = DEFAULT_GRID_RESOLUTION,\n    method: str = \"cubic\",\n) -&gt; Field:\n    \"\"\"Load BETSE data and return a Mneme Field object.\n\n    This is the main entry point for feeding BETSE simulation output\n    into the Mneme analysis pipeline.\n\n    Parameters\n    ----------\n    vmem_dir : str or Path\n        Directory containing Vmem2D_*.csv files.\n    resolution : Tuple[int, int]\n        Grid resolution for interpolation.\n    method : str\n        Interpolation method ('linear', 'cubic', 'nearest').\n\n    Returns\n    -------\n    field : Field\n        Mneme Field with shape (n_timesteps, rows, cols) if multiple\n        frames, or (rows, cols) for a single frame.\n    \"\"\"\n    field_sequence, metadata = load_betse_timeseries(\n        vmem_dir, resolution=resolution, method=method\n    )\n\n    # Build 2-D coordinate array for the regular grid\n    grid_x = metadata[\"grid_x\"]\n    grid_y = metadata[\"grid_y\"]\n    gx, gy = np.meshgrid(grid_x, grid_y)\n    coordinates = np.column_stack([gx.ravel(), gy.ravel()])\n\n    # Squeeze out time dimension if only one frame\n    data = field_sequence if field_sequence.shape[0] &gt; 1 else field_sequence[0]\n\n    return Field(\n        data=data,\n        coordinates=coordinates,\n        resolution=resolution,\n        bounds=(\n            (metadata[\"x_bounds\"][0], metadata[\"x_bounds\"][1]),\n            (metadata[\"y_bounds\"][0], metadata[\"y_bounds\"][1]),\n        ),\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/data/betse_loader/#loading-functions","title":"Loading Functions","text":""},{"location":"api/data/betse_loader/#mneme.data.betse_loader.load_betse_timeseries","title":"load_betse_timeseries","text":"<pre><code>load_betse_timeseries(vmem_dir: Union[str, Path], resolution: Tuple[int, int] = DEFAULT_GRID_RESOLUTION, method: str = 'cubic') -&gt; Tuple[np.ndarray, Dict[str, Any]]\n</code></pre> <p>Load a BETSE Vmem2D time series from a directory of CSV files.</p> <p>Reads all <code>Vmem2D_*.csv</code> files, interpolates each onto a common regular grid, and stacks them into a 3-D array (time, rows, cols).</p> <p>Parameters:</p> Name Type Description Default <code>vmem_dir</code> <code>str or Path</code> <p>Directory containing Vmem2D_0.csv, Vmem2D_1.csv, ... files.</p> required <code>resolution</code> <code>Tuple[int, int]</code> <p>Target grid resolution per frame.</p> <code>DEFAULT_GRID_RESOLUTION</code> <code>method</code> <code>str</code> <p>Interpolation method passed to :func:<code>interpolate_to_grid</code>.</p> <code>'cubic'</code> <p>Returns:</p> Name Type Description <code>field_sequence</code> <code>ndarray</code> <p>Shape (n_timesteps, *resolution) array of Vmem fields in mV.</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Dictionary with keys: - <code>n_cells</code>: number of cells in the simulation - <code>n_timesteps</code>: number of temporal frames loaded - <code>grid_x</code>, <code>grid_y</code>: 1-D coordinate arrays for the regular grid - <code>x_bounds</code>, <code>y_bounds</code>: spatial extent in micrometres - <code>source_dir</code>: path to source directory</p> Source code in <code>src/mneme/data/betse_loader.py</code> <pre><code>def load_betse_timeseries(\n    vmem_dir: Union[str, Path],\n    resolution: Tuple[int, int] = DEFAULT_GRID_RESOLUTION,\n    method: str = \"cubic\",\n) -&gt; Tuple[np.ndarray, Dict[str, Any]]:\n    \"\"\"Load a BETSE Vmem2D time series from a directory of CSV files.\n\n    Reads all ``Vmem2D_*.csv`` files, interpolates each onto a common\n    regular grid, and stacks them into a 3-D array (time, rows, cols).\n\n    Parameters\n    ----------\n    vmem_dir : str or Path\n        Directory containing Vmem2D_0.csv, Vmem2D_1.csv, ... files.\n    resolution : Tuple[int, int]\n        Target grid resolution per frame.\n    method : str\n        Interpolation method passed to :func:`interpolate_to_grid`.\n\n    Returns\n    -------\n    field_sequence : np.ndarray\n        Shape (n_timesteps, *resolution) array of Vmem fields in mV.\n    metadata : Dict[str, Any]\n        Dictionary with keys:\n        - ``n_cells``: number of cells in the simulation\n        - ``n_timesteps``: number of temporal frames loaded\n        - ``grid_x``, ``grid_y``: 1-D coordinate arrays for the regular grid\n        - ``x_bounds``, ``y_bounds``: spatial extent in micrometres\n        - ``source_dir``: path to source directory\n    \"\"\"\n    vmem_dir = Path(vmem_dir)\n    csv_files = sorted(\n        vmem_dir.glob(\"Vmem2D_*.csv\"),\n        key=lambda p: int(re.search(r\"(\\d+)\", p.stem).group(1)),\n    )\n    if not csv_files:\n        raise FileNotFoundError(\n            f\"No Vmem2D_*.csv files found in {vmem_dir}\"\n        )\n\n    logger.info(\n        \"Loading %d BETSE Vmem frames from %s at resolution %s\",\n        len(csv_files), vmem_dir, resolution,\n    )\n\n    # First pass: determine shared coordinate bounds from all frames\n    all_x, all_y = [], []\n    frame_data: List[Tuple[np.ndarray, np.ndarray, np.ndarray]] = []\n    for csv_path in csv_files:\n        x, y, vmem = load_betse_vmem_csv(csv_path)\n        frame_data.append((x, y, vmem))\n        all_x.append(x)\n        all_y.append(y)\n\n    # Use union of all coordinate extents for a consistent grid\n    all_x_arr = np.concatenate(all_x)\n    all_y_arr = np.concatenate(all_y)\n    padding = 0.05\n    x_min = all_x_arr.min() - (all_x_arr.max() - all_x_arr.min()) * padding\n    x_max = all_x_arr.max() + (all_x_arr.max() - all_x_arr.min()) * padding\n    y_min = all_y_arr.min() - (all_y_arr.max() - all_y_arr.min()) * padding\n    y_max = all_y_arr.max() + (all_y_arr.max() - all_y_arr.min()) * padding\n\n    grid_x = np.linspace(x_min, x_max, resolution[1])\n    grid_y = np.linspace(y_min, y_max, resolution[0])\n    gx, gy = np.meshgrid(grid_x, grid_y)\n\n    # Second pass: interpolate each frame onto the shared grid\n    frames = []\n    for i, (x, y, vmem) in enumerate(frame_data):\n        points = np.column_stack([x, y])\n        grid = griddata(points, vmem, (gx, gy), method=method)\n        if np.any(np.isnan(grid)):\n            grid_nn = griddata(points, vmem, (gx, gy), method=\"nearest\")\n            grid = np.where(np.isnan(grid), grid_nn, grid)\n        frames.append(grid)\n\n    field_sequence = np.stack(frames, axis=0)\n\n    metadata = {\n        \"n_cells\": len(frame_data[0][0]),\n        \"n_timesteps\": len(frames),\n        \"grid_x\": grid_x,\n        \"grid_y\": grid_y,\n        \"x_bounds\": (float(x_min), float(x_max)),\n        \"y_bounds\": (float(y_min), float(y_max)),\n        \"resolution\": resolution,\n        \"interpolation_method\": method,\n        \"source_dir\": str(vmem_dir),\n        \"source\": \"BETSE\",\n        \"units\": {\"spatial\": \"um\", \"voltage\": \"mV\"},\n    }\n\n    logger.info(\n        \"Loaded BETSE field sequence: shape=%s, Vmem range=[%.2f, %.2f] mV\",\n        field_sequence.shape, field_sequence.min(), field_sequence.max(),\n    )\n\n    return field_sequence, metadata\n</code></pre>"},{"location":"api/data/betse_loader/#mneme.data.betse_loader.load_betse_vmem_csv","title":"load_betse_vmem_csv","text":"<pre><code>load_betse_vmem_csv(csv_path: Union[str, Path]) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Load a single BETSE Vmem2D CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>str or Path</code> <p>Path to a Vmem2D_*.csv file exported by BETSE.</p> required <p>Returns:</p> Name Type Description <code>x</code> <code>ndarray</code> <p>Cell x-coordinates in micrometres, shape (n_cells,).</p> <code>y</code> <code>ndarray</code> <p>Cell y-coordinates in micrometres, shape (n_cells,).</p> <code>vmem</code> <code>ndarray</code> <p>Transmembrane voltage in millivolts, shape (n_cells,).</p> Source code in <code>src/mneme/data/betse_loader.py</code> <pre><code>def load_betse_vmem_csv(\n    csv_path: Union[str, Path],\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Load a single BETSE Vmem2D CSV file.\n\n    Parameters\n    ----------\n    csv_path : str or Path\n        Path to a Vmem2D_*.csv file exported by BETSE.\n\n    Returns\n    -------\n    x : np.ndarray\n        Cell x-coordinates in micrometres, shape (n_cells,).\n    y : np.ndarray\n        Cell y-coordinates in micrometres, shape (n_cells,).\n    vmem : np.ndarray\n        Transmembrane voltage in millivolts, shape (n_cells,).\n    \"\"\"\n    csv_path = Path(csv_path)\n    data = np.loadtxt(csv_path, delimiter=\",\", skiprows=1)\n    if data.ndim != 2 or data.shape[1] &lt; 3:\n        raise ValueError(\n            f\"Expected CSV with at least 3 columns (x, y, Vmem), \"\n            f\"got shape {data.shape} from {csv_path}\"\n        )\n    return data[:, 0], data[:, 1], data[:, 2]\n</code></pre>"},{"location":"api/data/betse_loader/#mneme.data.betse_loader.load_betse_exported_data","title":"load_betse_exported_data","text":"<pre><code>load_betse_exported_data(csv_path: Union[str, Path]) -&gt; Tuple[np.ndarray, List[str]]\n</code></pre> <p>Load a BETSE ExportedData.csv single-cell time series.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>str or Path</code> <p>Path to ExportedData.csv.</p> required <p>Returns:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>Shape (n_timesteps, n_columns) array.</p> <code>columns</code> <code>List[str]</code> <p>Column names from the CSV header.</p> Source code in <code>src/mneme/data/betse_loader.py</code> <pre><code>def load_betse_exported_data(\n    csv_path: Union[str, Path],\n) -&gt; Tuple[np.ndarray, List[str]]:\n    \"\"\"Load a BETSE ExportedData.csv single-cell time series.\n\n    Parameters\n    ----------\n    csv_path : str or Path\n        Path to ExportedData.csv.\n\n    Returns\n    -------\n    data : np.ndarray\n        Shape (n_timesteps, n_columns) array.\n    columns : List[str]\n        Column names from the CSV header.\n    \"\"\"\n    csv_path = Path(csv_path)\n    with open(csv_path, \"r\") as f:\n        header = f.readline().strip()\n    columns = [c.strip() for c in header.split(\",\")]\n    data = np.loadtxt(csv_path, delimiter=\",\", skiprows=1)\n    return data, columns\n</code></pre>"},{"location":"api/data/betse_loader/#grid-interpolation","title":"Grid Interpolation","text":""},{"location":"api/data/betse_loader/#mneme.data.betse_loader.interpolate_to_grid","title":"interpolate_to_grid","text":"<pre><code>interpolate_to_grid(x: ndarray, y: ndarray, values: ndarray, resolution: Tuple[int, int] = DEFAULT_GRID_RESOLUTION, method: str = 'cubic', padding: float = 0.05) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Interpolate scattered cell data onto a regular grid.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Irregular cell positions, each shape (n_cells,).</p> required <code>y</code> <code>ndarray</code> <p>Irregular cell positions, each shape (n_cells,).</p> required <code>values</code> <code>ndarray</code> <p>Scalar values at cell positions, shape (n_cells,).</p> required <code>resolution</code> <code>Tuple[int, int]</code> <p>Target grid resolution (rows, cols).</p> <code>DEFAULT_GRID_RESOLUTION</code> <code>method</code> <code>str</code> <p>Interpolation method ('linear', 'cubic', 'nearest').</p> <code>'cubic'</code> <code>padding</code> <code>float</code> <p>Fractional padding around data extent (0.05 = 5%).</p> <code>0.05</code> <p>Returns:</p> Name Type Description <code>grid</code> <code>ndarray</code> <p>Interpolated field, shape resolution.</p> <code>grid_x</code> <code>ndarray</code> <p>1-D array of x-coordinates for the regular grid.</p> <code>grid_y</code> <code>ndarray</code> <p>1-D array of y-coordinates for the regular grid.</p> Source code in <code>src/mneme/data/betse_loader.py</code> <pre><code>def interpolate_to_grid(\n    x: np.ndarray,\n    y: np.ndarray,\n    values: np.ndarray,\n    resolution: Tuple[int, int] = DEFAULT_GRID_RESOLUTION,\n    method: str = \"cubic\",\n    padding: float = 0.05,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Interpolate scattered cell data onto a regular grid.\n\n    Parameters\n    ----------\n    x, y : np.ndarray\n        Irregular cell positions, each shape (n_cells,).\n    values : np.ndarray\n        Scalar values at cell positions, shape (n_cells,).\n    resolution : Tuple[int, int]\n        Target grid resolution (rows, cols).\n    method : str\n        Interpolation method ('linear', 'cubic', 'nearest').\n    padding : float\n        Fractional padding around data extent (0.05 = 5%).\n\n    Returns\n    -------\n    grid : np.ndarray\n        Interpolated field, shape *resolution*.\n    grid_x : np.ndarray\n        1-D array of x-coordinates for the regular grid.\n    grid_y : np.ndarray\n        1-D array of y-coordinates for the regular grid.\n    \"\"\"\n    # Compute data extent with padding\n    x_range = x.max() - x.min()\n    y_range = y.max() - y.min()\n    pad_x = x_range * padding\n    pad_y = y_range * padding\n\n    grid_x = np.linspace(x.min() - pad_x, x.max() + pad_x, resolution[1])\n    grid_y = np.linspace(y.min() - pad_y, y.max() + pad_y, resolution[0])\n    gx, gy = np.meshgrid(grid_x, grid_y)\n\n    points = np.column_stack([x, y])\n    grid = griddata(points, values, (gx, gy), method=method)\n\n    # Fill NaN regions (outside convex hull) with nearest-neighbour values\n    if np.any(np.isnan(grid)):\n        grid_nn = griddata(points, values, (gx, gy), method=\"nearest\")\n        grid = np.where(np.isnan(grid), grid_nn, grid)\n\n    return grid, grid_x, grid_y\n</code></pre>"},{"location":"api/data/generators/","title":"Generators","text":"<p>Synthetic field data generation for testing and validation.</p>"},{"location":"api/data/generators/#generator-class","title":"Generator Class","text":""},{"location":"api/data/generators/#mneme.data.generators.SyntheticFieldGenerator","title":"SyntheticFieldGenerator","text":"<pre><code>SyntheticFieldGenerator(field_type: str = 'gaussian_random', seed: Optional[int] = None)\n</code></pre> <p>Generate synthetic field data for testing.</p> <p>Initialize synthetic field generator.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <code>str</code> <p>Type of field to generate</p> <code>'gaussian_random'</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility</p> <code>None</code> Source code in <code>src/mneme/data/generators.py</code> <pre><code>def __init__(self, field_type: str = \"gaussian_random\", seed: Optional[int] = None):\n    \"\"\"\n    Initialize synthetic field generator.\n\n    Parameters\n    ----------\n    field_type : str\n        Type of field to generate\n    seed : int, optional\n        Random seed for reproducibility\n    \"\"\"\n    self.field_type = field_type\n    self.seed = seed\n    if seed is not None:\n        np.random.seed(seed)\n</code></pre>"},{"location":"api/data/generators/#mneme.data.generators.SyntheticFieldGenerator.generate_static","title":"generate_static","text":"<pre><code>generate_static(shape: Tuple[int, ...], parameters: Dict[str, Any]) -&gt; np.ndarray\n</code></pre> <p>Generate static field.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Tuple[int, ...]</code> <p>Shape of field to generate</p> required <code>parameters</code> <code>Dict[str, Any]</code> <p>Parameters specific to field type</p> required <p>Returns:</p> Name Type Description <code>field</code> <code>ndarray</code> <p>Generated field</p> Source code in <code>src/mneme/data/generators.py</code> <pre><code>def generate_static(self, shape: Tuple[int, ...], parameters: Dict[str, Any]) -&gt; np.ndarray:\n    \"\"\"\n    Generate static field.\n\n    Parameters\n    ----------\n    shape : Tuple[int, ...]\n        Shape of field to generate\n    parameters : Dict[str, Any]\n        Parameters specific to field type\n\n    Returns\n    -------\n    field : np.ndarray\n        Generated field\n    \"\"\"\n    if self.field_type == \"gaussian_random\":\n        return self._generate_gaussian_random(shape, parameters)\n    elif self.field_type == \"gaussian_blob\":\n        return self._generate_gaussian_blob(shape, parameters)\n    elif self.field_type == \"sinusoidal\":\n        return self._generate_sinusoidal(shape, parameters)\n    elif self.field_type == \"turbulent\":\n        return self._generate_turbulent(shape, parameters)\n    elif self.field_type == \"reaction_diffusion\":\n        return self._generate_reaction_diffusion(shape, parameters)\n    elif self.field_type == \"bioelectric_gradient\":\n        return self._generate_bioelectric_gradient(shape, parameters)\n    else:\n        raise ValueError(f\"Unknown field type: {self.field_type}\")\n</code></pre>"},{"location":"api/data/generators/#mneme.data.generators.SyntheticFieldGenerator.generate_dynamic","title":"generate_dynamic","text":"<pre><code>generate_dynamic(shape: Tuple[int, ...], timesteps: int, parameters: Dict[str, Any]) -&gt; np.ndarray\n</code></pre> <p>Generate time-evolving field.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Tuple[int, ...]</code> <p>Spatial shape of field</p> required <code>timesteps</code> <code>int</code> <p>Number of time steps</p> required <code>parameters</code> <code>Dict[str, Any]</code> <p>Parameters for evolution</p> required <p>Returns:</p> Name Type Description <code>field</code> <code>ndarray</code> <p>Time-evolving field with shape (timesteps, *shape)</p> Source code in <code>src/mneme/data/generators.py</code> <pre><code>def generate_dynamic(\n    self, \n    shape: Tuple[int, ...], \n    timesteps: int, \n    parameters: Dict[str, Any]\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate time-evolving field.\n\n    Parameters\n    ----------\n    shape : Tuple[int, ...]\n        Spatial shape of field\n    timesteps : int\n        Number of time steps\n    parameters : Dict[str, Any]\n        Parameters for evolution\n\n    Returns\n    -------\n    field : np.ndarray\n        Time-evolving field with shape (timesteps, *shape)\n    \"\"\"\n    # Generate initial field\n    initial_field = self.generate_static(shape, parameters)\n\n    # Initialize output array\n    dynamic_field = np.zeros((timesteps, *shape))\n    dynamic_field[0] = initial_field\n\n    # Get evolution parameters\n    drift_velocity = parameters.get(\"drift_velocity\", (0.0, 0.0))\n    growth_rate = parameters.get(\"growth_rate\", 0.0)\n    diffusion_rate = parameters.get(\"diffusion_rate\", 0.01)\n    noise_level = parameters.get(\"noise_level\", 0.0)\n\n    # Evolve field over time\n    for t in range(1, timesteps):\n        current_field = dynamic_field[t-1].copy()\n\n        # Apply drift\n        if drift_velocity != (0.0, 0.0):\n            current_field = self._apply_drift(current_field, drift_velocity)\n\n        # Apply growth/decay\n        if growth_rate != 0.0:\n            current_field *= (1 + growth_rate)\n\n        # Apply diffusion\n        if diffusion_rate &gt; 0.0:\n            current_field = gaussian_filter(current_field, sigma=diffusion_rate)\n\n        # Add noise\n        if noise_level &gt; 0.0:\n            noise = np.random.normal(0, noise_level, current_field.shape)\n            current_field += noise\n\n        dynamic_field[t] = current_field\n\n    return dynamic_field\n</code></pre>"},{"location":"api/data/generators/#mneme.data.generators.SyntheticFieldGenerator.add_noise","title":"add_noise","text":"<pre><code>add_noise(field: ndarray, noise_level: float, noise_type: str = 'gaussian') -&gt; np.ndarray\n</code></pre> <p>Add realistic noise to field.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>Clean field</p> required <code>noise_level</code> <code>float</code> <p>Noise intensity</p> required <code>noise_type</code> <code>str</code> <p>Type of noise to add</p> <code>'gaussian'</code> <p>Returns:</p> Name Type Description <code>noisy_field</code> <code>ndarray</code> <p>Field with added noise</p> Source code in <code>src/mneme/data/generators.py</code> <pre><code>def add_noise(\n    self, \n    field: np.ndarray, \n    noise_level: float, \n    noise_type: str = \"gaussian\"\n) -&gt; np.ndarray:\n    \"\"\"\n    Add realistic noise to field.\n\n    Parameters\n    ----------\n    field : np.ndarray\n        Clean field\n    noise_level : float\n        Noise intensity\n    noise_type : str\n        Type of noise to add\n\n    Returns\n    -------\n    noisy_field : np.ndarray\n        Field with added noise\n    \"\"\"\n    noisy_field = field.copy()\n\n    if noise_type == \"gaussian\":\n        noise = np.random.normal(0, noise_level, field.shape)\n        noisy_field += noise\n    elif noise_type == \"poisson\":\n        # Scale to positive values for Poisson noise\n        scaled_field = field - field.min() + 1e-6\n        noisy_field = np.random.poisson(scaled_field * noise_level) / noise_level\n        noisy_field += field.min()\n    elif noise_type == \"salt_pepper\":\n        mask = np.random.random(field.shape) &lt; noise_level\n        salt_pepper = np.random.choice([0, 1], size=field.shape, p=[0.5, 0.5])\n        noisy_field[mask] = salt_pepper[mask] * (field.max() - field.min()) + field.min()\n    elif noise_type == \"speckle\":\n        noise = np.random.normal(1, noise_level, field.shape)\n        noisy_field *= noise\n    else:\n        raise ValueError(f\"Unknown noise type: {noise_type}\")\n\n    return noisy_field\n</code></pre>"},{"location":"api/data/generators/#convenience-functions","title":"Convenience Functions","text":""},{"location":"api/data/generators/#mneme.data.generators.generate_planarian_bioelectric_sequence","title":"generate_planarian_bioelectric_sequence","text":"<pre><code>generate_planarian_bioelectric_sequence(shape: Tuple[int, int] = (256, 128), timesteps: int = 100, regeneration_event_time: int = 20, seed: Optional[int] = None) -&gt; np.ndarray\n</code></pre> <p>Generate a sequence mimicking planarian bioelectric patterns during regeneration.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Tuple[int, int]</code> <p>Field shape (height, width)</p> <code>(256, 128)</code> <code>timesteps</code> <code>int</code> <p>Number of time steps</p> <code>100</code> <code>regeneration_event_time</code> <code>int</code> <p>Time step when regeneration event occurs</p> <code>20</code> <code>seed</code> <code>int</code> <p>Random seed</p> <code>None</code> <p>Returns:</p> Name Type Description <code>sequence</code> <code>ndarray</code> <p>Bioelectric sequence with shape (timesteps, height, width)</p> Source code in <code>src/mneme/data/generators.py</code> <pre><code>def generate_planarian_bioelectric_sequence(\n    shape: Tuple[int, int] = (256, 128),\n    timesteps: int = 100,\n    regeneration_event_time: int = 20,\n    seed: Optional[int] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate a sequence mimicking planarian bioelectric patterns during regeneration.\n\n    Parameters\n    ----------\n    shape : Tuple[int, int]\n        Field shape (height, width)\n    timesteps : int\n        Number of time steps\n    regeneration_event_time : int\n        Time step when regeneration event occurs\n    seed : int, optional\n        Random seed\n\n    Returns\n    -------\n    sequence : np.ndarray\n        Bioelectric sequence with shape (timesteps, height, width)\n    \"\"\"\n    if seed is not None:\n        np.random.seed(seed)\n\n    generator = SyntheticFieldGenerator(\"bioelectric_gradient\", seed=seed)\n\n    # Pre-regeneration parameters\n    pre_params = {\n        \"anterior_voltage\": -50.0,\n        \"posterior_voltage\": -20.0,\n        \"lateral_variation\": 5.0,\n        \"gradient_steepness\": 0.1\n    }\n\n    # Post-regeneration parameters (more dynamic)\n    post_params = {\n        \"anterior_voltage\": -60.0,\n        \"posterior_voltage\": -15.0,\n        \"lateral_variation\": 15.0,\n        \"gradient_steepness\": 0.2\n    }\n\n    sequence = np.zeros((timesteps, *shape))\n\n    for t in range(timesteps):\n        # Gradually transition parameters after regeneration event\n        if t &lt; regeneration_event_time:\n            params = pre_params.copy()\n        else:\n            # Smoothly transition parameters\n            alpha = min(1.0, (t - regeneration_event_time) / 20.0)\n            params = {}\n            for key in pre_params:\n                params[key] = pre_params[key] + alpha * (post_params[key] - pre_params[key])\n\n        # Generate field for this time step\n        field = generator.generate_static(shape, params)\n\n        # Add temporal noise\n        noise = np.random.normal(0, 1, shape)\n        field += gaussian_filter(noise, sigma=1.0)\n\n        sequence[t] = field\n\n    return sequence\n</code></pre>"},{"location":"api/data/preprocessors/","title":"Preprocessors","text":"<p>Data preprocessing utilities for field data: denoising, normalization, interpolation, and registration.</p>"},{"location":"api/data/preprocessors/#preprocessor-classes","title":"Preprocessor Classes","text":""},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Denoiser","title":"Denoiser","text":"<pre><code>Denoiser(method: str = 'gaussian', sigma: float = 1.0, threshold: Optional[str] = None, wavelet: str = 'db4', levels: int = 3)\n</code></pre> <p>               Bases: <code>BasePreprocessor</code></p> <p>Denoise field data using various methods.</p> <p>Initialize denoiser.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Denoising method ('gaussian', 'median', 'wavelet')</p> <code>'gaussian'</code> <code>sigma</code> <code>float</code> <p>Standard deviation for Gaussian filter</p> <code>1.0</code> <code>threshold</code> <code>str</code> <p>Wavelet threshold method ('soft', 'hard')</p> <code>None</code> <code>wavelet</code> <code>str</code> <p>Wavelet type for wavelet denoising</p> <code>'db4'</code> <code>levels</code> <code>int</code> <p>Number of wavelet decomposition levels</p> <code>3</code> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def __init__(\n    self,\n    method: str = \"gaussian\",\n    sigma: float = 1.0,\n    threshold: Optional[str] = None,\n    wavelet: str = \"db4\",\n    levels: int = 3\n):\n    \"\"\"\n    Initialize denoiser.\n\n    Parameters\n    ----------\n    method : str\n        Denoising method ('gaussian', 'median', 'wavelet')\n    sigma : float\n        Standard deviation for Gaussian filter\n    threshold : str, optional\n        Wavelet threshold method ('soft', 'hard')\n    wavelet : str\n        Wavelet type for wavelet denoising\n    levels : int\n        Number of wavelet decomposition levels\n    \"\"\"\n    super().__init__()\n    self.method = method\n    self.sigma = sigma\n    self.threshold = threshold\n    self.wavelet = wavelet\n    self.levels = levels\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Denoiser.fit","title":"fit","text":"<pre><code>fit(data: ndarray) -&gt; Denoiser\n</code></pre> <p>Fit denoiser parameters.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit(self, data: np.ndarray) -&gt; 'Denoiser':\n    \"\"\"Fit denoiser parameters.\"\"\"\n    if self.method == \"gaussian\":\n        # Estimate optimal sigma if not provided\n        if self.sigma == \"auto\":\n            # Simple noise estimation using high-frequency content\n            if data.ndim == 2:\n                laplacian = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])\n                noise_est = np.abs(ndimage.convolve(data, laplacian)).mean()\n                self.sigma = max(0.5, min(3.0, noise_est / 2))\n            else:\n                self.sigma = 1.0\n\n        self.parameters[\"sigma\"] = self.sigma\n\n    elif self.method == \"median\":\n        # Median filter doesn't need fitting\n        self.parameters[\"kernel_size\"] = 3\n\n    elif self.method == \"wavelet\":\n        try:\n            import pywt\n            # Estimate noise threshold\n            coeffs = pywt.wavedec2(data, self.wavelet, level=self.levels)\n            sigma_est = np.median(np.abs(coeffs[-1])) / 0.6745\n            self.parameters[\"threshold_value\"] = sigma_est * np.sqrt(2 * np.log(data.size))\n            self.parameters[\"sigma_est\"] = sigma_est\n        except ImportError:\n            warnings.warn(\"PyWavelets not available, falling back to Gaussian\")\n            self.method = \"gaussian\"\n            self.sigma = 1.0\n            self.parameters[\"sigma\"] = self.sigma\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Denoiser.transform","title":"transform","text":"<pre><code>transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply denoising transformation.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply denoising transformation.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Denoiser must be fitted before transformation\")\n\n    if self.method == \"gaussian\":\n        return gaussian_filter(data, sigma=self.parameters[\"sigma\"])\n\n    elif self.method == \"median\":\n        return median_filter(data, size=self.parameters[\"kernel_size\"])\n\n    elif self.method == \"wavelet\":\n        try:\n            import pywt\n            coeffs = pywt.wavedec2(data, self.wavelet, level=self.levels)\n\n            # Apply threshold\n            threshold_value = self.parameters[\"threshold_value\"]\n            if self.threshold == \"soft\":\n                coeffs_thresh = list(coeffs)\n                coeffs_thresh[1:] = [\n                    pywt.threshold(detail, threshold_value, mode='soft') \n                    for detail in coeffs_thresh[1:]\n                ]\n            elif self.threshold == \"hard\":\n                coeffs_thresh = list(coeffs)\n                coeffs_thresh[1:] = [\n                    pywt.threshold(detail, threshold_value, mode='hard') \n                    for detail in coeffs_thresh[1:]\n                ]\n            else:\n                coeffs_thresh = coeffs\n\n            return pywt.waverec2(coeffs_thresh, self.wavelet)\n        except ImportError:\n            # Fallback to Gaussian if wavelet not available\n            return gaussian_filter(data, sigma=1.0)\n\n    else:\n        raise ValueError(f\"Unknown denoising method: {self.method}\")\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Normalizer","title":"Normalizer","text":"<pre><code>Normalizer(method: str = 'z_score', per_frame: bool = False, clip_percentile: Optional[float] = None)\n</code></pre> <p>               Bases: <code>BasePreprocessor</code></p> <p>Normalize field data.</p> <p>Initialize normalizer.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Normalization method ('z_score', 'min_max', 'robust')</p> <code>'z_score'</code> <code>per_frame</code> <code>bool</code> <p>Whether to normalize each frame independently</p> <code>False</code> <code>clip_percentile</code> <code>float</code> <p>Percentile for clipping outliers before normalization</p> <code>None</code> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def __init__(\n    self,\n    method: str = \"z_score\",\n    per_frame: bool = False,\n    clip_percentile: Optional[float] = None\n):\n    \"\"\"\n    Initialize normalizer.\n\n    Parameters\n    ----------\n    method : str\n        Normalization method ('z_score', 'min_max', 'robust')\n    per_frame : bool\n        Whether to normalize each frame independently\n    clip_percentile : float, optional\n        Percentile for clipping outliers before normalization\n    \"\"\"\n    super().__init__()\n    self.method = method\n    self.per_frame = per_frame\n    self.clip_percentile = clip_percentile\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Normalizer.fit","title":"fit","text":"<pre><code>fit(data: ndarray) -&gt; Normalizer\n</code></pre> <p>Fit normalization parameters.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit(self, data: np.ndarray) -&gt; 'Normalizer':\n    \"\"\"Fit normalization parameters.\"\"\"\n    if self.per_frame and data.ndim == 3:\n        # Fit parameters for each frame\n        self.parameters[\"frame_params\"] = []\n        for i in range(data.shape[0]):\n            frame_data = data[i]\n            params = self._fit_frame(frame_data)\n            self.parameters[\"frame_params\"].append(params)\n    else:\n        # Fit parameters for entire dataset\n        self.parameters.update(self._fit_frame(data))\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Normalizer.transform","title":"transform","text":"<pre><code>transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply normalization transformation.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply normalization transformation.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Normalizer must be fitted before transformation\")\n\n    if self.per_frame and data.ndim == 3:\n        # Transform each frame\n        result = np.zeros_like(data)\n        for i in range(data.shape[0]):\n            if i &lt; len(self.parameters[\"frame_params\"]):\n                params = self.parameters[\"frame_params\"][i]\n            else:\n                # Use last frame's parameters for extra frames\n                params = self.parameters[\"frame_params\"][-1]\n            result[i] = self._transform_frame(data[i], params)\n        return result\n    else:\n        # Transform entire dataset\n        return self._transform_frame(data, self.parameters)\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Interpolator","title":"Interpolator","text":"<pre><code>Interpolator(target_shape: Tuple[int, int], method: str = 'bicubic', preserve_range: bool = True)\n</code></pre> <p>               Bases: <code>BasePreprocessor</code></p> <p>Interpolate field data to different resolutions.</p> <p>Initialize interpolator.</p> <p>Parameters:</p> Name Type Description Default <code>target_shape</code> <code>Tuple[int, int]</code> <p>Target shape (height, width)</p> required <code>method</code> <code>str</code> <p>Interpolation method ('nearest', 'linear', 'bicubic')</p> <code>'bicubic'</code> <code>preserve_range</code> <code>bool</code> <p>Whether to preserve original value range</p> <code>True</code> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def __init__(\n    self,\n    target_shape: Tuple[int, int],\n    method: str = \"bicubic\",\n    preserve_range: bool = True\n):\n    \"\"\"\n    Initialize interpolator.\n\n    Parameters\n    ----------\n    target_shape : Tuple[int, int]\n        Target shape (height, width)\n    method : str\n        Interpolation method ('nearest', 'linear', 'bicubic')\n    preserve_range : bool\n        Whether to preserve original value range\n    \"\"\"\n    super().__init__()\n    self.target_shape = target_shape\n    self.method = method\n    self.preserve_range = preserve_range\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Interpolator.fit","title":"fit","text":"<pre><code>fit(data: ndarray) -&gt; Interpolator\n</code></pre> <p>Fit interpolation parameters.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit(self, data: np.ndarray) -&gt; 'Interpolator':\n    \"\"\"Fit interpolation parameters.\"\"\"\n    self.parameters[\"original_shape\"] = data.shape[-2:]\n\n    if self.preserve_range:\n        if data.ndim == 2:\n            self.parameters[\"value_range\"] = (np.min(data), np.max(data))\n        else:\n            self.parameters[\"value_range\"] = (np.min(data), np.max(data))\n\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Interpolator.transform","title":"transform","text":"<pre><code>transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply interpolation transformation.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply interpolation transformation.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Interpolator must be fitted before transformation\")\n\n    original_shape = data.shape\n\n    if data.ndim == 2:\n        result = self._interpolate_2d(data)\n    elif data.ndim == 3:\n        result = np.zeros((data.shape[0], *self.target_shape))\n        for i in range(data.shape[0]):\n            result[i] = self._interpolate_2d(data[i])\n    else:\n        raise ValueError(\"Interpolation only supports 2D or 3D data\")\n\n    # Preserve value range if requested\n    if self.preserve_range and \"value_range\" in self.parameters:\n        min_val, max_val = self.parameters[\"value_range\"]\n        result = np.clip(result, min_val, max_val)\n\n    return result\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Registrator","title":"Registrator","text":"<pre><code>Registrator(reference: str = 'first', method: str = 'rigid', max_shift: int = 10)\n</code></pre> <p>               Bases: <code>BasePreprocessor</code></p> <p>Register field data to align sequences.</p> <p>Initialize registrator.</p> <p>Parameters:</p> Name Type Description Default <code>reference</code> <code>str</code> <p>Reference frame ('first', 'mean', 'median')</p> <code>'first'</code> <code>method</code> <code>str</code> <p>Registration method ('rigid', 'translation_only')</p> <code>'rigid'</code> <code>max_shift</code> <code>int</code> <p>Maximum allowed shift in pixels</p> <code>10</code> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def __init__(\n    self,\n    reference: str = \"first\",\n    method: str = \"rigid\",\n    max_shift: int = 10\n):\n    \"\"\"\n    Initialize registrator.\n\n    Parameters\n    ----------\n    reference : str\n        Reference frame ('first', 'mean', 'median')\n    method : str\n        Registration method ('rigid', 'translation_only')\n    max_shift : int\n        Maximum allowed shift in pixels\n    \"\"\"\n    super().__init__()\n    self.reference = reference\n    self.method = method\n    self.max_shift = max_shift\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Registrator.fit","title":"fit","text":"<pre><code>fit(data: ndarray) -&gt; Registrator\n</code></pre> <p>Fit registration parameters.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit(self, data: np.ndarray) -&gt; 'Registrator':\n    \"\"\"Fit registration parameters.\"\"\"\n    if data.ndim != 3:\n        raise ValueError(\"Registration requires 3D data (time, height, width)\")\n\n    # Compute reference frame\n    if self.reference == \"first\":\n        self.parameters[\"reference_frame\"] = data[0].copy()\n    elif self.reference == \"mean\":\n        self.parameters[\"reference_frame\"] = np.mean(data, axis=0)\n    elif self.reference == \"median\":\n        self.parameters[\"reference_frame\"] = np.median(data, axis=0)\n    else:\n        raise ValueError(f\"Unknown reference type: {self.reference}\")\n\n    # Compute shifts for each frame\n    shifts = []\n    for i in range(data.shape[0]):\n        shift = self._compute_shift(data[i], self.parameters[\"reference_frame\"])\n        shifts.append(shift)\n\n    self.parameters[\"shifts\"] = shifts\n    self.is_fitted = True\n    return self\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.Registrator.transform","title":"transform","text":"<pre><code>transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply registration transformation.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply registration transformation.\"\"\"\n    if not self.is_fitted:\n        raise RuntimeError(\"Registrator must be fitted before transformation\")\n\n    if data.ndim != 3:\n        raise ValueError(\"Registration requires 3D data (time, height, width)\")\n\n    result = np.zeros_like(data)\n    for i in range(data.shape[0]):\n        if i &lt; len(self.parameters[\"shifts\"]):\n            shift = self.parameters[\"shifts\"][i]\n        else:\n            shift = (0, 0)  # No shift for extra frames\n\n        # Apply shift\n        if shift != (0, 0):\n            result[i] = ndimage.shift(data[i], shift, mode='constant', cval=0)\n        else:\n            result[i] = data[i]\n\n    return result\n</code></pre>"},{"location":"api/data/preprocessors/#composite-preprocessor","title":"Composite Preprocessor","text":""},{"location":"api/data/preprocessors/#mneme.data.preprocessors.FieldPreprocessor","title":"FieldPreprocessor","text":"<pre><code>FieldPreprocessor(steps: List[Union[str, Tuple[str, Dict[str, Any]]]])\n</code></pre> <p>Combined preprocessing pipeline for field data.</p> <p>Initialize preprocessing pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>steps</code> <code>List[Union[str, Tuple[str, Dict[str, Any]]]]</code> <p>List of preprocessing steps</p> required Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def __init__(self, steps: List[Union[str, Tuple[str, Dict[str, Any]]]]):\n    \"\"\"\n    Initialize preprocessing pipeline.\n\n    Parameters\n    ----------\n    steps : List[Union[str, Tuple[str, Dict[str, Any]]]]\n        List of preprocessing steps\n    \"\"\"\n    self.steps = []\n    self.step_names = []\n\n    for step in steps:\n        if isinstance(step, str):\n            name = step\n            params = {}\n        else:\n            name, params = step\n\n        self.step_names.append(name)\n\n        if name == \"denoise\":\n            self.steps.append(Denoiser(**params))\n        elif name == \"normalize\":\n            self.steps.append(Normalizer(**params))\n        elif name == \"register\":\n            self.steps.append(Registrator(**params))\n        elif name == \"interpolate\":\n            self.steps.append(Interpolator(**params))\n        else:\n            raise ValueError(f\"Unknown preprocessing step: {name}\")\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.FieldPreprocessor.fit","title":"fit","text":"<pre><code>fit(data: ndarray) -&gt; FieldPreprocessor\n</code></pre> <p>Fit all preprocessing steps.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit(self, data: np.ndarray) -&gt; 'FieldPreprocessor':\n    \"\"\"Fit all preprocessing steps.\"\"\"\n    current_data = data\n\n    for step in self.steps:\n        step.fit(current_data)\n        current_data = step.transform(current_data)\n\n    return self\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.FieldPreprocessor.transform","title":"transform","text":"<pre><code>transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply all preprocessing steps.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply all preprocessing steps.\"\"\"\n    current_data = data\n\n    for step in self.steps:\n        current_data = step.transform(current_data)\n\n    return current_data\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.FieldPreprocessor.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Fit and transform data.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit_transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Fit and transform data.\"\"\"\n    return self.fit(data).transform(data)\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.FieldPreprocessor.get_step_parameters","title":"get_step_parameters","text":"<pre><code>get_step_parameters() -&gt; Dict[str, Dict[str, Any]]\n</code></pre> <p>Get parameters for all steps.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def get_step_parameters(self) -&gt; Dict[str, Dict[str, Any]]:\n    \"\"\"Get parameters for all steps.\"\"\"\n    parameters = {}\n    for name, step in zip(self.step_names, self.steps):\n        parameters[name] = step.get_parameters()\n    return parameters\n</code></pre>"},{"location":"api/data/preprocessors/#base-class","title":"Base Class","text":""},{"location":"api/data/preprocessors/#mneme.data.preprocessors.BasePreprocessor","title":"BasePreprocessor","text":"<pre><code>BasePreprocessor()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for preprocessing steps.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def __init__(self):\n    self.is_fitted = False\n    self.parameters = {}\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.BasePreprocessor.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(data: ndarray) -&gt; BasePreprocessor\n</code></pre> <p>Fit preprocessing parameters to data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data to fit to</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>BasePreprocessor</code> <p>Fitted preprocessor</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>@abstractmethod\ndef fit(self, data: np.ndarray) -&gt; 'BasePreprocessor':\n    \"\"\"\n    Fit preprocessing parameters to data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Input data to fit to\n\n    Returns\n    -------\n    self : BasePreprocessor\n        Fitted preprocessor\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.BasePreprocessor.transform","title":"transform  <code>abstractmethod</code>","text":"<pre><code>transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Apply preprocessing transformation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data to transform</p> required <p>Returns:</p> Name Type Description <code>transformed</code> <code>ndarray</code> <p>Transformed data</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>@abstractmethod\ndef transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply preprocessing transformation.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Input data to transform\n\n    Returns\n    -------\n    transformed : np.ndarray\n        Transformed data\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.BasePreprocessor.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(data: ndarray) -&gt; np.ndarray\n</code></pre> <p>Fit and transform data in one step.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def fit_transform(self, data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Fit and transform data in one step.\"\"\"\n    return self.fit(data).transform(data)\n</code></pre>"},{"location":"api/data/preprocessors/#mneme.data.preprocessors.BasePreprocessor.get_parameters","title":"get_parameters","text":"<pre><code>get_parameters() -&gt; Dict[str, Any]\n</code></pre> <p>Get fitted parameters.</p> Source code in <code>src/mneme/data/preprocessors.py</code> <pre><code>def get_parameters(self) -&gt; Dict[str, Any]:\n    \"\"\"Get fitted parameters.\"\"\"\n    return self.parameters.copy()\n</code></pre>"},{"location":"api/models/autoencoders/","title":"Autoencoders","text":"<p>Convolutional Variational Autoencoder for learning compressed field representations.</p>"},{"location":"api/models/autoencoders/#factory-function","title":"Factory Function","text":""},{"location":"api/models/autoencoders/#mneme.models.autoencoders.create_field_vae","title":"create_field_vae","text":"<pre><code>create_field_vae(input_shape: Tuple[int, int], latent_dim: int = 32, architecture: str = 'standard') -&gt; FieldAutoencoder\n</code></pre> <p>Create a FieldAutoencoder with sensible defaults.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>Tuple[int, int]</code> <p>Field dimensions (height, width).</p> required <code>latent_dim</code> <code>int</code> <p>Latent space dimension.</p> <code>32</code> <code>architecture</code> <code>str</code> <p>'standard' or 'deep'.</p> <code>'standard'</code> <p>Returns:</p> Name Type Description <code>vae</code> <code>FieldAutoencoder</code> <p>Configured VAE ready for training.</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def create_field_vae(\n    input_shape: Tuple[int, int],\n    latent_dim: int = 32,\n    architecture: str = \"standard\",\n) -&gt; FieldAutoencoder:\n    \"\"\"Create a FieldAutoencoder with sensible defaults.\n\n    Parameters\n    ----------\n    input_shape : Tuple[int, int]\n        Field dimensions (height, width).\n    latent_dim : int\n        Latent space dimension.\n    architecture : str\n        'standard' or 'deep'.\n\n    Returns\n    -------\n    vae : FieldAutoencoder\n        Configured VAE ready for training.\n    \"\"\"\n    return FieldAutoencoder(\n        input_shape=input_shape,\n        latent_dim=latent_dim,\n        architecture=architecture,\n        base_channels=32,\n        beta=1.0,\n    )\n</code></pre>"},{"location":"api/models/autoencoders/#vae-model","title":"VAE Model","text":""},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder","title":"FieldAutoencoder","text":"<pre><code>FieldAutoencoder(input_shape: Tuple[int, int], latent_dim: int = 32, in_channels: int = 1, base_channels: int = 32, architecture: str = 'standard', beta: float = 1.0)\n</code></pre> <p>               Bases: <code>Module if _TORCH_AVAILABLE else object</code></p> <p>Convolutional Variational Autoencoder for 2D field data.</p> <p>This VAE learns a compressed latent representation of bioelectric field patterns, which can be used for: - Dimensionality reduction - Anomaly detection - Generative modeling - Feature extraction for downstream analysis</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>Tuple[int, int]</code> <p>Shape of input field (height, width). Should be divisible by 16.</p> required <code>latent_dim</code> <code>int</code> <p>Dimension of latent space. Default 32.</p> <code>32</code> <code>in_channels</code> <code>int</code> <p>Number of input channels. Default 1 for single field.</p> <code>1</code> <code>base_channels</code> <code>int</code> <p>Base number of channels in first conv layer. Doubles each layer.</p> <code>32</code> <code>architecture</code> <code>str</code> <p>Architecture type: 'standard', 'deep', or 'residual'.</p> <code>'standard'</code> <code>beta</code> <code>float</code> <p>Beta parameter for \u03b2-VAE. Higher values encourage disentanglement.</p> <code>1.0</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from mneme.models.autoencoders import FieldAutoencoder\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Create VAE for 64x64 fields\n&gt;&gt;&gt; vae = FieldAutoencoder(input_shape=(64, 64), latent_dim=16)\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Forward pass\n&gt;&gt;&gt; x = torch.randn(8, 1, 64, 64)  # batch of 8 fields\n&gt;&gt;&gt; output = vae(x)\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Access outputs\n&gt;&gt;&gt; recon = output.reconstruction  # Reconstructed fields\n&gt;&gt;&gt; z = output.z  # Latent representations\n</code></pre> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def __init__(\n    self,\n    input_shape: Tuple[int, int],\n    latent_dim: int = 32,\n    in_channels: int = 1,\n    base_channels: int = 32,\n    architecture: str = \"standard\",\n    beta: float = 1.0,\n) -&gt; None:\n    self.input_shape = input_shape\n    self.latent_dim = latent_dim\n    self.in_channels = in_channels\n    self.base_channels = base_channels\n    self.architecture = architecture\n    self.beta = beta\n\n    if not _TORCH_AVAILABLE:\n        # Lightweight placeholder\n        return\n\n    super().__init__()\n\n    h, w = input_shape\n\n    # Validate input shape\n    if h % 16 != 0 or w % 16 != 0:\n        raise ValueError(\n            f\"Input shape {input_shape} must be divisible by 16. \"\n            f\"Consider padding or resizing to {((h // 16 + 1) * 16, (w // 16 + 1) * 16)}\"\n        )\n\n    # Calculate sizes after encoding\n    self._h_encoded = h // 16\n    self._w_encoded = w // 16\n    self._flat_size = base_channels * 8 * self._h_encoded * self._w_encoded\n\n    # Build encoder\n    self.encoder = self._build_encoder()\n\n    # Latent space projections\n    self.fc_mu = nn.Linear(self._flat_size, latent_dim)\n    self.fc_log_var = nn.Linear(self._flat_size, latent_dim)\n\n    # Decoder input projection\n    self.fc_decode = nn.Linear(latent_dim, self._flat_size)\n\n    # Build decoder\n    self.decoder = self._build_decoder()\n\n    # Final output layer\n    self.output_conv = nn.Conv2d(base_channels, in_channels, 3, 1, 1)\n\n    # Initialize weights\n    self._initialize_weights()\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.encode","title":"encode","text":"<pre><code>encode(x: 'torch.Tensor') -&gt; Tuple['torch.Tensor', 'torch.Tensor']\n</code></pre> <p>Encode input to latent distribution parameters.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input field of shape (batch, channels, height, width).</p> required <p>Returns:</p> Name Type Description <code>mu</code> <code>Tensor</code> <p>Mean of latent distribution, shape (batch, latent_dim).</p> <code>log_var</code> <code>Tensor</code> <p>Log variance of latent distribution, shape (batch, latent_dim).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def encode(self, x: 'torch.Tensor') -&gt; Tuple['torch.Tensor', 'torch.Tensor']:\n    \"\"\"Encode input to latent distribution parameters.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input field of shape (batch, channels, height, width).\n\n    Returns\n    -------\n    mu : torch.Tensor\n        Mean of latent distribution, shape (batch, latent_dim).\n    log_var : torch.Tensor\n        Log variance of latent distribution, shape (batch, latent_dim).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        return None, None\n\n    h = self.encoder(x)\n    mu = self.fc_mu(h)\n    log_var = self.fc_log_var(h)\n    return mu, log_var\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.reparameterize","title":"reparameterize","text":"<pre><code>reparameterize(mu: 'torch.Tensor', log_var: 'torch.Tensor') -&gt; 'torch.Tensor'\n</code></pre> <p>Reparameterization trick for VAE.</p> <p>Parameters:</p> Name Type Description Default <code>mu</code> <code>Tensor</code> <p>Mean of latent distribution.</p> required <code>log_var</code> <code>Tensor</code> <p>Log variance of latent distribution.</p> required <p>Returns:</p> Name Type Description <code>z</code> <code>Tensor</code> <p>Sampled latent vector.</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def reparameterize(self, mu: 'torch.Tensor', log_var: 'torch.Tensor') -&gt; 'torch.Tensor':\n    \"\"\"Reparameterization trick for VAE.\n\n    Parameters\n    ----------\n    mu : torch.Tensor\n        Mean of latent distribution.\n    log_var : torch.Tensor\n        Log variance of latent distribution.\n\n    Returns\n    -------\n    z : torch.Tensor\n        Sampled latent vector.\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        return None\n\n    std = torch.exp(0.5 * log_var)\n    eps = torch.randn_like(std)\n    return mu + eps * std\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.decode","title":"decode","text":"<pre><code>decode(z: 'torch.Tensor') -&gt; 'torch.Tensor'\n</code></pre> <p>Decode latent vector to field reconstruction.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>Tensor</code> <p>Latent vector of shape (batch, latent_dim).</p> required <p>Returns:</p> Name Type Description <code>reconstruction</code> <code>Tensor</code> <p>Reconstructed field of shape (batch, channels, height, width).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def decode(self, z: 'torch.Tensor') -&gt; 'torch.Tensor':\n    \"\"\"Decode latent vector to field reconstruction.\n\n    Parameters\n    ----------\n    z : torch.Tensor\n        Latent vector of shape (batch, latent_dim).\n\n    Returns\n    -------\n    reconstruction : torch.Tensor\n        Reconstructed field of shape (batch, channels, height, width).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        return None\n\n    h = self.fc_decode(z)\n    h = h.view(-1, self.base_channels * 8, self._h_encoded, self._w_encoded)\n    h = self.decoder(h)\n    return self.output_conv(h)\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.forward","title":"forward","text":"<pre><code>forward(x: 'torch.Tensor') -&gt; VAEOutput\n</code></pre> <p>Forward pass through VAE.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input field of shape (batch, channels, height, width).</p> required <p>Returns:</p> Name Type Description <code>output</code> <code>VAEOutput</code> <p>Named tuple with reconstruction, mu, log_var, and z.</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def forward(self, x: 'torch.Tensor') -&gt; VAEOutput:\n    \"\"\"Forward pass through VAE.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input field of shape (batch, channels, height, width).\n\n    Returns\n    -------\n    output : VAEOutput\n        Named tuple with reconstruction, mu, log_var, and z.\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        return VAEOutput(None, None, None, None)\n\n    mu, log_var = self.encode(x)\n    z = self.reparameterize(mu, log_var)\n    reconstruction = self.decode(z)\n\n    return VAEOutput(reconstruction=reconstruction, mu=mu, log_var=log_var, z=z)\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.loss_function","title":"loss_function","text":"<pre><code>loss_function(reconstruction: 'torch.Tensor', original: 'torch.Tensor', mu: 'torch.Tensor', log_var: 'torch.Tensor') -&gt; Dict[str, 'torch.Tensor']\n</code></pre> <p>Compute VAE loss.</p> <p>Parameters:</p> Name Type Description Default <code>reconstruction</code> <code>Tensor</code> <p>Reconstructed field.</p> required <code>original</code> <code>Tensor</code> <p>Original input field.</p> required <code>mu</code> <code>Tensor</code> <p>Latent mean.</p> required <code>log_var</code> <code>Tensor</code> <p>Latent log variance.</p> required <p>Returns:</p> Name Type Description <code>losses</code> <code>Dict[str, Tensor]</code> <p>Dictionary with 'loss', 'recon_loss', and 'kl_loss'.</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def loss_function(\n    self,\n    reconstruction: 'torch.Tensor',\n    original: 'torch.Tensor',\n    mu: 'torch.Tensor',\n    log_var: 'torch.Tensor',\n) -&gt; Dict[str, 'torch.Tensor']:\n    \"\"\"Compute VAE loss.\n\n    Parameters\n    ----------\n    reconstruction : torch.Tensor\n        Reconstructed field.\n    original : torch.Tensor\n        Original input field.\n    mu : torch.Tensor\n        Latent mean.\n    log_var : torch.Tensor\n        Latent log variance.\n\n    Returns\n    -------\n    losses : Dict[str, torch.Tensor]\n        Dictionary with 'loss', 'recon_loss', and 'kl_loss'.\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        return {'loss': 0, 'recon_loss': 0, 'kl_loss': 0}\n\n    # Reconstruction loss (MSE)\n    recon_loss = F.mse_loss(reconstruction, original, reduction='sum') / original.size(0)\n\n    # KL divergence\n    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) / original.size(0)\n\n    # Total loss with beta weighting\n    loss = recon_loss + self.beta * kl_loss\n\n    return {\n        'loss': loss,\n        'recon_loss': recon_loss,\n        'kl_loss': kl_loss,\n    }\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.fit","title":"fit","text":"<pre><code>fit(train_data: Union[ndarray, 'torch.Tensor'], val_data: Optional[Union[ndarray, 'torch.Tensor']] = None, epochs: int = 100, batch_size: int = 32, learning_rate: float = 0.001, device: Optional[str] = None, early_stopping_patience: int = 10, verbose: bool = True) -&gt; TrainingResult\n</code></pre> <p>Train the VAE on field data.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>array - like</code> <p>Training fields of shape (n_samples, height, width) or (n_samples, channels, height, width).</p> required <code>val_data</code> <code>array - like</code> <p>Validation fields.</p> <code>None</code> <code>epochs</code> <code>int</code> <p>Number of training epochs.</p> <code>100</code> <code>batch_size</code> <code>int</code> <p>Batch size for training.</p> <code>32</code> <code>learning_rate</code> <code>float</code> <p>Learning rate for Adam optimizer.</p> <code>0.001</code> <code>device</code> <code>str</code> <p>Device to train on ('cuda' or 'cpu'). Auto-detected if None.</p> <code>None</code> <code>early_stopping_patience</code> <code>int</code> <p>Stop training if validation loss doesn't improve for this many epochs.</p> <code>10</code> <code>verbose</code> <code>bool</code> <p>Whether to print training progress.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>result</code> <code>TrainingResult</code> <p>Training results with loss history.</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def fit(\n    self,\n    train_data: Union[np.ndarray, 'torch.Tensor'],\n    val_data: Optional[Union[np.ndarray, 'torch.Tensor']] = None,\n    epochs: int = 100,\n    batch_size: int = 32,\n    learning_rate: float = 1e-3,\n    device: Optional[str] = None,\n    early_stopping_patience: int = 10,\n    verbose: bool = True,\n) -&gt; TrainingResult:\n    \"\"\"Train the VAE on field data.\n\n    Parameters\n    ----------\n    train_data : array-like\n        Training fields of shape (n_samples, height, width) or\n        (n_samples, channels, height, width).\n    val_data : array-like, optional\n        Validation fields.\n    epochs : int\n        Number of training epochs.\n    batch_size : int\n        Batch size for training.\n    learning_rate : float\n        Learning rate for Adam optimizer.\n    device : str, optional\n        Device to train on ('cuda' or 'cpu'). Auto-detected if None.\n    early_stopping_patience : int\n        Stop training if validation loss doesn't improve for this many epochs.\n    verbose : bool\n        Whether to print training progress.\n\n    Returns\n    -------\n    result : TrainingResult\n        Training results with loss history.\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        raise RuntimeError(\"PyTorch is required for training. Install with: pip install torch\")\n\n    # Setup device\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n    self.to(device)\n\n    # Prepare data\n    train_tensor = self._prepare_data(train_data, device)\n    val_tensor = self._prepare_data(val_data, device) if val_data is not None else None\n\n    # Create data loader\n    train_dataset = torch.utils.data.TensorDataset(train_tensor)\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True\n    )\n\n    # Optimizer\n    optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=5\n    )\n\n    # Training loop\n    train_losses = []\n    val_losses = [] if val_tensor is not None else None\n    best_val_loss = float('inf')\n    best_epoch = 0\n    patience_counter = 0\n\n    for epoch in range(epochs):\n        # Training\n        self.train()\n        epoch_loss = 0.0\n\n        for (batch,) in train_loader:\n            optimizer.zero_grad()\n            output = self(batch)\n            losses = self.loss_function(output.reconstruction, batch, output.mu, output.log_var)\n            losses['loss'].backward()\n            optimizer.step()\n            epoch_loss += losses['loss'].item() * batch.size(0)\n\n        epoch_loss /= len(train_tensor)\n        train_losses.append(epoch_loss)\n\n        # Validation\n        if val_tensor is not None:\n            self.eval()\n            with torch.no_grad():\n                output = self(val_tensor)\n                val_loss_dict = self.loss_function(\n                    output.reconstruction, val_tensor, output.mu, output.log_var\n                )\n                val_loss = val_loss_dict['loss'].item()\n                val_losses.append(val_loss)\n\n            scheduler.step(val_loss)\n\n            if val_loss &lt; best_val_loss:\n                best_val_loss = val_loss\n                best_epoch = epoch\n                patience_counter = 0\n            else:\n                patience_counter += 1\n\n            if patience_counter &gt;= early_stopping_patience:\n                if verbose:\n                    print(f\"Early stopping at epoch {epoch}\")\n                break\n\n            if verbose and (epoch + 1) % 10 == 0:\n                print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n        else:\n            if verbose and (epoch + 1) % 10 == 0:\n                print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {epoch_loss:.4f}\")\n\n    return TrainingResult(\n        train_losses=train_losses,\n        val_losses=val_losses,\n        best_epoch=best_epoch,\n        final_loss=train_losses[-1],\n    )\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.encode_fields","title":"encode_fields","text":"<pre><code>encode_fields(fields: Union[ndarray, 'torch.Tensor']) -&gt; np.ndarray\n</code></pre> <p>Encode fields to latent space.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>array - like</code> <p>Fields to encode, shape (n_samples, height, width).</p> required <p>Returns:</p> Name Type Description <code>latent</code> <code>ndarray</code> <p>Latent representations, shape (n_samples, latent_dim).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def encode_fields(self, fields: Union[np.ndarray, 'torch.Tensor']) -&gt; np.ndarray:\n    \"\"\"Encode fields to latent space.\n\n    Parameters\n    ----------\n    fields : array-like\n        Fields to encode, shape (n_samples, height, width).\n\n    Returns\n    -------\n    latent : np.ndarray\n        Latent representations, shape (n_samples, latent_dim).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        raise RuntimeError(\"PyTorch is required\")\n\n    self.eval()\n    device = next(self.parameters()).device\n\n    tensor = self._prepare_data(fields, str(device))\n\n    with torch.no_grad():\n        mu, _ = self.encode(tensor)\n\n    return mu.cpu().numpy()\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.decode_latent","title":"decode_latent","text":"<pre><code>decode_latent(z: Union[ndarray, 'torch.Tensor']) -&gt; np.ndarray\n</code></pre> <p>Decode latent vectors to fields.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>array - like</code> <p>Latent vectors, shape (n_samples, latent_dim).</p> required <p>Returns:</p> Name Type Description <code>fields</code> <code>ndarray</code> <p>Reconstructed fields, shape (n_samples, height, width).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def decode_latent(self, z: Union[np.ndarray, 'torch.Tensor']) -&gt; np.ndarray:\n    \"\"\"Decode latent vectors to fields.\n\n    Parameters\n    ----------\n    z : array-like\n        Latent vectors, shape (n_samples, latent_dim).\n\n    Returns\n    -------\n    fields : np.ndarray\n        Reconstructed fields, shape (n_samples, height, width).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        raise RuntimeError(\"PyTorch is required\")\n\n    self.eval()\n    device = next(self.parameters()).device\n\n    if isinstance(z, np.ndarray):\n        z = torch.from_numpy(z).float()\n    z = z.to(device)\n\n    with torch.no_grad():\n        recon = self.decode(z)\n\n    return recon.squeeze(1).cpu().numpy()\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(fields: Union[ndarray, 'torch.Tensor']) -&gt; np.ndarray\n</code></pre> <p>Reconstruct fields through the VAE.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>array - like</code> <p>Input fields, shape (n_samples, height, width).</p> required <p>Returns:</p> Name Type Description <code>reconstructions</code> <code>ndarray</code> <p>Reconstructed fields, shape (n_samples, height, width).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def reconstruct(self, fields: Union[np.ndarray, 'torch.Tensor']) -&gt; np.ndarray:\n    \"\"\"Reconstruct fields through the VAE.\n\n    Parameters\n    ----------\n    fields : array-like\n        Input fields, shape (n_samples, height, width).\n\n    Returns\n    -------\n    reconstructions : np.ndarray\n        Reconstructed fields, shape (n_samples, height, width).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        raise RuntimeError(\"PyTorch is required\")\n\n    self.eval()\n    device = next(self.parameters()).device\n\n    tensor = self._prepare_data(fields, str(device))\n\n    with torch.no_grad():\n        output = self(tensor)\n\n    return output.reconstruction.squeeze(1).cpu().numpy()\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.sample","title":"sample","text":"<pre><code>sample(n_samples: int = 1) -&gt; np.ndarray\n</code></pre> <p>Generate random field samples from the prior.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>Number of samples to generate.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>samples</code> <code>ndarray</code> <p>Generated fields, shape (n_samples, height, width).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def sample(self, n_samples: int = 1) -&gt; np.ndarray:\n    \"\"\"Generate random field samples from the prior.\n\n    Parameters\n    ----------\n    n_samples : int\n        Number of samples to generate.\n\n    Returns\n    -------\n    samples : np.ndarray\n        Generated fields, shape (n_samples, height, width).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        raise RuntimeError(\"PyTorch is required\")\n\n    self.eval()\n    device = next(self.parameters()).device\n\n    z = torch.randn(n_samples, self.latent_dim).to(device)\n\n    with torch.no_grad():\n        samples = self.decode(z)\n\n    return samples.squeeze(1).cpu().numpy()\n</code></pre>"},{"location":"api/models/autoencoders/#mneme.models.autoencoders.FieldAutoencoder.interpolate","title":"interpolate","text":"<pre><code>interpolate(field1: ndarray, field2: ndarray, n_steps: int = 10) -&gt; np.ndarray\n</code></pre> <p>Interpolate between two fields in latent space.</p> <p>Parameters:</p> Name Type Description Default <code>field1</code> <code>ndarray</code> <p>First field, shape (height, width).</p> required <code>field2</code> <code>ndarray</code> <p>Second field, shape (height, width).</p> required <code>n_steps</code> <code>int</code> <p>Number of interpolation steps.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>interpolation</code> <code>ndarray</code> <p>Interpolated fields, shape (n_steps, height, width).</p> Source code in <code>src/mneme/models/autoencoders.py</code> <pre><code>def interpolate(\n    self,\n    field1: np.ndarray,\n    field2: np.ndarray,\n    n_steps: int = 10,\n) -&gt; np.ndarray:\n    \"\"\"Interpolate between two fields in latent space.\n\n    Parameters\n    ----------\n    field1 : np.ndarray\n        First field, shape (height, width).\n    field2 : np.ndarray\n        Second field, shape (height, width).\n    n_steps : int\n        Number of interpolation steps.\n\n    Returns\n    -------\n    interpolation : np.ndarray\n        Interpolated fields, shape (n_steps, height, width).\n    \"\"\"\n    if not _TORCH_AVAILABLE:\n        raise RuntimeError(\"PyTorch is required\")\n\n    # Encode both fields\n    z1 = self.encode_fields(field1[np.newaxis, ...])[0]\n    z2 = self.encode_fields(field2[np.newaxis, ...])[0]\n\n    # Linear interpolation in latent space\n    alphas = np.linspace(0, 1, n_steps)\n    z_interp = np.array([z1 * (1 - a) + z2 * a for a in alphas])\n\n    # Decode interpolated latents\n    return self.decode_latent(z_interp)\n</code></pre>"},{"location":"api/models/autoencoders/#data-classes","title":"Data Classes","text":""},{"location":"api/models/autoencoders/#mneme.models.autoencoders.TrainingResult","title":"TrainingResult  <code>dataclass</code>","text":"<pre><code>TrainingResult(train_losses: List[float], val_losses: Optional[List[float]], best_epoch: int, final_loss: float)\n</code></pre> <p>Result from VAE training.</p>"},{"location":"api/models/symbolic/","title":"Symbolic Regression","text":"<p>PySR integration for discovering governing equations from field dynamics.</p>"},{"location":"api/models/symbolic/#convenience-function","title":"Convenience Function","text":""},{"location":"api/models/symbolic/#mneme.models.symbolic.discover_field_dynamics","title":"discover_field_dynamics","text":"<pre><code>discover_field_dynamics(field_sequence: ndarray, dt: float = 1.0, spatial_features: bool = True, niterations: int = 100, **kwargs: Any) -&gt; Dict[str, Any]\n</code></pre> <p>Discover symbolic equations governing field evolution.</p> <p>This is a convenience function that extracts relevant features from a field time series and runs symbolic regression to find governing equations.</p> <p>Parameters:</p> Name Type Description Default <code>field_sequence</code> <code>ndarray</code> <p>Field evolution with shape (timesteps, height, width).</p> required <code>dt</code> <code>float</code> <p>Time step between frames.</p> <code>1.0</code> <code>spatial_features</code> <code>bool</code> <p>Whether to include spatial derivative features.</p> <code>True</code> <code>niterations</code> <code>int</code> <p>Number of PySR iterations.</p> <code>100</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to SymbolicRegressor.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Dict[str, Any]</code> <p>Dictionary containing: - 'equations': List of discovered equations - 'best_equation': Best equation string - 'regressor': Fitted SymbolicRegressor - 'features_used': Names of input features - 'r2_score': R\u00b2 score on training data</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def discover_field_dynamics(\n    field_sequence: np.ndarray,\n    dt: float = 1.0,\n    spatial_features: bool = True,\n    niterations: int = 100,\n    **kwargs: Any,\n) -&gt; Dict[str, Any]:\n    \"\"\"Discover symbolic equations governing field evolution.\n\n    This is a convenience function that extracts relevant features from\n    a field time series and runs symbolic regression to find governing equations.\n\n    Parameters\n    ----------\n    field_sequence : np.ndarray\n        Field evolution with shape (timesteps, height, width).\n    dt : float\n        Time step between frames.\n    spatial_features : bool\n        Whether to include spatial derivative features.\n    niterations : int\n        Number of PySR iterations.\n    **kwargs\n        Additional arguments passed to SymbolicRegressor.\n\n    Returns\n    -------\n    result : Dict[str, Any]\n        Dictionary containing:\n        - 'equations': List of discovered equations\n        - 'best_equation': Best equation string\n        - 'regressor': Fitted SymbolicRegressor\n        - 'features_used': Names of input features\n        - 'r2_score': R\u00b2 score on training data\n    \"\"\"\n    if field_sequence.ndim != 3:\n        raise ValueError(\"field_sequence must be 3D (timesteps, height, width)\")\n\n    T, H, W = field_sequence.shape\n\n    # Extract features and targets\n    features = []\n    targets = []\n    feature_names = ['u']  # Field value\n\n    for t in range(T - 1):\n        current = field_sequence[t]\n        next_frame = field_sequence[t + 1]\n\n        # Target: time derivative (du/dt)\n        du_dt = (next_frame - current) / dt\n\n        # Flatten for sampling (subsample for speed)\n        step = max(1, min(H, W) // 32)\n        for i in range(0, H, step):\n            for j in range(0, W, step):\n                feat = [current[i, j]]  # u\n\n                if spatial_features:\n                    # Add Laplacian (\u2207\u00b2u)\n                    if 0 &lt; i &lt; H-1 and 0 &lt; j &lt; W-1:\n                        laplacian = (\n                            current[i+1, j] + current[i-1, j] +\n                            current[i, j+1] + current[i, j-1] -\n                            4 * current[i, j]\n                        )\n                        feat.append(laplacian)\n\n                        # Add gradients\n                        du_dx = (current[i, j+1] - current[i, j-1]) / 2\n                        du_dy = (current[i+1, j] - current[i-1, j]) / 2\n                        feat.append(du_dx)\n                        feat.append(du_dy)\n                    else:\n                        feat.extend([0, 0, 0])\n\n                features.append(feat)\n                targets.append(du_dt[i, j])\n\n    if spatial_features:\n        feature_names.extend(['laplacian_u', 'du_dx', 'du_dy'])\n\n    X = np.array(features)\n    y = np.array(targets)\n\n    # Fit symbolic regressor\n    sr = SymbolicRegressor(niterations=niterations, **kwargs)\n    sr.fit(X, y, variable_names=feature_names)\n\n    return {\n        'equations': sr.get_equations(),\n        'best_equation': sr.get_best_equation(),\n        'regressor': sr,\n        'features_used': feature_names,\n        'r2_score': sr.score(X, y),\n    }\n</code></pre>"},{"location":"api/models/symbolic/#regressor","title":"Regressor","text":""},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor","title":"SymbolicRegressor","text":"<pre><code>SymbolicRegressor(operators: Optional[List[str]] = None, complexity_penalty: float = 0.001, max_complexity: int = 30, populations: int = 15, niterations: int = 100, binary_operators: Optional[List[str]] = None, unary_operators: Optional[List[str]] = None, extra_sympy_mappings: Optional[Dict[str, Any]] = None, loss: str = 'L2DistLoss()', denoise: bool = False, select_k_features: Optional[int] = None, progress: bool = True, random_state: Optional[int] = None)\n</code></pre> <p>Discover symbolic equations from field dynamics.</p> <p>This class wraps PySR to find interpretable mathematical equations that describe how field values evolve over time or relate to each other.</p> <p>When PySR is not installed, it operates in placeholder mode and returns simple fallback equations.</p> <p>Parameters:</p> Name Type Description Default <code>operators</code> <code>List[str]</code> <p>Mathematical operators to use. Default includes basic arithmetic and trigonometric functions.</p> <code>None</code> <code>complexity_penalty</code> <code>float</code> <p>Penalty for equation complexity (higher = simpler equations). Maps to PySR's parsimony parameter.</p> <code>0.001</code> <code>max_complexity</code> <code>int</code> <p>Maximum allowed complexity for equations.</p> <code>30</code> <code>populations</code> <code>int</code> <p>Number of populations for genetic algorithm.</p> <code>15</code> <code>niterations</code> <code>int</code> <p>Number of iterations for symbolic search.</p> <code>100</code> <code>binary_operators</code> <code>List[str]</code> <p>Binary operators (e.g., +, -, *, /). If None, derived from operators.</p> <code>None</code> <code>unary_operators</code> <code>List[str]</code> <p>Unary operators (e.g., sin, cos, exp). If None, derived from operators.</p> <code>None</code> <code>extra_sympy_mappings</code> <code>Dict[str, Any]</code> <p>Additional SymPy function mappings.</p> <code>None</code> <code>loss</code> <code>str</code> <p>Loss function for PySR. Default is 'loss(prediction, target) = (prediction - target)^2'.</p> <code>'L2DistLoss()'</code> <code>denoise</code> <code>bool</code> <p>Whether to denoise data before fitting.</p> <code>False</code> <code>select_k_features</code> <code>int</code> <p>If set, use only the k most important features.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>Whether to show progress during fitting.</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from mneme.models.symbolic import SymbolicRegressor\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Generate sample dynamics data\n&gt;&gt;&gt; t = np.linspace(0, 10, 100)\n&gt;&gt;&gt; X = np.column_stack([t, np.sin(t)])\n&gt;&gt;&gt; y = 2.0 * np.sin(t) + 0.5 * t  # True relationship\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Fit symbolic regressor\n&gt;&gt;&gt; sr = SymbolicRegressor(niterations=40)\n&gt;&gt;&gt; sr.fit(X, y, variable_names=['t', 'sin_t'])\n&gt;&gt;&gt; \n&gt;&gt;&gt; # Get discovered equations\n&gt;&gt;&gt; equations = sr.get_equations()\n&gt;&gt;&gt; print(equations[0])  # Best equation\n</code></pre> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def __init__(\n    self,\n    operators: Optional[List[str]] = None,\n    complexity_penalty: float = 0.001,\n    max_complexity: int = 30,\n    populations: int = 15,\n    niterations: int = 100,\n    binary_operators: Optional[List[str]] = None,\n    unary_operators: Optional[List[str]] = None,\n    extra_sympy_mappings: Optional[Dict[str, Any]] = None,\n    loss: str = \"L2DistLoss()\",\n    denoise: bool = False,\n    select_k_features: Optional[int] = None,\n    progress: bool = True,\n    random_state: Optional[int] = None,\n) -&gt; None:\n    self.operators = operators\n    self.complexity_penalty = complexity_penalty\n    self.max_complexity = max_complexity\n    self.populations = populations\n    self.niterations = niterations\n    self.loss = loss\n    self.denoise = denoise\n    self.select_k_features = select_k_features\n    self.progress = progress\n    self.random_state = random_state\n    self.extra_sympy_mappings = extra_sympy_mappings or {}\n\n    # Parse operators into binary and unary\n    if binary_operators is not None:\n        self.binary_operators = binary_operators\n    elif operators is not None:\n        self.binary_operators = [op for op in operators if op in ['+', '-', '*', '/', 'pow', '^', '**']]\n    else:\n        self.binary_operators = self.DEFAULT_BINARY_OPS\n\n    if unary_operators is not None:\n        self.unary_operators = unary_operators\n    elif operators is not None:\n        self.unary_operators = [op for op in operators if op in ['sin', 'cos', 'tan', 'exp', 'log', 'sqrt', 'abs', 'neg', 'square', 'cube']]\n    else:\n        self.unary_operators = self.DEFAULT_UNARY_OPS\n\n    # Internal state\n    self._model: Optional[Any] = None\n    self._equations: List[str] = []\n    self._equation_scores: List[float] = []\n    self._variable_names: Optional[List[str]] = None\n    self._is_fitted: bool = False\n    self._using_pysr: bool = False\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.is_available","title":"is_available  <code>property</code>","text":"<pre><code>is_available: bool\n</code></pre> <p>Check if PySR is available.</p>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.fit","title":"fit","text":"<pre><code>fit(X: Union[ndarray, List], y: Union[ndarray, List], variable_names: Optional[List[str]] = None, weights: Optional[ndarray] = None) -&gt; 'SymbolicRegressor'\n</code></pre> <p>Fit symbolic regressor to discover equations.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Input features (e.g., spatial coordinates, time, field values).</p> required <code>y</code> <code>array-like of shape (n_samples,)</code> <p>Target values to predict (e.g., field evolution, gradients).</p> required <code>variable_names</code> <code>List[str]</code> <p>Names for input variables. If None, uses x0, x1, etc.</p> <code>None</code> <code>weights</code> <code>ndarray</code> <p>Sample weights for weighted regression.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>SymbolicRegressor</code> <p>Fitted regressor.</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def fit(\n    self,\n    X: Union[np.ndarray, List],\n    y: Union[np.ndarray, List],\n    variable_names: Optional[List[str]] = None,\n    weights: Optional[np.ndarray] = None,\n) -&gt; 'SymbolicRegressor':\n    \"\"\"Fit symbolic regressor to discover equations.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Input features (e.g., spatial coordinates, time, field values).\n    y : array-like of shape (n_samples,)\n        Target values to predict (e.g., field evolution, gradients).\n    variable_names : List[str], optional\n        Names for input variables. If None, uses x0, x1, etc.\n    weights : np.ndarray, optional\n        Sample weights for weighted regression.\n\n    Returns\n    -------\n    self : SymbolicRegressor\n        Fitted regressor.\n    \"\"\"\n    X = np.asarray(X)\n    y = np.asarray(y)\n\n    if X.ndim == 1:\n        X = X.reshape(-1, 1)\n\n    n_features = X.shape[1]\n    self._variable_names = variable_names or [f\"x{i}\" for i in range(n_features)]\n\n    if _PYSR_AVAILABLE and _PySRRegressor is not None:\n        self._fit_pysr(X, y, weights)\n        self._using_pysr = True\n    else:\n        self._fit_fallback(X, y)\n        self._using_pysr = False\n        warnings.warn(\n            \"PySR not available. Using fallback placeholder. \"\n            \"Install with: pip install pysr\",\n            UserWarning\n        )\n\n    self._is_fitted = True\n    return self\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.predict","title":"predict","text":"<pre><code>predict(X: Union[ndarray, List]) -&gt; np.ndarray\n</code></pre> <p>Predict using the best discovered equation.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Input features.</p> required <p>Returns:</p> Name Type Description <code>y_pred</code> <code>np.ndarray of shape (n_samples,)</code> <p>Predictions.</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def predict(self, X: Union[np.ndarray, List]) -&gt; np.ndarray:\n    \"\"\"Predict using the best discovered equation.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Input features.\n\n    Returns\n    -------\n    y_pred : np.ndarray of shape (n_samples,)\n        Predictions.\n    \"\"\"\n    if not self._is_fitted:\n        raise RuntimeError(\"SymbolicRegressor must be fitted before prediction\")\n\n    X = np.asarray(X)\n    if X.ndim == 1:\n        X = X.reshape(-1, 1)\n\n    if self._model is not None:\n        try:\n            return self._model.predict(X)\n        except Exception as e:\n            warnings.warn(f\"Prediction failed: {e}\")\n            return np.zeros(len(X))\n\n    return np.zeros(len(X))\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.get_equations","title":"get_equations","text":"<pre><code>get_equations(n_best: Optional[int] = None) -&gt; List[str]\n</code></pre> <p>Get discovered equations.</p> <p>Parameters:</p> Name Type Description Default <code>n_best</code> <code>int</code> <p>Return only the n best equations. If None, returns all.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>equations</code> <code>List[str]</code> <p>List of equation strings, sorted by score (best first).</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def get_equations(self, n_best: Optional[int] = None) -&gt; List[str]:\n    \"\"\"Get discovered equations.\n\n    Parameters\n    ----------\n    n_best : int, optional\n        Return only the n best equations. If None, returns all.\n\n    Returns\n    -------\n    equations : List[str]\n        List of equation strings, sorted by score (best first).\n    \"\"\"\n    if n_best is None:\n        return list(self._equations)\n    return list(self._equations[:n_best])\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.get_best_equation","title":"get_best_equation","text":"<pre><code>get_best_equation() -&gt; str\n</code></pre> <p>Get the single best equation.</p> <p>Returns:</p> Name Type Description <code>equation</code> <code>str</code> <p>Best equation string.</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def get_best_equation(self) -&gt; str:\n    \"\"\"Get the single best equation.\n\n    Returns\n    -------\n    equation : str\n        Best equation string.\n    \"\"\"\n    if self._equations:\n        return self._equations[0]\n    return \"&lt;no_equation_found&gt;\"\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.get_equation_scores","title":"get_equation_scores","text":"<pre><code>get_equation_scores() -&gt; List[float]\n</code></pre> <p>Get scores for all equations.</p> <p>Returns:</p> Name Type Description <code>scores</code> <code>List[float]</code> <p>Loss/score values for each equation (lower is better).</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def get_equation_scores(self) -&gt; List[float]:\n    \"\"\"Get scores for all equations.\n\n    Returns\n    -------\n    scores : List[float]\n        Loss/score values for each equation (lower is better).\n    \"\"\"\n    return list(self._equation_scores)\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.get_sympy_expression","title":"get_sympy_expression","text":"<pre><code>get_sympy_expression(equation_index: int = 0) -&gt; Any\n</code></pre> <p>Get SymPy expression for an equation.</p> <p>Parameters:</p> Name Type Description Default <code>equation_index</code> <code>int</code> <p>Index of equation to get (0 = best).</p> <code>0</code> <p>Returns:</p> Name Type Description <code>expr</code> <code>Expr or None</code> <p>SymPy expression, or None if not available.</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def get_sympy_expression(self, equation_index: int = 0) -&gt; Any:\n    \"\"\"Get SymPy expression for an equation.\n\n    Parameters\n    ----------\n    equation_index : int\n        Index of equation to get (0 = best).\n\n    Returns\n    -------\n    expr : sympy.Expr or None\n        SymPy expression, or None if not available.\n    \"\"\"\n    if not self._using_pysr or self._model is None:\n        try:\n            import sympy\n            return sympy.sympify(self._equations[equation_index])\n        except Exception:\n            return None\n\n    try:\n        return self._model.sympy(equation_index)\n    except Exception:\n        return None\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.latex","title":"latex","text":"<pre><code>latex(equation_index: int = 0) -&gt; str\n</code></pre> <p>Get LaTeX representation of an equation.</p> <p>Parameters:</p> Name Type Description Default <code>equation_index</code> <code>int</code> <p>Index of equation to render (0 = best).</p> <code>0</code> <p>Returns:</p> Name Type Description <code>latex_str</code> <code>str</code> <p>LaTeX string for the equation.</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def latex(self, equation_index: int = 0) -&gt; str:\n    \"\"\"Get LaTeX representation of an equation.\n\n    Parameters\n    ----------\n    equation_index : int\n        Index of equation to render (0 = best).\n\n    Returns\n    -------\n    latex_str : str\n        LaTeX string for the equation.\n    \"\"\"\n    expr = self.get_sympy_expression(equation_index)\n    if expr is not None:\n        try:\n            import sympy\n            return sympy.latex(expr)\n        except Exception:\n            pass\n\n    # Fallback: return raw equation\n    if equation_index &lt; len(self._equations):\n        return self._equations[equation_index]\n    return \"\"\n</code></pre>"},{"location":"api/models/symbolic/#mneme.models.symbolic.SymbolicRegressor.score","title":"score","text":"<pre><code>score(X: Union[ndarray, List], y: Union[ndarray, List]) -&gt; float\n</code></pre> <p>Compute R\u00b2 score on test data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array - like</code> <p>Test features.</p> required <code>y</code> <code>array - like</code> <p>True target values.</p> required <p>Returns:</p> Name Type Description <code>r2</code> <code>float</code> <p>R\u00b2 score (1.0 = perfect, 0.0 = baseline).</p> Source code in <code>src/mneme/models/symbolic.py</code> <pre><code>def score(self, X: Union[np.ndarray, List], y: Union[np.ndarray, List]) -&gt; float:\n    \"\"\"Compute R\u00b2 score on test data.\n\n    Parameters\n    ----------\n    X : array-like\n        Test features.\n    y : array-like\n        True target values.\n\n    Returns\n    -------\n    r2 : float\n        R\u00b2 score (1.0 = perfect, 0.0 = baseline).\n    \"\"\"\n    X = np.asarray(X)\n    y = np.asarray(y)\n\n    y_pred = self.predict(X)\n\n    ss_res = np.sum((y - y_pred) ** 2)\n    ss_tot = np.sum((y - np.mean(y)) ** 2)\n\n    if ss_tot == 0:\n        return 1.0 if ss_res == 0 else 0.0\n\n    return 1.0 - (ss_res / ss_tot)\n</code></pre>"},{"location":"course/","title":"Mneme Course: From First Principles to Mastery","text":"<p>Welcome to the comprehensive, hands-on course for Mneme: a system for detecting field-like memory structures in biological systems. This program takes you from foundational theory to confident, practitioner-level use of Mneme\u2019s CLI and Python APIs\u2014with exercises, projects, and optional advanced modules.</p> <ul> <li>Audience: Scientists, ML/DS engineers, biophysicists, and curious generalists</li> <li>Prerequisites: Python fundamentals; basic linear algebra and probability; comfort with NumPy; curiosity about fields and topology</li> <li>Compute: CPU is sufficient for the MVP; GPU optional (PyTorch, heavy models)</li> <li>Duration: ~12\u201318 hours total (self-paced)</li> </ul>"},{"location":"course/#learning-paths","title":"Learning paths","text":"<ul> <li>Foundations (Modules 1\u20134): First principles, environment, CLI, pipeline anatomy</li> <li>Practitioner (Modules 5\u20139): Reconstruction, topology, attractors, visualization, experiments</li> <li>Advanced (Modules 10\u201311): Performance/monitoring; optional symbolic regression (PySR)</li> <li>Capstone: End-to-end experiment with reporting</li> </ul>"},{"location":"course/#syllabus","title":"Syllabus","text":"<ol> <li>First Principles: Fields, Topology, Attractors</li> <li>Environment Setup and Sanity Checks</li> <li>CLI Quickstart: Generate \u2192 Analyze \u2192 Visualize</li> <li>Pipeline Anatomy and Configuration</li> <li>Field Reconstruction (IFT and GP)</li> <li>Topology (Cubical, Rips, Alpha) and Features</li> <li>Attractor Detection (Recurrence, Lyapunov, Clustering)</li> <li>Visualization and Reporting</li> <li>Designing Experiments and Reproducibility</li> <li>Performance and Monitoring (MVP Tools)</li> <li>Optional: Symbolic Regression with PySR</li> </ol>"},{"location":"course/#how-to-use-this-course","title":"How to use this course","text":"<ul> <li>Each module includes learning objectives, short readings, and exercises</li> <li>Exercises are designed to run in minutes on CPU</li> <li>Solutions are outlined inline after exercises (concealed by headings)</li> </ul>"},{"location":"course/#reference-docs","title":"Reference docs","text":"<ul> <li>Core project docs: Project Structure, Development Setup, API Design, Data Pipeline</li> <li>Run Logs: Each module will gain a short \u201cRun log\u201d section as we execute the exercises end-to-end, noting successes and any failures with fixes.</li> <li>Source: <code>src/mneme/</code> (see <code>analysis/</code>, <code>core/</code>, <code>data/</code>, <code>utils/</code>)</li> </ul> <p>Happy exploring!</p>"},{"location":"course/01_first_principles/","title":"Module 1: First Principles \u2014 Fields, Topology, Attractors","text":"<ul> <li>Objectives</li> <li>Understand why biological memory can be field-like and distributed</li> <li>Grasp core notions: Information Field Theory (IFT), persistent homology, attractors</li> <li>Map concepts to Mneme\u2019s MVP: reconstruction \u2192 topology \u2192 attractors</li> <li>Prereqs: None</li> <li>Time: 60\u201390 minutes</li> </ul>"},{"location":"course/01_first_principles/#11-why-fields-for-biological-memory","title":"1.1 Why fields for biological memory?","text":"<p>Biological tissues exhibit spatially distributed bioelectric patterns. Hypothesis: some memory is encoded as stable, recoverable attractors in such fields, beyond sequence-only models.</p> <p>Key ideas: - A field f(x, y, t) over tissue; memory as stable structures/trajectories - Perturbations relax back to morphology via attractors</p>"},{"location":"course/01_first_principles/#12-information-field-theory-ift","title":"1.2 Information Field Theory (IFT)","text":"<p>IFT reconstructs continuous fields from sparse/noisy observations with priors on smoothness/correlation. In Mneme: - Reconstructors: IFT, Gaussian Process (GP), Neural Field (placeholder) - Goal: obtain a continuous field suitable for topology + further analysis</p>"},{"location":"course/01_first_principles/#13-topological-data-analysis-tda","title":"1.3 Topological Data Analysis (TDA)","text":"<p>Persistent homology summarizes shape across scales. In Mneme: - Cubical complex for 2D fields (default) - Rips/Alpha for point-clouds extracted from fields (via adapters) - Outputs: diagrams, features, derived images/landscapes</p>"},{"location":"course/01_first_principles/#14-attractors-in-dynamical-systems","title":"1.4 Attractors in dynamical systems","text":"<p>Attractors are sets toward which trajectories evolve (fixed point, limit cycle, strange). Mneme MVP: - Recurrence-based detection (default) - Basic Lyapunov and clustering modes (experimental MVP)</p>"},{"location":"course/01_first_principles/#15-how-mneme-ties-these-together","title":"1.5 How Mneme ties these together","text":"<p>1) Preprocess + reconstruct continuous fields 2) Compute persistence features (structure across thresholds) 3) Detect attractors from dynamical trajectories when temporal data exist 4) Visualize + report</p>"},{"location":"course/01_first_principles/#exercises","title":"Exercises","text":"<p>1) Concept check (short answers) - Define \u201cfield-like memory\u201d in one sentence - What does persistent homology measure, at a high level? - Name two attractor types and one biological reason they matter</p> <p>2) Mini-derivation (paper &amp; pencil) - Suppose field noise is i.i.d. Gaussian. What prior/likelihood choices make GP inference natural? How does correlation length shape reconstructions?</p> <p>3) Sanity coding (optional, Python) - Build a tiny 2D array with two bright blobs. Threshold at multiple values and count connected components by hand; sketch how births/deaths would look.</p> <p>Solutions (outline) - Field-like memory: information stored as stable spatial patterns whose dynamics encode state - PH measures the birth/death of k-dimensional features across thresholds; robustness of structure - Fixed point: steady patterns; limit cycles: oscillations; important for regenerative stability - GP prior with RBF kernel + Gaussian likelihood; longer correlation length \u2192 smoother reconstructions; smaller \u2192 finer detail</p>"},{"location":"course/02_environment_setup/","title":"Module 2: Environment Setup and Sanity Checks","text":"<ul> <li>Objectives</li> <li>Install/activate Mneme in a virtual environment</li> <li>Verify core and optional dependencies</li> <li>Run smoke tests on your machine</li> <li>Time: 30\u201345 minutes</li> </ul>"},{"location":"course/02_environment_setup/#21-install-and-activate","title":"2.1 Install and activate","text":"<pre><code># From repo root\nsource venv/bin/activate\npip install -e .\n# Optional dev tools\npip install -r requirements-dev.txt\n</code></pre>"},{"location":"course/02_environment_setup/#22-verify-toolchain","title":"2.2 Verify toolchain","text":"<p><pre><code>mneme info\n</code></pre> Check: - Python, NumPy, CUDA availability - Optional deps: <code>gudhi</code>, <code>pysr</code>, <code>h5py</code>, <code>scipy</code>, <code>sklearn</code> - Default topology backend (from config if provided)</p>"},{"location":"course/02_environment_setup/#23-smoke-tests","title":"2.3 Smoke tests","text":"<pre><code>python -c \"import mneme; print('OK')\"\npytest -q  # optional dev\n</code></pre>"},{"location":"course/02_environment_setup/#24-gpu-optionality","title":"2.4 GPU optionality","text":"<ul> <li>GPU not required for MVP. Neural-field reconstructor is a placeholder; keep CPU for now.</li> </ul>"},{"location":"course/02_environment_setup/#exercises","title":"Exercises","text":"<p>1) Change verbosity: run <code>mneme info -v</code> and note any differences in logging 2) Optional: install GUDHI if missing; confirm cubical backend will be used 3) Optional: install PySR; run <code>mneme info</code> and confirm Julia availability status</p> <p>Solutions (outline) - <code>mneme info</code> reports optional deps and default backend; with <code>-v</code>, console logging is verbose - With GUDHI installed, cubical/Rips/Alpha backends are available - PySR shows \u2713; Julia may install lazily on first use</p>"},{"location":"course/03_cli_quickstart/","title":"Module 3: CLI Quickstart \u2014 Generate \u2192 Analyze \u2192 Visualize","text":"<ul> <li>Objectives</li> <li>Use Mneme CLI to generate synthetic data and run the bioelectric pipeline</li> <li>Explore topology backends and attractor options</li> <li>Time: 45\u201360 minutes</li> </ul>"},{"location":"course/03_cli_quickstart/#31-generate-synthetic-data","title":"3.1 Generate synthetic data","text":"<pre><code>mneme generate -o data/synthetic/quickstart.npz -t bioelectric -s 64,64 --timesteps 10 --seed 7\n</code></pre>"},{"location":"course/03_cli_quickstart/#32-analyze-bioelectric-defaults","title":"3.2 Analyze (bioelectric defaults)","text":"<p><pre><code>mneme analyze data/synthetic/quickstart.npz \\\n  --pipeline bioelectric \\\n  --topology-backend cubical \\\n  -o results_cli\n</code></pre> Expected: <code>results_cli/analysis_results.hdf5</code></p>"},{"location":"course/03_cli_quickstart/#33-visualize-dashboard","title":"3.3 Visualize dashboard","text":"<p><pre><code>mneme visualize results_cli/analysis_results.hdf5 -o plots -f png\n</code></pre> Expected: <code>plots/dashboard.png</code> with field, topology, and any attractor summaries.</p> <p>If you prefer Python, you can also drive visualization programmatically:</p> <pre><code>from mneme.utils.io import load_results\nfrom mneme.analysis.visualization import FieldVisualizer\nfrom mneme.types import AnalysisResult, Field\n\nar = load_results('results_cli/analysis_results.hdf5')  # returns AnalysisResult\nFieldVisualizer().create_analysis_dashboard(ar)\n</code></pre>"},{"location":"course/03_cli_quickstart/#34-backend-and-attractor-variations","title":"3.4 Backend and attractor variations","text":"<ul> <li>Rips (point-cloud): <pre><code>mneme analyze data/synthetic/quickstart.npz \\\n  --pipeline bioelectric \\\n  --topology-backend rips \\\n  -o results_cli_rips\n</code></pre></li> <li>Disable attractors: <pre><code>mneme analyze data/synthetic/quickstart.npz --attractor-method none -o results_noattr\n</code></pre></li> </ul>"},{"location":"course/03_cli_quickstart/#exercises","title":"Exercises","text":"<p>1) Compare cubical vs rips outputs (feature vector length; diagram counts) 2) Increase <code>--attractor-threshold</code> and note changes in detected attractors 3) Try <code>--attractor-method clustering</code> with <code>--attractor-min-samples 20</code></p> <p>Solutions (outline) - Cubical operates directly on grids; Rips requires point-cloud conversion and may produce different diagram sparsity - Higher thresholds reduce recurrence connections \u2192 fewer attractors - Clustering groups dense regions; raising min_samples filters small basins</p>"},{"location":"course/04_pipeline_anatomy/","title":"Module 4: Pipeline Anatomy and Configuration","text":"<ul> <li>Objectives</li> <li>Understand built-in stages and default config</li> <li>Apply CLI overrides and read stage summaries</li> <li>Time: 60 minutes</li> </ul>"},{"location":"course/04_pipeline_anatomy/#41-read-the-source","title":"4.1 Read the source","text":"<ul> <li>Start at <code>src/mneme/analysis/pipeline.py</code> (class <code>MnemePipeline</code>)</li> <li>Components: Quality check \u2192 Preprocess (denoise/normalize/register/interpolate) \u2192 Topology \u2192 Attractors \u2192 Reconstruction (identity fallback unless sparse obs provided)</li> </ul>"},{"location":"course/04_pipeline_anatomy/#42-defaults","title":"4.2 Defaults","text":"<ul> <li><code>create_bioelectric_pipeline()</code> sets light denoise, per-frame normalize, linear interpolate, IFT reconstructor, cubical TDA, recurrence attractors (threshold 0.1)</li> </ul>"},{"location":"course/04_pipeline_anatomy/#43-config-overrides-via-cli","title":"4.3 Config overrides via CLI","text":"<p>Examples: <pre><code># Change topology backend\nmneme analyze path.npz --topology-backend alpha\n\n# Override attractors\nmneme analyze path.npz --attractor-method recurrence --attractor-min-persistence 0.2\n</code></pre></p>"},{"location":"course/04_pipeline_anatomy/#44-inspect-stage-results","title":"4.4 Inspect stage results","text":"<ul> <li>Stage summaries are included in the pipeline result and reflected in reports/visuals</li> <li>Quality report keys: <code>snr</code>, <code>resolution_adequacy</code>, <code>dynamic_range</code>, <code>coherence_quality</code>, etc.</li> </ul>"},{"location":"course/04_pipeline_anatomy/#exercises","title":"Exercises","text":"<p>1) Enable registration (for 3D time series) and observe changes in quality metrics 2) Downsampled TDA: increase your input size (e.g., 256\u00d7256) and confirm stride downsampling kicks in for cubical backend (see code around 128 limit) 3) Add a custom stage in Python that thresholds the processed field and records area; run it via a short script using <code>MnemePipeline.add_stage</code></p> <p>Solutions (outline) - Registration computes per-frame shifts; coherence/diff metrics can change - For large 2D arrays, the pipeline subsamples before TDA for speed; verify with logs/stage summary - <code>add_stage(name='threshold', stage=..., inputs=['processed_field'], outputs=['mask'])</code> and append to pipeline before run</p>"},{"location":"course/05_field_reconstruction/","title":"Module 5: Field Reconstruction (IFT and GP)","text":"<ul> <li>Objectives</li> <li>Understand and use IFT and GP reconstructors</li> <li>Provide sparse observations and positions to reconstruct fields</li> <li>Time: 60\u201390 minutes</li> </ul>"},{"location":"course/05_field_reconstruction/#51-api-overview","title":"5.1 API overview","text":"<ul> <li><code>mneme.core.field_theory.FieldReconstructor(method='ift'|'gaussian_process'|'neural_field')</code></li> <li><code>fit(observations, positions)</code> then <code>reconstruct()</code> and <code>uncertainty()</code></li> </ul>"},{"location":"course/05_field_reconstruction/#52-minimal-example-python","title":"5.2 Minimal example (Python)","text":"<pre><code>import numpy as np\nfrom mneme.core.field_theory import FieldReconstructor\n\n# Suppose we have 40 electrode observations on a 32x32 field\nrng = np.random.default_rng(0)\npositions = rng.uniform(0, 1, size=(40, 2))  # in [0,1]^2\nobservations = np.sin(4*np.pi*positions[:,0]) * np.cos(4*np.pi*positions[:,1]) + 0.1*rng.normal(size=40)\n\nrecon = FieldReconstructor(method='gaussian_process', resolution=(32, 32), length_scale=0.2, noise_level=0.05)\nresult = recon.fit_reconstruct(observations, positions)\nfield = result.field.data\nunc = result.uncertainty  # already an ndarray; do not call as a function\n</code></pre>"},{"location":"course/05_field_reconstruction/#53-ift-notes","title":"5.3 IFT notes","text":"<ul> <li>Prior covariance controlled by <code>correlation_length</code>, <code>power_spectrum_model</code></li> <li>Identity fallback is used when the pipeline has no sparse obs; supply <code>observations</code> and <code>positions</code> to enable real reconstruction</li> </ul>"},{"location":"course/05_field_reconstruction/#54-exercises","title":"5.4 Exercises","text":"<p>1) Reconstruct with GP over multiple <code>length_scale</code> values; inspect smoothness and uncertainty 2) Switch to IFT; tune <code>correlation_length</code>; compare visualizations 3) Stress test: add noise and see how uncertainty reflects confidence</p> <p>Run log (MVP) - Success: GP reconstruction returned a (32,32) field; <code>uncertainty</code> is an ndarray (don\u2019t call it). - Caveat: Calling <code>result.uncertainty()</code> raises <code>TypeError</code>; fix is to treat it as a property/array (<code>result.uncertainty</code>).</p> <p>Solutions (outline) - Larger <code>length_scale</code> \u2192 smoother fields; uncertainty smaller where observations dense - IFT yields similar behavior with different prior formulation; visual inspection + metrics - Noise increases posterior variance; visualize uncertainty heatmap</p>"},{"location":"course/06_topology_tda/","title":"Module 6: Topology (Cubical, Rips, Alpha) and Features","text":"<ul> <li>Objectives</li> <li>Compute persistence via cubical, Rips, Alpha backends</li> <li>Extract feature vectors; understand persistence images/landscapes</li> <li>Time: 60\u201390 minutes</li> </ul>"},{"location":"course/06_topology_tda/#61-cubical-persistence","title":"6.1 Cubical persistence","text":"<pre><code>import numpy as np\nfrom mneme.core.topology import PersistentHomology\n\nfield = np.random.randn(64,64)\nph = PersistentHomology(max_dimension=2, filtration='sublevel', persistence_threshold=0.05)\ndiagrams = ph.compute_persistence(field)\nfeatures = ph.extract_features(diagrams)\n</code></pre>"},{"location":"course/06_topology_tda/#62-ripsalpha-via-adapter","title":"6.2 Rips/Alpha via adapter","text":"<pre><code>from mneme.core.topology import RipsComplex, AlphaComplex, field_to_point_cloud\n\npc = field_to_point_cloud(field, method='peaks', percentile=95.0, max_points=2000)\nrc = RipsComplex(max_dimension=1)\nrd = rc.compute_persistence(pc)\nrf = rc.extract_features(rd)\n</code></pre>"},{"location":"course/06_topology_tda/#63-persistence-imageslandscapes-mvp","title":"6.3 Persistence images/landscapes (MVP)","text":"<ul> <li>Use <code>compute_persistence_image</code>/<code>compute_persistence_landscape</code> helpers for derived representations</li> </ul>"},{"location":"course/06_topology_tda/#exercises","title":"Exercises","text":"<p>1) Compare feature vectors across backends on the same field 2) Increase <code>percentile</code> in <code>field_to_point_cloud</code> and see how point density affects Rips results 3) Plot a persistence image for H1 and interpret visually</p> <p>Run log (MVP) - Success: Cubical and Rips both produced 2 diagrams with 12-length feature vectors in a quick test.</p> <p>Solutions (outline) - Different backends produce different sensitivities; features reflect scale and sampling - Higher threshold \u2192 fewer points \u2192 sparser complexes - Bright areas in persistence image correspond to long-lived features</p>"},{"location":"course/07_attractor_detection/","title":"Module 7: Attractor Detection (Recurrence, Lyapunov, Clustering)","text":"<ul> <li>Objectives</li> <li>Detect attractors from temporal field trajectories</li> <li>Tune thresholds and method-specific parameters</li> <li>Time: 60\u201390 minutes</li> </ul>"},{"location":"course/07_attractor_detection/#71-recurrence-default","title":"7.1 Recurrence (default)","text":"<pre><code>import numpy as np\nfrom mneme.core.attractors import AttractorDetector\n\n# Create a simple 2D oscillation\nt = np.linspace(0, 10, 200)\ntraj = np.column_stack([np.sin(t), np.cos(t)])\n\nad = AttractorDetector(method='recurrence', threshold=0.2, min_persistence=0.1, embedding_dimension=3, time_delay=1)\nattractors = ad.detect(traj)\n</code></pre>"},{"location":"course/07_attractor_detection/#72-lyapunov-basic-mvp","title":"7.2 Lyapunov (basic MVP)","text":"<pre><code>ad = AttractorDetector(method='lyapunov', threshold=0.05, n_neighbors=10, evolution_time=5)\nattractors = ad.detect(traj)\n</code></pre>"},{"location":"course/07_attractor_detection/#73-clustering-dbscankmeans","title":"7.3 Clustering (DBSCAN/KMeans)","text":"<pre><code>ad = AttractorDetector(method='clustering', threshold=0.2, min_samples=20, clustering_method='dbscan')\nattractors = ad.detect(traj)\n</code></pre>"},{"location":"course/07_attractor_detection/#74-exercises","title":"7.4 Exercises","text":"<p>1) Vary <code>threshold</code> and observe recurrence matrix density and attractor counts 2) For Lyapunov, change <code>evolution_time</code>; infer stability from mean exponents 3) For clustering, compare DBSCAN vs KMeans (set <code>n_clusters</code> via code edit if needed)</p> <p>Run log (MVP) - Recurrence: Detected several attractors on a simple circular trajectory (expected, due to recurrence clustering). Adjust thresholds for control. - Lyapunov: Returned 0 attractors on the simple sinusoid with default params (expected \u2014 near-neutral exponents). Increase <code>evolution_time</code> or apply to chaotic trajectories for meaningful results. - Clustering: Returned 0 for the toy sinusoid with <code>min_samples=20</code> (expected). Reduce <code>min_samples</code> or use denser/recurrent trajectories to see clusters.</p> <p>Solutions (outline) - Lower threshold \u2192 denser recurrences \u2192 more/merged attractors; higher \u2192 sparser - Longer evolution windows smooth estimates; negative averages suggest attracting regions - DBSCAN finds dense basins; KMeans partitions more uniformly but may miss irregular basins</p>"},{"location":"course/08_visualization_reporting/","title":"Module 8: Visualization and Reporting","text":"<ul> <li>Objectives</li> <li>Create dashboards and pipeline plots</li> <li>Read stage summaries and annotate findings</li> <li>Time: 45\u201360 minutes</li> </ul>"},{"location":"course/08_visualization_reporting/#81-dashboard","title":"8.1 Dashboard","text":"<pre><code>from mneme.analysis.visualization import FieldVisualizer\nfrom mneme.types import AnalysisResult\n\n# Suppose you already have `result: AnalysisResult`\nviz = FieldVisualizer()\nfig = viz.create_analysis_dashboard(result)\nfig.savefig('dashboard.png', dpi=300)\n</code></pre>"},{"location":"course/08_visualization_reporting/#82-pipeline-stage-plots","title":"8.2 Pipeline stage plots","text":"<pre><code>fig2 = viz.plot_pipeline_results(result.metadata.get('stage_results', {}) if isinstance(result.metadata, dict) else {})\nfig2.savefig('pipeline.png', dpi=300)\n\nNote: `mneme.utils.io.load_results` now returns an `AnalysisResult` directly for HDF5 paths (both `.h5` and `.hdf5`), so you can pass it straight into `create_analysis_dashboard`.\n</code></pre>"},{"location":"course/08_visualization_reporting/#exercises","title":"Exercises","text":"<p>1) Add titles and annotations to highlight key topology features 2) Save a persistence image for H1 using <code>compute_persistence_image</code> and place it in your report</p> <p>Run log (MVP) - The HDF5 loader now returns an <code>AnalysisResult</code>; dashboards render without conversion.</p> <p>Solutions (outline) - Use Matplotlib annotations; summarize feature vector stats on the figure - Derived images help visualize the distribution of persistence across birth/persistence space</p>"},{"location":"course/09_experiments_reproducibility/","title":"Module 9: Designing Experiments and Reproducibility","text":"<ul> <li>Objectives</li> <li>Use the <code>experiment</code> CLI to structure runs</li> <li>Save configs, results, and plots reproducibly</li> <li>Time: 45\u201360 minutes</li> </ul>"},{"location":"course/09_experiments_reproducibility/#91-run-an-experiment","title":"9.1 Run an experiment","text":"<p><pre><code>mneme experiment planarian_demo -d data/synthetic/quickstart.npz -p bioelectric -b experiments\n</code></pre> Creates a timestamped directory with config, results, and plots.</p>"},{"location":"course/09_experiments_reproducibility/#92-configuration-discipline","title":"9.2 Configuration discipline","text":"<ul> <li>Keep <code>config/default.yaml</code> under version control; override per-run via CLI or copying to an experiment folder</li> </ul>"},{"location":"course/09_experiments_reproducibility/#93-exercises","title":"9.3 Exercises","text":"<p>1) Compare two experiments with different topology backends; write a 5-sentence summary 2) Change attractor thresholds; capture differences in a simple CSV of metrics (edit <code>analysis/metrics.py</code> if desired)</p> <p>Solutions (outline) - Record backend, diagram counts, feature vector lengths, and any attractor counts; summarize trade-offs - Metrics scripts help quantify differences reproducibly</p>"},{"location":"course/10_performance_monitoring/","title":"Module 10: Performance and Monitoring (MVP Tools)","text":"<ul> <li>Objectives</li> <li>Use basic parallel helpers and monitoring utilities</li> <li>Measure stage timing and resource usage</li> <li>Time: 45\u201360 minutes</li> </ul>"},{"location":"course/10_performance_monitoring/#101-monitoring","title":"10.1 Monitoring","text":"<pre><code>from mneme.utils import monitoring\nmon = monitoring.PipelineMonitor()\nmon.start()\n# with mon.track_stage('preprocessing'):\n#     ...\nmetrics = mon.get_metrics()\nprint(metrics)\n</code></pre>"},{"location":"course/10_performance_monitoring/#102-parallel-helpers","title":"10.2 Parallel helpers","text":"<pre><code>from mneme.data.parallel import ParallelPipeline\n# Example: wrap an existing pipeline for batch\npp = ParallelPipeline(pipeline=my_pipeline, backend='multiprocessing', n_workers=4)\npp.map([\"data/a.npz\", \"data/b.npz\"])  # pseudo-example\n</code></pre>"},{"location":"course/10_performance_monitoring/#103-exercises","title":"10.3 Exercises","text":"<p>1) Time topology vs no-topology runs on 128\u00d7128 vs 256\u00d7256 inputs; chart the difference 2) Profile preprocessing SNR improvements vs runtime; choose defaults for your data</p> <p>Solutions (outline) - TDA time grows with size; confirm subsampling behavior for cubical - SNR/denoise trade-offs guide parameter choices for speed vs quality</p>"},{"location":"course/11_symbolic_regression/","title":"Module 11 (Optional): Symbolic Regression with PySR","text":"<ul> <li>Objectives</li> <li>Understand where symbolic regression may fit (post-feature extraction)</li> <li>Run a small regression to recover simple dynamics</li> <li>Time: 45\u201360 minutes (optional)</li> </ul>"},{"location":"course/11_symbolic_regression/#111-caveats","title":"11.1 Caveats","text":"<ul> <li>PySR is optional and may install Julia on first use</li> <li>Recommended install: <code>pip install -e .[pysr]</code> (pins scikit-learn and juliacall compatibly)</li> <li>MVP integrates lightly; treat this as exploratory</li> </ul>"},{"location":"course/11_symbolic_regression/#112-minimal-example-toy-data","title":"11.2 Minimal example (toy data)","text":"<pre><code>import numpy as np\nfrom pysr import PySRRegressor\n\nrng = np.random.default_rng(0)\nX = rng.uniform(-1,1,(200,2))\ny = np.sin(X[:,0]) + 0.5*X[:,1]**2\n\nmodel = PySRRegressor(niterations=20, binary_operators=[\"+\",\"*\",\"-\"], unary_operators=[\"sin\",\"cos\"])\nmodel.fit(X, y)\nprint(model.get_best())\n</code></pre> <p>Run log (MVP) - With <code>pip install -e .[pysr]</code>, PySR should work with compatible scikit-learn/juliacall versions. If Julia setup is deferred, the first call may download/build Julia artifacts.</p>"},{"location":"course/11_symbolic_regression/#113-using-topological-features-as-inputs","title":"11.3 Using topological features as inputs","text":"<p>In this section, we treat persistence-derived features as explanatory variables and try to learn an interpretable mapping to a target quantity. We\u2019ll synthesize a target first, then show how to use features from a pipeline run.</p>"},{"location":"course/11_symbolic_regression/#1131-direct-feature-construction-from-fields","title":"11.3.1 Direct feature construction from fields","text":"<pre><code>import numpy as np\nfrom mneme.core.topology import PersistentHomology\nfrom pysr import PySRRegressor\n\n# Create K random fields and compute PH features\nrng = np.random.default_rng(0)\nK = 100\nph = PersistentHomology(max_dimension=2, filtration='sublevel', persistence_threshold=0.03)\nX = []\nfor _ in range(K):\n    field = rng.normal(size=(64, 64))\n    diags = ph.compute_persistence(field)\n    feats = ph.extract_features(diags)  # shape ~ (6 * (max_dimension+1),)\n    X.append(feats)\nX = np.vstack(X)\n\n# Synthesize a target as a simple function of features\n# (e.g., y = 0.5 * sum of top 3 feature components + sin of the next)\ny = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.sin(X[:, 2])\n\n# Fit PySR\nmodel = PySRRegressor(\n    niterations=40,\n    binary_operators=[\"+\", \"*\", \"-\"],\n    unary_operators=[\"sin\", \"cos\", \"exp\"],\n    model_selection=\"best\",\n    maxsize=20,\n    progress=False,\n)\nmodel.fit(X, y)\n\nprint(\"Best equation:\")\nprint(model.get_best())\n\n# Evaluate R^2 on a held-out mini-set\nX_test = []\nfor _ in range(20):\n    field = rng.normal(size=(64, 64))\n    diags = ph.compute_persistence(field)\n    feats = ph.extract_features(diags)\n    X_test.append(feats)\nX_test = np.vstack(X_test)\ny_test = 0.5 * X_test[:, 0] + 0.3 * X_test[:, 1] + np.sin(X_test[:, 2])\nfrom sklearn.metrics import r2_score\nprint(\"R2:\", r2_score(y_test, model.predict(X_test)))\n</code></pre> <p>Expected outcome: PySR recovers a simple, low-complexity expression approximating the synthetic rule with high R^2.</p>"},{"location":"course/11_symbolic_regression/#1132-using-features-from-a-pipeline-result-hdf5","title":"11.3.2 Using features from a pipeline result (HDF5)","text":"<p>You can also run the pipeline once (Module 3/4), then use the saved features under <code>topology/features</code> as inputs:</p> <pre><code>from mneme.utils.io import load_results\nfrom pysr import PySRRegressor\nimport numpy as np\n\nar = load_results(\"results_cli/analysis_results.hdf5\")  # returns AnalysisResult\nif ar.topology is None or ar.topology.features is None:\n    raise RuntimeError(\"No topology features found in results. Re-run with topology enabled.\")\n\n# For demonstration, treat the feature vector as a single sample; in practice,\n# assemble a matrix across many samples (multiple fields or timepoints) before fitting.\nX = ar.topology.features.reshape(1, -1)\ny = np.array([np.sum(X)])  # dummy target; replace with a true label or metric\n\nmodel = PySRRegressor(niterations=10, binary_operators=[\"+\",\"*\",\"-\"], unary_operators=[\"sin\",\"cos\"], progress=False)\nmodel.fit(X, y)\nprint(model.get_best())\n</code></pre> <p>Note: For real learning, collect features from many samples (e.g., multiple runs, timepoints, or fields) and build a proper dataset <code>(X, y)</code>.</p>"},{"location":"course/11_symbolic_regression/#114-tips-and-best-practices","title":"11.4 Tips and best practices","text":"<ul> <li>Normalize/standardize features (z-score) before symbolic regression when magnitudes vary widely</li> <li>Keep operator sets small initially (e.g., <code>+ - *</code>, plus one or two unary ops)</li> <li>Limit expression size (<code>maxsize</code>) to encourage interpretable formulas</li> <li>Cross-validate by splitting fields/timepoints to gauge generalization</li> <li>Use domain knowledge to craft targets (e.g., known morphometric metrics) and constrain operator sets</li> </ul>"},{"location":"course/11_symbolic_regression/#115-exercises","title":"11.5 Exercises","text":"<p>1) Build a dataset of (features, target) from 50\u2013100 synthetic fields; recover a simple target like <code>sin(f0) + 0.2*f1</code> and report R^2 on a held-out set 2) Restrict operators to <code>+ - *</code> and observe how accuracy vs simplicity trades off 3) Use features from Rips/Alpha backends (via <code>field_to_point_cloud</code>) and compare the discovered forms 4) If you have labels from experiments, try replacing synthetic <code>y</code> with your real target; report the simplest model that achieves R^2 &gt; 0.7</p> <p>Run log (MVP) - With <code>pip install -e .[pysr]</code>, the synthetic feature regression converged quickly to a low-complexity formula with high R^2. Pipeline-derived features worked once multiple samples were aggregated.</p>"},{"location":"course/11_symbolic_regression/#exercises","title":"Exercises","text":"<p>1) Use topological features as <code>X</code> and a known morphodynamic target as <code>y</code>; see if simple expressions emerge 2) Inspect equation complexity vs error</p> <p>Solutions (outline) - Topological summaries may correlate with morphological regimes; use as features for interpretable rules - Complexity penalties steer PySR toward simpler, more generalizable equations</p>"}]}